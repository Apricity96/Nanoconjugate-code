{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf283534-5126-4fb0-b317-d61ffdbe3941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n",
      "C:\\Users\\Image_Processing_PC\\OneDrive\\UNSW\\Xueqian Chen - 20210326_totalextractionfromswab\\s2\\w1\\Analysisfolder_thresholding\n",
      "processing images\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6a44c75133eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    883\u001b[0m     \u001b[1;31m#loadsall the images in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m     \u001b[0mimaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimbef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeforeimfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mafterimfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimageprocessingfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeforefol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mafterfol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"processed and converted images\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-6a44c75133eb>\u001b[0m in \u001b[0;36mimageprocessingfunction\u001b[1;34m(beforefol, afterfol)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mimaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimbef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabef\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mafterimfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexifdata\u001b[0m\u001b[1;33m=\u001b[0m   \u001b[0mconvertfilefun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[0mimaf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mlabaf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexifdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-6a44c75133eb>\u001b[0m in \u001b[0;36mconvertfilefun\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;31m#cv2.imwrite(path + '.tiff',rgb)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# extract EXIF data to save as metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mmetdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0mexifdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetexif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### CHANGE THIS TO YOUR FOLDER##################\n",
    "##################################################\n",
    "bigfol=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\UNSW\\Xueqian Chen - 20210326_totalextractionfromswab\"\n",
    "##################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialise dependencies\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "from scipy import sparse\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "#import md5, sha\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "import imageio\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from PIL import Image,ImageEnhance,ImageFilter\n",
    "import PIL\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "#import hcluster\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from math import pow\n",
    "import scipy.signal \n",
    "%matplotlib qt\n",
    "#template matching\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.util import img_as_ubyte\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def process(token):\n",
    "    return token['text']\n",
    "\n",
    "#General Functions\n",
    "def listdirs(folder):\n",
    "## a function which lists the files in a folder and adds to a list. returns a list of folders, \n",
    "##input folder: the file path to folder\n",
    "    return [\n",
    "        d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))\n",
    "        if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "def labcolourfilt(image):\n",
    "    #%matplotlib qt\n",
    "    img_lab = cv.cvtColor(image, cv.COLOR_RGB2Lab)\n",
    "    lower_l = np.array([140,0,0])\n",
    "    upper_l = np.array([255,255,255])\n",
    "    lab_l,lab_a,lab_b=cv.split(img_lab)\n",
    "    mask = cv.inRange(img_lab, lower_l, upper_l)\n",
    "    res = cv.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    #plt.imshow(res)\n",
    "    return res\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_auto_wb=True,\n",
    "                                #user_wb=[1.5,1.0,1.0,1.0],\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1),\n",
    "                              bright=1.0,\n",
    "                              dcb_enhance=True)\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        \n",
    "def saveexcelfun(dimercoord,corecoord,savepath):\n",
    "#Save the coordinates of everything to an excel spreadsheet. Yeah I know it's ugly. \n",
    "#input: dimercoord- the dimer coordinates\n",
    "########corecoord- the core coordinates \n",
    "########savepath- the folder location where the files will be saved \n",
    "    columns=['Before Dimers xval']\n",
    "    saveexcel=savepath+\".\"+\"xlsx\"\n",
    "    beforedimercentres = pd.DataFrame({'Before Dimers xval':dimercoord})\n",
    "    try:\n",
    "        aftercorecentres = pd.DataFrame({'After core xval': corecoord})\n",
    "    except:\n",
    "        aftercorecentres=pd.DataFrame({'After core xval': np.array([0]), \n",
    "                                'After core yval': np.array([0])})\n",
    "\n",
    "   \n",
    "    writer = pd.ExcelWriter(saveexcel,engine='xlsxwriter')\n",
    "    workbook=writer.book\n",
    "    worksheet=workbook.add_worksheet('DimersPicked')\n",
    "    writer.sheets['DimersPicked'] = worksheet\n",
    "    worksheet2=workbook.add_worksheet('CoresPicked')\n",
    "    writer.sheets['CoresPicked'] = worksheet2\n",
    "\n",
    "\n",
    "    beforedimercentres.to_excel(writer,sheet_name='DimersPicked',startrow=1 , startcol=0)\n",
    "    #worksheet.write_string(beforedimercentres.shape[0] + 4, 0, beforedimercentres.name)\n",
    "\n",
    "    aftercorecentres.to_excel(writer,sheet_name='CoresPicked',startrow=1, startcol=3)\n",
    "    \n",
    "\n",
    "    writer.save()\n",
    "def savetextfilefun(data,savepath,datastring):\n",
    "##### A function which saves an array to a text file. Is a little buggy in that sometimes there's weird spaces. \n",
    "##### reccomend the excel save functions instead. Python struggles to re-read these text tiles\n",
    "\n",
    "    savetextstring=savepath+datastring+\".txt\"\n",
    "    file = open(savetextstring,\"w\")\n",
    "    for dataentry in data:\n",
    "        arr_of_strings = np.array2string(dataentry)\n",
    "        file.write(arr_of_strings) \n",
    "    file.close() \n",
    "    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "## A function which reads in images and adds them to a list of images.\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "## note !! The images wil be read in with open cv, and will be in BGR format and will look strange unless converted\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "def load_images_from_foldercv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to RGB\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "       \n",
    "        if img is not None:\n",
    "            img= cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "def load_images_from_folderhsv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to HSV\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        img= cv.cvtColor(img,  cv.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#####################################################\n",
    "###################################################\n",
    "#Template matching functions\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "        \n",
    "def nonmaxsuppression(xCoords,yCoords,template):\n",
    "    center_coordinates=[]\n",
    "    rects=[]\n",
    "    rectangle_coordinates=[]\n",
    "    (w, h) = template.shape[:2]\n",
    "    #print(w)\n",
    "    #print(h)\n",
    "## stops the overcounting of variables with nonmax suppression and returns an updated list\n",
    "    for (x, y) in zip(xCoords, yCoords):\n",
    "    # update our list of rectangles\n",
    "        rects.append((x, y, x +w, y + h))\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        center_coordinates.append((startX+h//2,startY+h//2))\n",
    "        rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "     \n",
    "    #print(\"center coordinates are \",center_coordinates)\n",
    "    #print(\"rectangle_coordinates are \", rectangle_coordinates)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "\n",
    "\n",
    "def blockimagecombo(image_rgb, points,r,bok):\n",
    "    #print(points)\n",
    "    if bok==1:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,255), -1)\n",
    "    else:\n",
    "        mask2 = np.zeros(image_rgb.shape[:2], dtype= np.uint8)\n",
    "        for pt in points: \n",
    "            #print(pt)\n",
    "            mask2 = cv.circle(mask2,pt,r, (255,255,255), -1)\n",
    "            \n",
    "            # a rectangle is drawn on the mask, which marks where the points are \n",
    "        #invmask=255-mask2\n",
    "        #This is an inbuilt cv function which clips the image around the mask. \n",
    "        #plt.imshow(cv.bitwise_and(image_rgb, image_rgb, mask=invmask))\n",
    "        image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "def performtemplatematching(image_rgb,imgpath,bok,threshold,clumpflag):\n",
    "## a function which performs template matching on the images and blocks them depending on whether\n",
    "## we want to keep the particles or block them out for more accuracy \n",
    "#input: image_rgb: the big image in rgb format where we are looking for matches\n",
    "########imgpath: the path to the template images, as a string\n",
    "#########bok: block or keep. 0 is for keeping, 1 is for blocking with a rectange\n",
    "#########threshold: the threshold for the minimum values. Variable. \n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=imagetempmatch(imgpath,image_rgb,threshold,clumpflag)\n",
    "    r=round(w/1.5)\n",
    "\n",
    "    correctedimg=blockimagecombo(image_rgb,center_coordinates ,r,bok)\n",
    "    return correctedimg,center_coordinates,r\n",
    "\n",
    "def performsaveimage(image,path):\n",
    "## saves image using pillow, which is a lot faster than matplot lib. \n",
    "    img_rgb_corr=image\n",
    "    try:\n",
    "        im_pil = Image.fromarray(img_rgb_corr)\n",
    "        im_pil.save(path, compress_level=1)\n",
    "    except:\n",
    "        exception=1\n",
    "\n",
    "def savetotrainingfol(foldername,image,points):\n",
    "## saves the cropped images to a folder, for use in machine learning. uses a 16 pixel box.\n",
    "#input: foldername: name of the folder where you want the images stored\n",
    "#######image: an image in rgb format which you want to cut up\n",
    "########points: the coordinates of the particles which you have selected. \n",
    "    boxwid=round(16/2)\n",
    "    w=16\n",
    "    for j,pt in enumerate(points):\n",
    "        savepathfol= addstringwithtime(foldername +'\\\\')\n",
    "        savepath= savepathfol+str(j)+\"registeredimg\" + \".\" + \"png\"\n",
    "        #savepath=os.path.join(savepathfol, str(j)+\"registeredimg\" + \".\" + \"png\")\n",
    "        lilimage=image[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        performsaveimage(lilimage,savepath)\n",
    "        \n",
    "def blockoutunwantedparticles(analpath,sat_img,path,threshold,clumpflag):\n",
    "## a function which blocks out that particles which are interfering with analysis i.e. clumps and clusters\n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#output: correctedimgcore, the corrected image after accounting for cores and clumps\n",
    "# These images are hardcoded into a folder, so the code has some dependencies. But any exmaples of the correct size will do\n",
    "    #The threshold of 0.25 seems to be highly variable\n",
    "    correctedimg,_,r= performtemplatematching(sat_img, path,1,threshold,clumpflag)\n",
    "    #plt.imshow(correctedimg)\n",
    "    #print(r)\n",
    "    return correctedimg,r\n",
    "\n",
    "         \n",
    "def getthecolourscores(vector):\n",
    "    #print(vector)\n",
    "    splitvec=np.array_split(vector, 2,axis=1)\n",
    "    #print(splitvec)\n",
    "    intvals=[np.trapz(vec) for vec in splitvec]\n",
    "    #print(intvals[0])\n",
    "    #print(intvals[1])\n",
    "    #yes=here\n",
    "    \n",
    "    return intvals[0],intvals[1]\n",
    "def makeLabvectorspretty(l_vec,a_vec,b_vec):\n",
    "    #l_vec = l_vec.ravel()\n",
    "    lnoz=np.nonzero(l_vec)\n",
    "    l_vecf=l_vec[lnoz]\n",
    "    #a_vec = a_vec.ravel()\n",
    "    #a_vec.sort()\n",
    "    anoz=np.nonzero(a_vec)\n",
    "    a_vecf=a_vec[anoz]\n",
    "    #b_vec = b_vec.ravel()\n",
    "    bnoz=np.nonzero(b_vec)\n",
    "    b_vecf=b_vec[bnoz]\n",
    "    return l_vecf.reshape((1,-1)),a_vecf.reshape((1,-1)),b_vecf.reshape((1,-1))\n",
    "def makeLabvectorsprettyind(l_vec):\n",
    "    lnoz=np.nonzero(l_vec)\n",
    "    l_vecf=l_vec[lnoz]\n",
    "    return l_vecf.reshape((1,-1))\n",
    "\n",
    "def makelinspacevector(vector):\n",
    "    max_vec=np.max(vector)\n",
    "    min_vec=np.min(vector)\n",
    "    #print(vector.shape)\n",
    "    xshape,yshape=vector.shape\n",
    "    \n",
    "    #print(yshape)\n",
    "    lin_vec = np.linspace(min_vec, max_vec,num=yshape)\n",
    "    return lin_vec\n",
    "\n",
    "def getkdefunction(vector):\n",
    "    #print(vector)\n",
    "    #print(vector.shape)\n",
    "    \n",
    "    \n",
    "    kde = KernelDensity(kernel=\"gaussian\", bandwidth=3)\n",
    "    \n",
    "    \n",
    "    if len(vector)==0:\n",
    "        log_dens=[0]\n",
    "      \n",
    "\n",
    "    else:\n",
    "        kde.fit(vector.reshape((1,-1)))\n",
    "        x_d=makelinspacevector(vector.reshape((1,-1)))\n",
    "        log_dens = kde.score_samples(x_d.reshape((1,-1)))\n",
    "        \n",
    "\n",
    "    return log_dens\n",
    "\n",
    "\n",
    "def getkdepeaksLABind(l_vec):\n",
    "    vector=makeLabvectorsprettyind(l_vec)\n",
    "    \n",
    "    if len(l_vec)!=0:\n",
    "        \n",
    "        log_dens_l=getkdefunction(l_vec)\n",
    "        x_d=makelinspacevector(l_vec.reshape((1,-1)))\n",
    "        #density = norm(l_vec).pdf(x_d)\n",
    "        #yes=here\n",
    "        kde = KernelDensity(bandwidth=1.0, kernel='gaussian')\n",
    "        kde.fit(l_vec[:, None])\n",
    "        logprob = kde.score_samples(x_d[:, None])\n",
    "        \n",
    "        #peaks_l, _ = find_peaks(logprob)\n",
    "        \n",
    "        intneg,intpos=getthecolourscores(vector)\n",
    "        #print(log_dens_l)\n",
    "        #%matplotlib qt\n",
    "        #plt.figure()\n",
    "        #plt.fill_between(x_d, density, alpha=0.5)\n",
    "        \n",
    "        #plt.plot(x_d, np.exp(logprob))\n",
    "        #plt.hist(l_vec,bins=5)\n",
    "        #plt.plot(density)\n",
    "        #plt.hist(l_vec, bins=8)\n",
    "        #plt.plot(x_d,density)\n",
    "        #plt.plot(peaks_l, logprob[peaks_l], \"x\")\n",
    "        #plt.show()\n",
    "        #stop=here\n",
    "        \n",
    "    #if len(peaks_l)==0:\n",
    "        #peaks_l=[0]\n",
    "    if len(intpos)==0:\n",
    "        intpos=[0.1]\n",
    "        intneg=[0.1]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #print(peaks_l)\n",
    "    #print(peaks_b)\n",
    "    #print(peaks_a)\n",
    "    #plt.figure()\n",
    "    #plt.plot(log_dens_a)\n",
    "    #plt.plot(peaks_a, log_dens_a[peaks_a], \"x\")\n",
    "    #plt.show()\n",
    "    #yes=here\n",
    "    return intneg,intpos#peaks_l    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def gethistogrampeaksLAB(l_vec,a_vec,b_vec):\n",
    "    l_vec,a_vec,b_vec=makeLabvectorspretty(l_vec,a_vec,b_vec)\n",
    "    peaks_l,peaks_a,peaks_b=getkdepeaksLAB(l_vec,a_vec,b_vec)\n",
    "    \n",
    " \n",
    "\n",
    "    return peaks_l,peaks_a,peaks_b,y_l,y_a,y_b\n",
    "\n",
    "def processimagecrop(vector,w,pt):\n",
    "    cropimage=vector[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "    #print(cropimage)\n",
    "    cropimr=cropimage.reshape((1,-1))\n",
    "    #print(cropimr)\n",
    "    return cropimr\n",
    "def keepemptyindex(vector,point):\n",
    "    item=vector[np.nonzero(vector)]\n",
    "    pointlist=point\n",
    "    return item, pointlist\n",
    "\n",
    "def checkforempty(vector,points):\n",
    "    test=[keepemptyindex(item,points[index]) for index,item in enumerate(vector) if len(item[np.nonzero(item)])!=0]\n",
    "    if len(test)==0:\n",
    "        vector2=[]\n",
    "        pointlist=[]\n",
    "    else:\n",
    "    \n",
    "        vector2,pointlist=map(list,zip(*[keepemptyindex(item,points[index]) for index,item in enumerate(vector) if len(item[np.nonzero(item)])!=0]))\n",
    "\n",
    "    return vector2,np.asarray(pointlist).reshape((-1,2))\n",
    "    \n",
    "\n",
    "def getaveragevaluesLAB(image,points,analpath,yespeaks):\n",
    "    #A function which gets the colour scores for each lab colour vector by finding the vector, doing a kde desnsity graph of each value, splitting that kde density in half \n",
    "    # and then integrating each half\n",
    "    ####input: image- the image you want to analyse\n",
    "    ###########points- the centre of each particle you want to analyse\n",
    "    ##########analpath- the place to save the analysis\n",
    "    ##########yespeaks- an optional boolean so you have the option to not get the scores for each round. \n",
    "    #width of the sampling box around the particle center\n",
    "    w=8\n",
    "    #convert to lab colourspace\n",
    "    labim = rgb2lab(image)\n",
    "    #split into individual vectors\n",
    "    l_vec,a_vec,b_vec = cv.split(labim)\n",
    "    average_colour_aDivg=[]\n",
    "    max_val_lDivg=[]\n",
    "    average_lum=[]\n",
    "    average_comp_a_to_b=[]\n",
    "    info_l=[]\n",
    "    info_a=[]\n",
    "    info_b=[]\n",
    "    allchannel=[l_vec,a_vec,b_vec]\n",
    "    \n",
    "    #Get the cropped particles around the center points\n",
    "    allcropimagesl=[processimagecrop(l_vec,w,pt) for pt in points if len(l_vec)!=0]\n",
    "    #print(points)\n",
    "    #check that the cropped images aren't empty, delete the empty ones\n",
    "    \n",
    "    allcropimagesl2,pointlistl=checkforempty(allcropimagesl,points)\n",
    "    \n",
    "    \n",
    "    #repeat for the a vector\n",
    "    allcropimagesa=[processimagecrop(a_vec,w,pt) for pt in pointlistl]\n",
    "    allcropimagesa2,pointlist_a=checkforempty(allcropimagesa,pointlistl)\n",
    "   \n",
    "    \n",
    "    #repeat for the b vector\n",
    "    allcropimagesb=[processimagecrop(b_vec,w,pt) for pt in pointlist_a]\n",
    "    allcropimagesb2,pointlist_b=checkforempty(allcropimagesb,pointlist_a)\n",
    "    \n",
    "    #for each cropped image, perform the kde analysis and get the colour score by integration. repeat for the three vectors. \n",
    "    if len(allcropimagesl2)!=0:\n",
    "        neg_l,pos_l=map(list,zip(*[getkdepeaksLABind(vector) for vector in allcropimagesl2 if yespeaks==1]))\n",
    "\n",
    "\n",
    "        greenscore,redscore=map(list,zip(*[getkdepeaksLABind(vector) for vector in allcropimagesa2 if yespeaks==1]))\n",
    "\n",
    "\n",
    "        bluescore,yellowscore=map(list,zip(*[getkdepeaksLABind(vector) for vector in allcropimagesb2 if yespeaks==1]))\n",
    "    else:\n",
    "        neg_l=[]\n",
    "        pos_l=[]\n",
    "        greenscore=[]\n",
    "        redscore=[]\n",
    "        bluescore=[]\n",
    "        yellowscore=[]\n",
    "        pointlist_b=[]\n",
    "   \n",
    "    return neg_l,pos_l,greenscore,redscore,bluescore,yellowscore,pointlist_b\n",
    "\n",
    "\n",
    "\n",
    "######### Extra functions\n",
    "\n",
    "def getindividualfoldersandsuch(bigfol):\n",
    "# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\n",
    "    topfolders=listdirs(bigfol)\n",
    "    subfolders=[0]\n",
    "    for nextfolders in topfolders:\n",
    "        subfolders= subfolders+ listdirs(nextfolders)\n",
    "    subfolders.pop(0)\n",
    "    #print(subfolders)\n",
    "    subfolders=np.array(subfolders).reshape(-1,1)\n",
    "    #print(subfolders)\n",
    "    return subfolders\n",
    "def searchforsatandtargetfolders(folder):\n",
    "#finds the satellite and targetfolders using regexp\n",
    "    subfolders2 = folder.tolist()\n",
    "    subfolders3=str(subfolders2).replace('[','').replace(']','').replace('\\\\\\\\','\\\\')\n",
    "\n",
    "    listexpfolders=listdirs(subfolders3[1:len(subfolders3)-1])\n",
    "    beforefol = [x for x in listexpfolders if re.search(\"satellite\",x)]\n",
    "    beforefol=beforefol[0]\n",
    "    afterfol= [x for x in listexpfolders if re.search(\"target\",x)]\n",
    "    afterfol=afterfol[0]\n",
    "    \n",
    "    return beforefol,afterfol\n",
    "\n",
    "def createanalysisfolder(beforefol,string):\n",
    "#creates an analysis folder in the address above where the satellite and target folders are located.\n",
    "    oneuppath=os.path.dirname(beforefol)\n",
    "    analysisfolderpath=oneuppath+\"\\\\\"+string\n",
    "    try:\n",
    "        os.mkdir(analysisfolderpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    print(analysisfolderpath)\n",
    "    print(\"processing images\")\n",
    "    return analysisfolderpath,oneuppath\n",
    "\n",
    "def createimagesubfolderforsaving(pathtomatch,analysisfolderpath):\n",
    "# creates a folder with the name of the image in the analysis folder \n",
    "    pathtomatch=beforeimfile[j]\n",
    "    matchingsearch=re.search(\"IMG_.*.CR2\",pathtomatch)\n",
    "    savefilespath=analysisfolderpath+\"\\\\\"+matchingsearch.group()+\"\\\\\"\n",
    "    try: \n",
    "        os.mkdir(savefilespath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    return savefilespath\n",
    "def addstringwithtime(savefilespath):\n",
    "# adds the current date and time so there's no saving over the top of different analysis\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    savepath=savefilespath+dt_string\n",
    "    return savepath\n",
    "def makeanalysisfolder(savefilespath,string):\n",
    "# makes a directory in the folder which matches the image name which says 'analysis'\n",
    "    analpath=os.path.join(savefilespath,string)\n",
    "                        #saves the registered image\n",
    "    try: \n",
    "        os.mkdir(analpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    return analpath\n",
    "\n",
    "################ THRESHOLDING\n",
    "\n",
    "def getcentroidsandcenters(image):\n",
    "    ### a function which gets the centres of particles. It's not perfect but it's okay\n",
    "    \n",
    "    h=8\n",
    "    src=image.copy()\n",
    "    #turns the image black and white\n",
    "    bw = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    #_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #Finds the contours of the black and white image\n",
    "    contours, hierarchy = cv.findContours(bw, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    list_of_centres=[]\n",
    "    boundRect = [None]*len(contours)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    #filters for repeats of the same point by drawing a rectangle around it and seeing if it overlaps using non_max_suppression\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        center_circle, _ = cv.minEnclosingCircle(contours_poly[i])\n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(boundRect),0.5) \n",
    "   \n",
    "    \n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        list_of_centres.append((startX+h//2,startY+h//2))\n",
    "        #rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "    #list_of_centres.append((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "    for centers in list_of_centres:\n",
    "        cv.circle(src, ((np.int(np.round(centers[0])),np.int(np.round(centers[1])))), 20, (255, 255, 0), 1)\n",
    "\n",
    "        \n",
    "    return list_of_centres\n",
    "\n",
    "def returnlistoftargeted(scorelist,greenscore,redscore):\n",
    "    returnedlist=np.array(scorelist)[np.logical_and(np.array(greenscore)>100,np.array(redscore)>200)]\n",
    "    \n",
    "    return returnedlist\n",
    "\n",
    "def returnlistoftargeteddimers(scorelist,greenscore,redscore):\n",
    "    ### just a function that returns the filtered values for a list of attributes\n",
    "    returnedlist=np.array(scorelist)[np.logical_and(np.array(greenscore)>100,np.array(redscore)>200)]\n",
    "    \n",
    "    return returnedlist\n",
    "def returnlistoftargetedcores(scorelist,greenscore,redscore,lscore):\n",
    "    ### just a function that returns the filtered values for a list of attributes\n",
    "    #print(greenscore\n",
    "    #print(scorelist)\n",
    "    returnedlist=np.array(scorelist)[np.logical_and(np.array(greenscore)<-100,np.array(redscore)<-500)]\n",
    "    lscorefilt=np.array(greenscore)[np.logical_and(np.array(greenscore)<-100,np.array(redscore)<-500)]\n",
    "    returnedlist2=np.array(returnedlist)[lscorefilt<4000]\n",
    "    \n",
    "    \n",
    "    return returnedlist2#returnedlist2\n",
    "\n",
    "def drawcirclesandsave(image,points,analpath,string):\n",
    "    #####A function which draws circles on an image given some points. Truly thrilling lol\n",
    "    ##inputs: image- the image you're drawing circles on\n",
    "    #########points- the centers of the circles you want to draw\n",
    "    ########analpath- the analysis path where you want to save the image\n",
    "    ########string- a description of the image\n",
    "    circleim=image.copy()\n",
    "    for pt in points:\n",
    "        cv.circle(circleim, (pt[0],pt[1]), 8, (255, 255, 0), 4)\n",
    "    savepath=analpath+'\\\\'+string\n",
    "    performsaveimage(circleim,savepath)\n",
    "    \n",
    "def performthresholdingLABfortarget(beforeim,afterim,analpath):\n",
    "    ### performs the thresholding using LAB colour vectors. Integrates these vectors for each particle to come up with colourscores for each particle, then filtered.\n",
    "    ##inputs: beforeim- dimer image\n",
    "    #########afterim-target image\n",
    "    ##### used for target data, change if you want red to green instead of green to red\n",
    "    ##outputs: list_of_data- colourscores for each target particle selected \n",
    "    ##########dimer_points2- the centres of each particle for each target particle selected\n",
    "    ##########listofdatabefore-the colourscores for each dimer particle corresponding to the selected target\n",
    "    ##########core_points2- confusing, sorry, will fix eventually. The centers of each selected dimer particle\n",
    "    #gets the list of centers of all particles using the centroid function on the before images\n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    #For each center found, get the corresponding colour and luminance values\n",
    "    neg_l,pos_l,greenscore,redscore,bluescore,yellowscore,pointlist_b=getaveragevaluesLAB(beforeim,list_of_centres,analpath,1)\n",
    "    #filter the selected points using green and red score parameters\n",
    "    filtercore=np.asarray(np.logical_and(np.array(greenscore)>100,np.array(redscore)>500))\n",
    "    filtercore2=np.asarray(np.array(neg_l)<4000)\n",
    "    #it goes funny if I try normally filtering it so I have to do this yuck version\n",
    "    core_points=np.array(pointlist_b)*filtercore*filtercore2\n",
    "    core_points2=(core_points[core_points!=0]).reshape((-1,2))\n",
    "    #Draw the circles of the selected particles on the image and save it in the analysis folder\n",
    "    drawcirclesandsave(beforeim,core_points2,analpath,\"dimers_selected.png\")\n",
    "    print(\"done the dimer points\")\n",
    "    \n",
    "    #Do the same process for the target, using the dimer points from before and seeing if any dimer particles have gone green\n",
    "    neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d,pointlist_d=getaveragevaluesLAB(afterim,core_points2,analpath,1)\n",
    "    #print(\"done the dimer points\")\n",
    "    filterdimer=np.asarray(np.logical_and(np.asarray(greenscore_d).reshape((-1,1))<-100,np.asarray(redscore_d).reshape((-1,1))<-500))\n",
    "    filterdimer2=np.asarray(np.array(neg_l_d).reshape((-1,1))<4000)\n",
    "    dimer_points=np.array(pointlist_d)*filterdimer*filterdimer2\n",
    "    \n",
    "    dimer_points2=(dimer_points[dimer_points!=0]).reshape((-1,2))\n",
    "    drawcirclesandsave(afterim,dimer_points2,analpath,\"target_selected.png\")\n",
    "    #targeted_points=np.array(core_points).reshape((-1,2))[np.logical_and(np.asarray(greenscore).reshape((-1,1))>100,np.asarray(redscore).reshape((-1,1))>100)] \n",
    "    if len(dimer_points2)==0:\n",
    "        listofdatabefore=[]\n",
    "        #print(\"it's reading this as empty\")\n",
    "    else:\n",
    "        neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c,pointlist_c=getaveragevaluesLAB(beforeim,dimer_points2,analpath,1)\n",
    "        \n",
    "        listofdatabefore=[neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c]\n",
    "        #print(listofdatabefore)\n",
    "    arrayofdata=[neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d]\n",
    "    #print(arrayofdata)\n",
    "    list_of_data=[returnlistoftargetedcores(scorelist,greenscore_d,redscore_d,neg_l_d) for scorelist in arrayofdata]\n",
    "    \n",
    "    \n",
    "    return list_of_data,core_points2,dimer_points2,listofdatabefore\n",
    "    \n",
    "    \n",
    "def performthresholdingLABforruler(beforeim,afterim,analpath):\n",
    "    ### performs the thresholding using LAB colour vectors. Integrates these vectors for each particle to come up with colourscores for each particle, then filtered.\n",
    "    ##inputs: beforeim- core image\n",
    "    #########afterim-dimer image\n",
    "    ##### used for ruler data, change if you want green to red instead of red to green\n",
    "    ##outputs: list_of_data- colourscores for each dimer particle selected \n",
    "    ##########dimer_points2- the centres of each particle for each dimer particle selected\n",
    "    ##########listofdatabefore-the colourscores for each core particle corresponding to the selected dimer\n",
    "    \n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    \n",
    "    neg_l,pos_l,greenscore,redscore,bluescore,yellowscore,pointlist_b=getaveragevaluesLAB(beforeim,list_of_centres,analpath,1)\n",
    "    filtercore=np.asarray(np.logical_and(np.array(greenscore)<-50,np.array(redscore)<-100))\n",
    "    core_points=np.array(pointlist_b)*filtercore\n",
    "    \n",
    "    core_points2=(core_points[core_points!=0]).reshape((-1,2))\n",
    "    drawcirclesandsave(beforeim,core_points2,analpath,\"cores_selected.png\")\n",
    "    \n",
    "    \n",
    "    print(\"done the core points\")\n",
    "    neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d,pointlist_d=getaveragevaluesLAB(afterim,core_points2,analpath,1)\n",
    "    #print(\"done the dimer points\")\n",
    "    filterdimer=np.asarray(np.logical_and(np.asarray(greenscore_d).reshape((-1,1))>100,np.asarray(redscore_d).reshape((-1,1))>200))\n",
    "    dimer_points=np.array(pointlist_d)*filterdimer\n",
    "    dimer_points2=(dimer_points[dimer_points!=0]).reshape((-1,2))\n",
    "    drawcirclesandsave(afterim,dimer_points2,analpath,\"dimers_selected.png\")\n",
    "    #targeted_points=np.array(core_points).reshape((-1,2))[np.logical_and(np.asarray(greenscore).reshape((-1,1))>100,np.asarray(redscore).reshape((-1,1))>100)]\n",
    "    \n",
    "    neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c,pointlist_c=getaveragevaluesLAB(beforeim,dimer_points2,analpath,1)\n",
    "    \n",
    "    arrayofdata=[neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d]\n",
    "    list_of_data=[returnlistoftargeted(scorelist,greenscore_d,redscore_d) for scorelist in arrayofdata]\n",
    "    \n",
    "    listofdatabefore=[neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return list_of_data,dimer_points2,listofdatabefore\n",
    "\n",
    "\n",
    "def variance_of_laplacian(image):\n",
    "    return cv.Laplacian(image,cv.CV_64F).var()\n",
    "\n",
    "def blurdetect(befim,afterim,thresh):\n",
    "    blurry=0\n",
    "    gray_bef=cv.cvtColor(befim,cv.COLOR_RGB2GRAY)\n",
    "    gray_af=cv.cvtColor(afterim,cv.COLOR_RGB2GRAY)\n",
    "    lapbef=variance_of_laplacian(gray_bef)\n",
    "    lapaf=variance_of_laplacian(gray_af)\n",
    "    if (lapbef<thresh) or (lapaf<thresh):\n",
    "        blurry=1\n",
    "    print(\"lapbef is \" + str(lapbef))\n",
    "    print(\"lapaf is \" + str(lapaf))\n",
    "    return blurry\n",
    "    \n",
    "\n",
    "subfolders=getindividualfoldersandsuch(bigfol)\n",
    "\n",
    "for folder in subfolders:\n",
    "    #automatically find the before and after folder \n",
    "    beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    \n",
    "    #Create the relevant folder for saving,as well as the path one folder up \n",
    "    #analysisfolderpath_temp,oneuppath_temp=createanalysisfolder(beforefol,\"Analysisfolder_Template\")\n",
    "    analysisfolderpath_thresh,oneuppath_thresh=createanalysisfolder(beforefol,\"Analysisfolder_thresholding\")\n",
    "    \n",
    "    \n",
    "    #loadsall the images in \n",
    "\n",
    "    imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction(beforefol,afterfol)\n",
    "    print(\"processed and converted images\")\n",
    "    \n",
    "    \n",
    "    #response=[0]*len(beforeimfile)\n",
    "    #dimercount=[0]*len(beforeimfile)\n",
    "    #targetcount=[0]*len(beforeimfile)\n",
    "    response_thresh=[0]*len(beforeimfile)\n",
    "    dimercount_thresh=[0]*len(beforeimfile)\n",
    "    targetcount_thresh=[0]*len(beforeimfile)\n",
    "    dimer_greenscore=[0]*len(beforeimfile)\n",
    "    dimer_redscore=[0]*len(beforeimfile)\n",
    "    dimer_yellowscore=[0]*len(beforeimfile)\n",
    "    dimer_bluescore=[0]*len(beforeimfile)\n",
    "    dimer_lscore=[0]*len(beforeimfile)\n",
    "    target_greenscore=[0]*len(beforeimfile)\n",
    "    target_redscore=[0]*len(beforeimfile)\n",
    "    target_yellowscore=[0]*len(beforeimfile)\n",
    "    target_bluescore=[0]*len(beforeimfile)\n",
    "    target_lscore=[0]*len(beforeimfile)\n",
    "    #t = tqdm(total=len(imbef))\n",
    "    for j,image in enumerate(imbef):\n",
    "        \n",
    "\n",
    "        pathtomatch=beforeimfile[j]\n",
    "        #savefilespath_temp= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_temp)\n",
    "        savefilespath_thresh= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_thresh)\n",
    "        \n",
    "        \n",
    "        #add on the currentdate and time \n",
    "        #savepath_temp=addstringwithtime(savefilespath_temp)\n",
    "        savepath_thresh=addstringwithtime(savefilespath_thresh)\n",
    "        \n",
    "        \n",
    "        print(\"calculating image \"+str(j+1)+\" of \"+ str(len(imbef)))\n",
    "        \n",
    "        #make an analysis folder which says analysis in the image folder just created \n",
    "        #analpath_temp=makeanalysisfolder(savefilespath_temp,\"Analysisimages_Template\")\n",
    "        analpath_thresh=makeanalysisfolder(savefilespath_thresh,\"Analysisimages_thresholding\")\n",
    "        blurry=blurdetect(image,imaf[j],159)\n",
    "        if blurry==1:\n",
    "            continue\n",
    "        #spot matches the before and after images \n",
    "        transimaf=imgregfun(image, imaf[j])\n",
    "        #saves the redistered image\n",
    "        saveregisteredimage=os.path.join(analpath_thresh, \"registeredimg\" + \".\" + \"png\")\n",
    "        performsaveimage(transimaf,saveregisteredimage)\n",
    "       \n",
    "\n",
    "        centreimagebefore=labcolourfilt(image)\n",
    "        \n",
    "        print(\"Made the clipping Mask\")\n",
    "        #plt.imshow(centreimagebefore)\n",
    "        centreimageafter=labcolourfilt(transimaf)\n",
    "        #uncomment if you want a crop box    \n",
    "        height, width = image.shape[:2]\n",
    "        boxwid=round(2500/2)\n",
    "        centreimagebefore=centreimagebefore[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        centreimageafter=centreimageafter[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        \n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.75)\n",
    "            #sleep(0.1)\n",
    "        list_of_data,dimer_points,target_points,listofdatabefore=performthresholdingLABfortarget(centreimagebefore,centreimageafter,analpath_thresh)\n",
    "        neg_l,pos_l,greenscore,redscore,bluescore,yellowscore=np.vsplit(np.array(list_of_data), 6)\n",
    "\n",
    "        #print(neg_l.shape)\n",
    "        #print(neg_l.reshape((-1,1)))\n",
    "        if len(listofdatabefore)!=0:\n",
    "            #print(np.array(list_of_data).shape)\n",
    "            neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d=np.vsplit(np.array(listofdatabefore), 6)\n",
    "            #print(neg_l_d.shape)\n",
    "            \n",
    "\n",
    "            neg_l=neg_l.reshape((-1,1))\n",
    "            pos_l=pos_l.reshape((-1,1))\n",
    "            greenscore=greenscore.reshape((-1,1))\n",
    "            redscore=redscore.reshape((-1,1))\n",
    "            bluescore=bluescore.reshape((-1,1))\n",
    "            yellowscore=yellowscore.reshape((-1,1))\n",
    "\n",
    "            neg_l_d=neg_l.reshape((-1,1))\n",
    "            pos_l_d=pos_l.reshape((-1,1))\n",
    "            greenscore_d=greenscore_d.reshape((-1,1))\n",
    "            redscore_d=redscore_d.reshape((-1,1))\n",
    "            bluescore_d=bluescore_d.reshape((-1,1))\n",
    "            yellowscore_d=yellowscore_d.reshape((-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #saves the to an excel spreadsheet and saves the results to a list to get the overall results at the end \n",
    "            #if I feel bothered I can add something in that uses the already analysed images but meh \n",
    "\n",
    "\n",
    "            dimercount_thresh[j]=len(dimer_points)\n",
    "            targetcount_thresh[j]=len(target_points)\n",
    "            saveexpath=analpath_thresh+'\\\\'+\"colourscoresforimage.xlsx\"\n",
    "\n",
    "            # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "            writer = pd.ExcelWriter(saveexpath, engine='xlsxwriter')\n",
    "            dimerresp=pd.DataFrame({'dimer_greenscore':[np.transpose(greenscore_d)],'dimer_yellowscore':[np.transpose(yellowscore_d)],'dimer_redscore':[np.transpose(redscore_d)],'dimer_bluescore':[np.transpose(bluescore_d)],'dimer_luminosity':[np.transpose(neg_l_d)]})\n",
    "            targetresp=pd.DataFrame({'target_greenscore':[np.transpose(greenscore)],'target_yellowscore':[np.transpose(yellowscore)],'target_redscore':[np.transpose(redscore)],'target_bluescore':[np.transpose(bluescore)],'target_luminosity':[np.transpose(neg_l)]})\n",
    "            # Write each dataframe to a different worksheet.\n",
    "            dimerresp.to_excel(writer, sheet_name='DimerData')\n",
    "            targetresp.to_excel(writer, sheet_name='TargetData')\n",
    "        \n",
    "\n",
    "            # Close the Pandas Excel writer and output the Excel file.\n",
    "            writer.save()\n",
    "            try: \n",
    "                response_thresh[j]=(len(target_points)/len(dimer_points))*100\n",
    "\n",
    "            except:\n",
    "                response_thresh[j]=0\n",
    "        else:\n",
    "            \n",
    "            dimercount_thresh[j]=len(dimer_points)\n",
    "            targetcount_thresh[j]=0\n",
    "            saveexpath=analpath_thresh+'\\\\'+\"colourscoresforimage.xlsx\"\n",
    "\n",
    "            # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "            writer = pd.ExcelWriter(saveexpath, engine='xlsxwriter')\n",
    "            dimerresp=pd.DataFrame({'dimer_greenscore':[0],'dimer_yellowscore':[0],'dimer_redscore':[0],'dimer_bluescore':[0],'dimer_luminosity':[0]})\n",
    "            targetresp=pd.DataFrame({'target_greenscore':[0],'target_yellowscore':[0],'target_redscore':[0],'target_bluescore':[0],'target_luminosity':[0]})\n",
    "            # Write each dataframe to a different worksheet.\n",
    "            dimerresp.to_excel(writer, sheet_name='DimerData')\n",
    "            targetresp.to_excel(writer, sheet_name='TargetData')\n",
    "        \n",
    "\n",
    "            # Close the Pandas Excel writer and output the Excel file.\n",
    "            writer.save()\n",
    "\n",
    "            response_thresh[j]=0\n",
    "                \n",
    "\n",
    "  \n",
    " \n",
    "    print(\"Finished analysis woohoo\")\n",
    "    #t.close()\n",
    "    \n",
    "    searchfolder_thresh=oneuppath_thresh\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_thresh= searchfolder_thresh+'\\\\'+\"Analysisfolder_thresholding\"\n",
    "    imagefilefolders=os.listdir(savedir_thresh)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    #print(dimercount_thresh)\n",
    "    \n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount_thresh),'target_picked':np.array(targetcount_thresh),'response': np.array(response_thresh)})\n",
    "    \n",
    "    responsepath_thresh=savedir_thresh+'\\\\'+\"responseforallimages.xlsx\"\n",
    "\n",
    "    responseforexcel.to_excel(responsepath_thresh) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb48401e-7175-4af4-bb99-592392dac016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dimer_greenscore  dimer_yellowscore  dimer_redscore  dimer_bluescore  \\\n",
      "0        -476.565661         354.313758     -668.243878       103.265301   \n",
      "1        -534.574183         306.018774     -627.495611       218.755479   \n",
      "2        -806.721712         522.577886     -989.324673       289.837042   \n",
      "3        -678.558772         417.293847     -945.260944       214.085922   \n",
      "4         -34.085658           6.168873      -38.735433         4.829647   \n",
      "..               ...                ...             ...              ...   \n",
      "75      -1816.280061         670.107833     -948.560950       999.018048   \n",
      "76       -328.047832        1501.323480     -658.154506      1150.091035   \n",
      "77       -324.454627         203.258698     -505.607075       -70.556697   \n",
      "78       1077.349829        1939.167705      729.414196      1290.150040   \n",
      "79      -2110.795143        1597.627197    -2300.918686       807.229607   \n",
      "\n",
      "    dimer_luminosity  type  \n",
      "0        1129.668300     1  \n",
      "1        1119.124439     1  \n",
      "2        1497.785195     1  \n",
      "3        1587.249598     1  \n",
      "4          71.708102     1  \n",
      "..               ...   ...  \n",
      "75       3610.764852     4  \n",
      "76       3019.624061     4  \n",
      "77       1970.377685     4  \n",
      "78       5695.773043     4  \n",
      "79       6523.237240     4  \n",
      "\n",
      "[80 rows x 6 columns]\n",
      "[[ -476.56566101   354.31375838  -668.24387815   103.26530139]\n",
      " [ -534.57418343   306.01877448  -627.49561149   218.75547856]\n",
      " [ -806.72171231   522.57788582  -989.32467285   289.83704178]\n",
      " [ -678.55877182   417.29384712  -945.26094357   214.08592241]\n",
      " [  -34.08565796     6.16887343   -38.73543318     4.82964701]\n",
      " [-2065.45252336  2168.80825621 -2477.8784385    901.13478685]\n",
      " [ -536.69550298   262.20117232  -699.62683269    41.06464895]\n",
      " [-1132.68423658   769.8470224  -1517.58201449   179.57115788]\n",
      " [ -708.21372423   516.06034406 -1027.75073081   171.9432666 ]\n",
      " [ -899.00727141   473.59386672  -962.1847218    286.36581389]\n",
      " [ -547.65638087   294.20460575  -686.32368215   101.81653997]\n",
      " [ -699.33346902   428.10216612  -780.24196097   194.22922315]\n",
      " [-1605.08905407  1347.42664589 -2151.98151372   489.5324876 ]\n",
      " [-1117.7683899    600.8542815  -1314.53885997   425.13558509]\n",
      " [-1478.84514065  1159.89716265 -1438.4609761    760.45901979]\n",
      " [ -608.02986178   304.07591307  -818.61277908   179.85664135]\n",
      " [-1256.83083214   777.42924307 -1456.89609806   365.41548784]\n",
      " [-1523.53190356   958.66780839 -1688.15941034   589.47038473]\n",
      " [ -729.40241373   323.52409223  -811.36806461   241.99316309]\n",
      " [ -809.35592753   431.0520659   -787.51344728   288.50207055]\n",
      " [-1249.67586726   587.83631642 -1344.46418149   421.27344171]\n",
      " [ -574.67956398   258.92682244  -705.76909193    69.44606792]\n",
      " [-1221.81183136   625.52423485 -1435.71280507   576.95643121]\n",
      " [ -696.04004566   431.68229396  -852.06280928   211.22972026]\n",
      " [ -745.64615752   530.54482564  -979.34162714   174.83556612]\n",
      " [ -660.01980218   463.84645053  -778.18470211    54.81857684]\n",
      " [ -915.62372643   677.75505711 -1114.61078391   211.16894373]\n",
      " [  326.70896501  1450.00611224  -180.50985189   975.40557136]\n",
      " [  124.39598771   167.22825594    39.00090957   158.3741581 ]\n",
      " [  147.17758752   310.58525799  -197.34480559   328.64347963]\n",
      " [ -201.14377382   621.70035195  -365.11933784   472.33543401]\n",
      " [ -225.61271559  1660.47057146  -649.8662489    664.6456126 ]\n",
      " [ -442.67396609  1747.68233585  -362.56708594  1339.54303157]\n",
      " [ -463.73271831  1089.42096564  -865.70475153   659.79387215]\n",
      " [ -342.40671783   930.00674326  -676.24717109   660.67196869]\n",
      " [ -695.3518285   1652.39629741 -1038.86132324   958.22547675]\n",
      " [-1120.93548283  2031.37314526 -1348.9967801   1525.03915365]\n",
      " [ -703.28037863  1552.71079354  -941.29547949  1044.07463694]\n",
      " [ -506.67724618  1099.83530933  -834.79461124   671.13392961]\n",
      " [ -316.10477528   628.19567236  -463.97638919   447.16052203]\n",
      " [ -256.73733568  1418.21343735  -704.50543959   979.06915775]\n",
      " [ -346.57062266   521.4643784   -473.81685154   325.61561061]\n",
      " [ -655.92319029   708.77564674  -887.09548414   441.73883908]\n",
      " [ -521.63444651   977.27672171  -755.80923715   614.76530517]\n",
      " [ -773.43254569  1587.52513774  -952.86311388  1093.21403761]\n",
      " [ -678.04098163  1180.1580254   -310.88155349  1108.61804375]\n",
      " [  -19.37246242   637.02440795  -268.89373481   365.38361272]\n",
      " [ -734.96188888  1328.83946092  -729.46077124  1183.65829008]\n",
      " [ -571.44016774  1408.05152488  -653.8939083   1002.21174179]\n",
      " [  131.9944973    979.3511803     22.02679144   683.90323539]\n",
      " [ -119.91087661  1149.31835248  -339.36884432   903.18405951]\n",
      " [-1413.57514541  1818.89181779 -1199.33270645  1310.52064829]\n",
      " [  -43.87220456   951.52617834  -230.4349093    685.67602499]\n",
      " [ -393.39915706  1296.86077111  -602.91896543   946.07505159]\n",
      " [ -225.85496999  1161.70667263  -768.69613751   636.68104323]\n",
      " [ -274.98002089  1017.5175837   -552.21842473   647.80785616]\n",
      " [-1095.31781559  1826.21205356 -1120.13125372  1325.8301661 ]\n",
      " [ -314.11966116  1228.45544499  -660.67260158   420.20487768]\n",
      " [ -335.97465197   791.97813501  -609.87449775   385.782793  ]\n",
      " [ -243.0894094   1496.13361953  -882.36473693   975.12924332]\n",
      " [ -458.98002529  1340.44263188 -1113.84340354   814.08576337]\n",
      " [ -125.20935779   478.40819556  -481.90059036   225.5446351 ]\n",
      " [ -363.66255862  1622.88423531  -547.37793274  1083.21322221]\n",
      " [-1040.46853754  2153.03062698 -1183.18754484  1674.78025252]\n",
      " [  118.53376149  1795.84079037    59.39496886  1416.64003351]\n",
      " [  152.52909303  1457.20443158   -27.34116362  1008.43362936]\n",
      " [  809.65450455  1512.41163268   232.47397555   877.34092584]\n",
      " [  601.05764849  1452.25217802   161.4219716    875.48131476]\n",
      " [ -206.34195236  1570.06981517  -412.24330514   829.88609896]\n",
      " [  807.44908925  2062.86042467    53.01462932   489.74770863]\n",
      " [-1394.12013879  1810.96213434 -1663.20936101  1358.46172482]\n",
      " [  183.59282638   777.03482393   -30.81145917   386.70498877]\n",
      " [ -248.42288367  1675.30962346  -503.62286941   957.77506297]\n",
      " [  947.58524452  1975.66162152   257.77013177  1354.69253398]\n",
      " [ 1667.12041463  1719.7673523   1202.51689554  1503.38251098]\n",
      " [-1816.28006115   670.10783292  -948.56095036   999.01804831]\n",
      " [ -328.04783165  1501.3234796   -658.15450611  1150.09103458]\n",
      " [ -324.45462719   203.25869816  -505.60707527   -70.55669683]\n",
      " [ 1077.34982876  1939.16770526   729.41419551  1290.15003988]\n",
      " [-2110.79514253  1597.62719684 -2300.91868627   807.22960728]]\n"
     ]
    }
   ],
   "source": [
    "excel_filename=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\SEMDarkfield\\SEM4\\corresponding DFM\\Analysisfolder_thresholding\\IMG_0132_s4.CR2\\Analysisimages_thresholding\\allscoresforknownSEM.xlsx\"\n",
    "data=pd.read_excel(excel_filename, sheet_name=\"LABClassifier\",engine='openpyxl')\n",
    "#print(data)\n",
    "from sklearn import svm\n",
    "gvec=np.array(data.dimer_greenscore).reshape(-1,1)\n",
    "yvec=np.array(data.dimer_yellowscore).reshape(-1,1)\n",
    "rvec=np.array(data.dimer_redscore).reshape(-1,1)\n",
    "bvec=np.array(data.dimer_bluescore).reshape(-1,1)\n",
    "y_vector=np.array(data.type).reshape(-1,1)\n",
    "xvec=np.dstack((gvec,yvec))\n",
    "xvec=np.dstack((xvec,rvec))\n",
    "xvec=np.dstack((xvec,bvec))\n",
    "xvec=xvec.reshape(-1,4)\n",
    "#print(xvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81754b9e-fcaa-495c-8078-8a8e19a54185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
