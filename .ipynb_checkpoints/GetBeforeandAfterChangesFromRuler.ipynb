{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392d8729-7d94-4c5a-be54-a9f7a5ee1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CHANGE THIS TO YOUR FOLDER##################\n",
    "##################################################\n",
    "bigfol=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\NewMicroscope\\Time_series\"\n",
    "##################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialise dependencies\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "from scipy import sparse\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "#import md5, sha\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "import imageio\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from PIL import Image,ImageEnhance,ImageFilter\n",
    "import PIL\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "#import hcluster\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from math import pow\n",
    "import scipy.signal \n",
    "%matplotlib qt\n",
    "#template matching\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.util import img_as_ubyte\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#General Functions\n",
    "def listdirs(folder):\n",
    "## a function which lists the files in a folder and adds to a list. returns a list of folders, \n",
    "##input folder: the file path to folder\n",
    "    return [\n",
    "        d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))\n",
    "        if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "def labcolourfilt(image):\n",
    "    #%matplotlib qt\n",
    "    img_lab = cv.cvtColor(image, cv.COLOR_RGB2Lab)\n",
    "    lower_l = np.array([140,0,0])\n",
    "    upper_l = np.array([255,255,255])\n",
    "    lab_l,lab_a,lab_b=cv.split(img_lab)\n",
    "    mask = cv.inRange(img_lab, lower_l, upper_l)\n",
    "    res = cv.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    #plt.imshow(res)\n",
    "    return res\n",
    "    \n",
    "\n",
    "def makeclippingmask(image):\n",
    "    \n",
    "\n",
    "    #makes a clipping mask around each bright spot so the analysis isn't thrown off\n",
    "    grayA = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    \n",
    "\n",
    "    #watershed thresholding. Based on: https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html\n",
    "    src = image.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    kernelcirc=cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    imgLaplacian = np.clip(imgLaplacian, 0, 255)\n",
    "    imgLaplacian = np.uint8(imgLaplacian)\n",
    "    #cv.imshow('Laplace Filtered Image', imgLaplacian)\n",
    "    #cv.imshow('New Sharped Image', imgResult)\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n",
    "    #_, bw = cv.threshold(grayA, 80, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #plt.imshow(bw)\n",
    "    blurred = cv.GaussianBlur(bw, (7,7), 0)\n",
    "    bw = cv.adaptiveThreshold(blurred, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 21, 2)\n",
    "    \n",
    "    #cv.imshow('Binary Image', bw)\n",
    "    \n",
    "    opening = cv.morphologyEx(bw,cv.MORPH_OPEN,kernelcirc, iterations = 1)\n",
    "    closing = cv.morphologyEx(opening,cv.MORPH_CLOSE,kernelcirc, iterations = 4)\n",
    "    #kernel1 = np.ones((5,5),np.uint8)\n",
    "    #erosion = cv.erode(closing,kernel1,iterations = 1)\n",
    "   \n",
    "    contours,hierarchy = cv.findContours(closing.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "    cnt = contours\n",
    "\n",
    "    contour_list = []\n",
    "    img=image.copy()\n",
    "    mask2 = np.zeros(image.shape[:2], dtype= np.uint8)\n",
    "    for contour in contours:\n",
    "        (x,y),radius = cv.minEnclosingCircle(contour)\n",
    "        center = (int(x),int(y))\n",
    "        radius = int(radius)\n",
    "        approx = cv.approxPolyDP(contour,0.01*cv.arcLength(contour,True),True)\n",
    "        area = cv.contourArea(contour)\n",
    "        if radius>4:\n",
    "            # Filter based on length and area\n",
    "            contour_list.append(contour)\n",
    "    cv.fillPoly(mask2, pts =contour_list, color=[255])\n",
    "\n",
    "    #cv.drawContours(image, contour_list,  -1, (255,0,0), 2)\n",
    "    #cv.imshow('Objects Detected',img)\n",
    "    #cv.waitKey(5000)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #mask2[bw >0] = [255]\n",
    "    \n",
    "    #colours=((255,255,255))\n",
    "    # Fill labeled objects with random colors\n",
    "    #for i in range(markers.shape[0]):\n",
    "    #    for j in range(markers.shape[1]):\n",
    "    #        index = markers[i,j]\n",
    "    #        if index>0:\n",
    "    #            mask2[i,j] = 255\n",
    "    \n",
    "\n",
    "    image_rgb=image.copy()\n",
    "    image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    #print(contour_list)\n",
    "    %matplotlib qt\n",
    "    plt.imshow(image_blocked)\n",
    "    \n",
    "    #plt.imshow(image_blocked)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_auto_wb=True,\n",
    "                                #user_wb=[1.5,1.0,1.0,1.0],\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1),\n",
    "                              bright=1.0,\n",
    "                              dcb_enhance=True)\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        \n",
    "def saveexcelfun(dimercoord,corecoord,savepath):\n",
    "#Save the coordinates of everything to an excel spreadsheet. Yeah I know it's ugly. \n",
    "#input: dimercoord- the dimer coordinates\n",
    "########corecoord- the core coordinates \n",
    "########savepath- the folder location where the files will be saved \n",
    "    columns=['Before Dimers xval']\n",
    "    saveexcel=savepath+\".\"+\"xlsx\"\n",
    "    beforedimercentres = pd.DataFrame({'Before Dimers xval':dimercoord})\n",
    "    try:\n",
    "        aftercorecentres = pd.DataFrame({'After core xval': corecoord})\n",
    "    except:\n",
    "        aftercorecentres=pd.DataFrame({'After core xval': np.array([0]), \n",
    "                                'After core yval': np.array([0])})\n",
    "\n",
    "   \n",
    "    writer = pd.ExcelWriter(saveexcel,engine='xlsxwriter')\n",
    "    workbook=writer.book\n",
    "    worksheet=workbook.add_worksheet('DimersPicked')\n",
    "    writer.sheets['DimersPicked'] = worksheet\n",
    "    worksheet2=workbook.add_worksheet('CoresPicked')\n",
    "    writer.sheets['CoresPicked'] = worksheet2\n",
    "\n",
    "\n",
    "    beforedimercentres.to_excel(writer,sheet_name='DimersPicked',startrow=1 , startcol=0)\n",
    "    #worksheet.write_string(beforedimercentres.shape[0] + 4, 0, beforedimercentres.name)\n",
    "\n",
    "    aftercorecentres.to_excel(writer,sheet_name='CoresPicked',startrow=1, startcol=3)\n",
    "    \n",
    "\n",
    "    writer.save()\n",
    "def savetextfilefun(data,savepath,datastring):\n",
    "##### A function which saves an array to a text file. Is a little buggy in that sometimes there's weird spaces. \n",
    "##### reccomend the excel save functions instead. Python struggles to re-read these text tiles\n",
    "\n",
    "    savetextstring=savepath+datastring+\".txt\"\n",
    "    file = open(savetextstring,\"w\")\n",
    "    for dataentry in data:\n",
    "        arr_of_strings = np.array2string(dataentry)\n",
    "        file.write(arr_of_strings) \n",
    "    file.close() \n",
    "    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "## A function which reads in images and adds them to a list of images.\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "## note !! The images wil be read in with open cv, and will be in BGR format and will look strange unless converted\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "def load_images_from_foldercv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to RGB\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "       \n",
    "        if img is not None:\n",
    "            img= cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "def load_images_from_folderhsv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to HSV\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        img= cv.cvtColor(img,  cv.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#####################################################\n",
    "###################################################\n",
    "#Template matching functions\n",
    "\n",
    "\n",
    "def findidealimagescale(image,template):\n",
    "    # loop over the images to find the template in\n",
    "   \n",
    "        # load the image, convert it to grayscale, and initialize the\n",
    "        # bookkeeping variable to keep track of the matched region\n",
    "        \n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    template=cv.cvtColor(template, cv.COLOR_HSV2RGB)\n",
    "    template=cv.cvtColor(template, cv.COLOR_RGB2GRAY)\n",
    "    #template.astype(np.uint8)\n",
    "    #gray.astype(np.uint8)\n",
    "    found = None\n",
    "    scalefin= None\n",
    "    (h, w) = template.shape[:2]\n",
    "    i=0\n",
    "    # loop over the scales of the image\n",
    "    for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "        # resize the image according to the scale, and keep track\n",
    "        # of the ratio of the resizing\n",
    "        resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "        r = gray.shape[1] / float(resized.shape[1])\n",
    "        # if the resized image is smaller than the template, then break\n",
    "        # from the loop\n",
    "        if resized.shape[0] < h or resized.shape[1] < w:\n",
    "            break\n",
    "        result = cv.matchTemplate(gray, template, cv.TM_SQDIFF_NORMED)\n",
    "        (minval, _, minloc, _) = cv.minMaxLoc(result)\n",
    "        if found is None or minval < found:\n",
    "            found = minval\n",
    "            scalefin=scale\n",
    "    return scalefin \n",
    "        \n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "        \n",
    "def nonmaxsuppression(xCoords,yCoords,template):\n",
    "    center_coordinates=[]\n",
    "    rects=[]\n",
    "    rectangle_coordinates=[]\n",
    "    (w, h) = template.shape[:2]\n",
    "    #print(w)\n",
    "    #print(h)\n",
    "## stops the overcounting of variables with nonmax suppression and returns an updated list\n",
    "    for (x, y) in zip(xCoords, yCoords):\n",
    "    # update our list of rectangles\n",
    "        rects.append((x, y, x +w, y + h))\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        center_coordinates.append((startX+h//2,startY+h//2))\n",
    "        rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "     \n",
    "    #print(\"center coordinates are \",center_coordinates)\n",
    "    #print(\"rectangle_coordinates are \", rectangle_coordinates)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithm(img_hsv,template, method,threshold):\n",
    "# defines the template matching algorithm and finds the minimum locations\n",
    "#inputs: img_rgb- the image to be matched in HSV format\n",
    "#########template- the template to be matched in HSV format\n",
    "#########method- the method of determining the minim. cv.TM_SQDIFF_NORMED is good for colour\n",
    "##### extras found here: https://docs.opencv.org/master/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d\n",
    "#########threshold: the threshold where the minimum is defined. Variable. May want to do something with min_val and max\n",
    "#outputs: locations_of_minimum- a really big array that needs to be zipped. \n",
    "#Note: this works on colour (3 d) images but may want to change to just hue\n",
    "    img_hsv = cv.cvtColor(img_hsv, cv.COLOR_HSV2BGR)\n",
    "    img_hsv = cv.cvtColor(img_hsv, cv.COLOR_BGR2Lab)\n",
    "    _,img_hsv_a,img_hsv_b=cv.split(img_hsv)\n",
    "    template = cv.cvtColor(template, cv.COLOR_HSV2BGR)\n",
    "    template = cv.cvtColor(template, cv.COLOR_BGR2Lab)\n",
    "    _,template_a,template_b=cv.split(template)\n",
    "    \n",
    "    mat_of_matching_results_a=cv.matchTemplate(img_hsv_a,template_a,method)\n",
    "    mat_of_matching_results_b=cv.matchTemplate(img_hsv_b,template_b,method)\n",
    "    \n",
    "    #This is to get some details about the minimum but isn't actually used\n",
    "    #print(\"template matching done\")\n",
    "    (min_val_a, max_val_a, _, max_loc_a) = cv.minMaxLoc(mat_of_matching_results_a)\n",
    "    (min_val_b, max_val_b, _, max_loc_b) = cv.minMaxLoc(mat_of_matching_results_b)\n",
    "    \n",
    "    #print(\"The min is done\")\n",
    "    #print(min_val)\n",
    "    #print(max_val_a)\n",
    "    if max_val_a>threshold:\n",
    "        #threshold=0.6\n",
    "        (yCoords, xCoords) = np.where(np.logical_and(mat_of_matching_results_a >= threshold, mat_of_matching_results_b>=threshold))\n",
    "        while (len(xCoords))>2500000:\n",
    "            threshold=threshold+0.1\n",
    "            #print(threshold)\n",
    "            (yCoords, xCoords) = np.where(np.logical_and(mat_of_matching_results_a >= threshold, mat_of_matching_results_b>=threshold))\n",
    "            \n",
    "    \n",
    "        center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template_a)\n",
    "    else:\n",
    "        center_coordinates=[[0,0]]\n",
    "        rectangle_coordinates=[[0,0,0,0]]\n",
    "        w=0.00001\n",
    "        h=0.00001\n",
    "    \n",
    "    #print(locations_of_minimum)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def imagetempmatch(imgpath,img_rgb,threshold,clumpflag):\n",
    "## performs the template matching function on each template image found in imgpath\n",
    "## input: imgpath: a string pointing to the folder the template images are contained in\n",
    "##########img_rgb: the image to be matched, in rgb format \n",
    "##########threshold: the threshold at which the minimum is accepted. The minimum value is the value where the \n",
    "#####################template matching function thinks that the image is matched. Note, this may be a maximum \n",
    "####################for other methods\n",
    "    #loads the template images in as HSV\n",
    "    images=load_images_from_folderhsv(imgpath)\n",
    "    center_list=[]\n",
    "    rectangle_list=[]\n",
    "    r_list=[]\n",
    "    #Creates a mask which has the shape of the image to be matched. The dtype is important or error will occur. \n",
    "    # This mask is to test whether the template matching has counted the same point multiple times\n",
    "    mask = np.zeros(img_rgb.shape, dtype=np.uint8)\n",
    "    res=[];\n",
    "    if clumpflag==1:\n",
    "        scale=findidealimagescale(img_rgb,images[0])\n",
    "    else:\n",
    "        scale=1\n",
    "    #print(scale)\n",
    "    resized = imutils.resize(img_rgb, width = int(img_rgb.shape[1]*scale))\n",
    "    for template in tqdm(images):\n",
    "        #for each template, the width and height is taken\n",
    "        if clumpflag==1:\n",
    "            scale=findidealimagescale(img_rgb,template)\n",
    "        else:\n",
    "            scale=1\n",
    "        #print(scale)\n",
    "        resized = imutils.resize(img_rgb, width = int(img_rgb.shape[1]*scale))\n",
    "\n",
    "        w=16\n",
    "        h=16\n",
    "        \n",
    "        \n",
    "        #big image converted to hsv format\n",
    "        img_hsv= cv.cvtColor(resized,  cv.COLOR_RGB2HSV)\n",
    "        #the location minima identified with the template matching algorithm\n",
    "        center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithm(img_hsv,template,cv.TM_CCOEFF_NORMED,threshold)\n",
    "        center_list.extend(center_coordinates)\n",
    "        rectangle_list.extend(rectangle_coordinates)\n",
    "        r_list.append(w)\n",
    "        \n",
    "        #print(center_coordinates)\n",
    "        \n",
    "        #print(\"locations of min are\", locations_of_min)\n",
    "        # the locations are checked for multiple counting of the same point. \n",
    "        #particle_count=checkfordoublecounting(img_hsv,locations_of_min)\n",
    "        #print(particle_count)\n",
    "    #print(np.array(center_list))\n",
    "    return np.array(center_list),np.array(rectangle_list),np.max(np.array(r_list)),h\n",
    "\n",
    "\n",
    "def blockimagecombo(image_rgb, points,r,bok):\n",
    "    #print(points)\n",
    "    if bok==1:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,255), -1)\n",
    "    else:\n",
    "        mask2 = np.zeros(image_rgb.shape[:2], dtype= np.uint8)\n",
    "        for pt in points: \n",
    "            #print(pt)\n",
    "            mask2 = cv.circle(mask2,pt,r, (255,255,255), -1)\n",
    "            \n",
    "            # a rectangle is drawn on the mask, which marks where the points are \n",
    "        #invmask=255-mask2\n",
    "        #This is an inbuilt cv function which clips the image around the mask. \n",
    "        #plt.imshow(cv.bitwise_and(image_rgb, image_rgb, mask=invmask))\n",
    "        image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "def performtemplatematching(image_rgb,imgpath,bok,threshold,clumpflag):\n",
    "## a function which performs template matching on the images and blocks them depending on whether\n",
    "## we want to keep the particles or block them out for more accuracy \n",
    "#input: image_rgb: the big image in rgb format where we are looking for matches\n",
    "########imgpath: the path to the template images, as a string\n",
    "#########bok: block or keep. 0 is for keeping, 1 is for blocking with a rectange\n",
    "#########threshold: the threshold for the minimum values. Variable. \n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=imagetempmatch(imgpath,image_rgb,threshold,clumpflag)\n",
    "    r=round(w/1.5)\n",
    "\n",
    "    correctedimg=blockimagecombo(image_rgb,center_coordinates ,r,bok)\n",
    "    return correctedimg,center_coordinates,r\n",
    "\n",
    "def performsaveimage(image,path):\n",
    "## saves image using pillow, which is a lot faster than matplot lib. \n",
    "    img_rgb_corr=image\n",
    "    try:\n",
    "        im_pil = Image.fromarray(img_rgb_corr)\n",
    "        im_pil.save(path, compress_level=1)\n",
    "    except:\n",
    "        exception=1\n",
    "\n",
    "def savetotrainingfol(foldername,image,points):\n",
    "## saves the cropped images to a folder, for use in machine learning. uses a 16 pixel box.\n",
    "#input: foldername: name of the folder where you want the images stored\n",
    "#######image: an image in rgb format which you want to cut up\n",
    "########points: the coordinates of the particles which you have selected. \n",
    "    boxwid=round(16/2)\n",
    "    w=16\n",
    "    for j,pt in enumerate(points):\n",
    "        savepathfol= addstringwithtime(foldername +'\\\\')\n",
    "        savepath= savepathfol+str(j)+\"registeredimg\" + \".\" + \"png\"\n",
    "        #savepath=os.path.join(savepathfol, str(j)+\"registeredimg\" + \".\" + \"png\")\n",
    "        lilimage=image[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        performsaveimage(lilimage,savepath)\n",
    "        \n",
    "def blockoutunwantedparticles(analpath,sat_img,path,threshold,clumpflag):\n",
    "## a function which blocks out that particles which are interfering with analysis i.e. clumps and clusters\n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#output: correctedimgcore, the corrected image after accounting for cores and clumps\n",
    "# These images are hardcoded into a folder, so the code has some dependencies. But any exmaples of the correct size will do\n",
    "    #The threshold of 0.25 seems to be highly variable\n",
    "    correctedimg,_,r= performtemplatematching(sat_img, path,1,threshold,clumpflag)\n",
    "    #plt.imshow(correctedimg)\n",
    "    #print(r)\n",
    "    return correctedimg,r\n",
    "\n",
    "\n",
    "def unwantedparticleblocking(analpath,sat_img):\n",
    "    #clusterpath=  r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\Cluster\"\n",
    "    #threshold= 0.25\n",
    "    #correctedimgcluster=blockoutunwantedparticles(analpath,sat_img,clusterpath,threshold)\n",
    "    \n",
    "    clumppath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\clump\"\n",
    "    threshold=0.55\n",
    "    savepath=os.path.join(analpath, \"clumpcorrectedimg\" + \".\" + \"png\")\n",
    "    correctedimgclump,r=blockoutunwantedparticles(analpath,sat_img,clumppath,threshold,0)\n",
    "    performsaveimage(correctedimgclump,savepath)\n",
    "    \n",
    "    corepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\core2\"\n",
    "    threshold=0.55\n",
    "    correctedimgcore,r=blockoutunwantedparticles(analpath,correctedimgclump,corepath,threshold,1)\n",
    "    savepath=os.path.join(analpath, \"corecorrectedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgcore,savepath)\n",
    "    \n",
    "    return correctedimgcore,r\n",
    "    \n",
    "def keepmatchedparticles(path,image,threshold):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "    correctedimgdimer,pointsdimer,r= performtemplatematching(image, path, 0, threshold,1)\n",
    "    \n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "                                                              \n",
    "\n",
    "def performkeepmatchedparticles(analpath,image):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "#outputs: the selected image and the dimer points selected\n",
    "    dimerpath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\dimer2\"\n",
    "    threshold=0.55\n",
    "    \n",
    "    correctedimgdimer,pointsdimer,r=keepmatchedparticles(dimerpath,image,threshold)\n",
    "    savepath=os.path.join(analpath, \"pickeddimersimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgdimer,savepath)\n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "\n",
    "\n",
    "\n",
    "def getaveragevalueshsv(image,points,w,h,analpath):\n",
    "# a function to get the average values of the image in rgb format\n",
    "#inputs: image: the hsv image\n",
    "#########points: the selected dimer values\n",
    "#########w,h- the width and height in pixels\n",
    "#########analpath: the path to the analysis folder\n",
    "#outputs: an array of the average colour of the red divided by the green vector\n",
    "\n",
    "    average_colour_rDivg=[]\n",
    "    #converts the image to hsv\n",
    "    image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_rDivg)), \" min is \",np.min(np.array(average_colour_rDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_rDivg)), \"median is \", np.mean(np.array(average_colour_rDivg)) )\n",
    "    print(\"standard deviation is \", np.mean(np.array(average_colour_rDivg)))\n",
    "    return np.array(average_colour_rDivg)\n",
    "def makeLabvectorspretty(l_vec,a_vec,b_vec):\n",
    "    #l_vec = l_vec.ravel()\n",
    "    lnoz=np.nonzero(l_vec)\n",
    "    l_vecf=l_vec[lnoz]\n",
    "    #a_vec = a_vec.ravel()\n",
    "    #a_vec.sort()\n",
    "    anoz=np.nonzero(a_vec)\n",
    "    a_vecf=a_vec[anoz]\n",
    "    #b_vec = b_vec.ravel()\n",
    "    bnoz=np.nonzero(b_vec)\n",
    "    b_vecf=b_vec[bnoz]\n",
    "    return l_vecf.reshape((1,-1)),a_vecf.reshape((1,-1)),b_vecf.reshape((1,-1))\n",
    "\n",
    "def makelinspacevector(vector):\n",
    "    max_vec=np.max(vector)\n",
    "    min_vec=np.min(vector)\n",
    "    #print(vector.shape)\n",
    "    xshape,yshape=vector.shape\n",
    "    \n",
    "    #print(yshape)\n",
    "    lin_vec = np.linspace(min_vec, max_vec,num=yshape)\n",
    "    return lin_vec\n",
    "    \n",
    "def getkdepeaksLAB(l_vec,a_vec,b_vec):\n",
    "    l_vec,a_vec,b_vec=makeLabvectorspretty(l_vec,a_vec,b_vec)\n",
    "    kde = KernelDensity(kernel=\"gaussian\", bandwidth=3)\n",
    "    \n",
    "    kde.fit(l_vec.reshape(-1,1))\n",
    "    x_d=makelinspacevector(l_vec)\n",
    "\n",
    "    %matplotlib qt\n",
    "    #log_dens = kde.score_samples(l_vec)\n",
    "    log_dens = kde.score_samples(x_d.reshape(-1,1))\n",
    "    plt.figure()\n",
    "    #plt.fill((l_vec).reshape(-1,1), np.exp(log_dens).reshape(-1,1), c='cyan')\n",
    "    plt.hist(l_vec, bins = 50)\n",
    "    plt.plot(x_d,log_dens)\n",
    "    plt.show()\n",
    "    print(log_dens)\n",
    "    yes=here\n",
    "    # score_samples returns the log of the probability density\n",
    "    #logprob = kde.score_samples(x_d[:, None])\n",
    "\n",
    "\n",
    "def gethistogrampeaksLAB(l_vec,a_vec,b_vec):\n",
    "    #print(l_vec.shape)\n",
    "    l_vec = l_vec.ravel()\n",
    "    lnoz=np.nonzero(l_vec)\n",
    "    l_vecf=l_vec[lnoz]\n",
    "    a_vec = a_vec.ravel()\n",
    "    #a_vec.sort()\n",
    "    anoz=np.nonzero(a_vec)\n",
    "    a_vecf=a_vec[anoz]\n",
    "    b_vec = b_vec.ravel()\n",
    "    bnoz=np.nonzero(b_vec)\n",
    "    b_vecf=b_vec[bnoz]\n",
    "    #b_vec.sort()\n",
    "   # %matplotlib qt\n",
    "    plt.figure()\n",
    "    ax1=sns.kdeplot(l_vecf)\n",
    "    #plt.show()\n",
    "    try:\n",
    "        x_l = ax1.lines[0].get_xdata() # Get the x data of the distribution\n",
    "        y_l = ax1.lines[0].get_ydata() # Get the y data of the distribution\n",
    "        peak_l = np.argmax(y_l) # The id of the peak (maximum of y data)\n",
    "        plt.close()\n",
    "        plt.figure()\n",
    "        ax2=sns.kdeplot(a_vecf)\n",
    "    except:\n",
    "        x_1=[0]\n",
    "        y_1=[0]\n",
    "    #plt.show()\n",
    "    x_a = ax2.lines[0].get_xdata() # Get the x data of the distribution\n",
    "    y_a = ax2.lines[0].get_ydata() # Get the y data of the distribution\n",
    "    peak_a = np.argmax(y_a) # The id of the peak (maximum of y data)\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    ax3=sns.kdeplot(b_vecf)\n",
    "#plt.show()\n",
    "    x_b = ax3.lines[0].get_xdata() # Get the x data of the distribution\n",
    "    y_b = ax3.lines[0].get_ydata() # Get the y data of the distribution\n",
    "    maxid = np.argmax(y_b) # The id of the peak (maximum of y data)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    #plt.plot(x[maxid],y[maxid], 'bo', ms=10)\n",
    "    #plt.show()\n",
    "    peaks_l, _ = find_peaks(y_l)\n",
    "    peaks_l\n",
    "    peaks_b, _ = find_peaks(y_b)\n",
    "    peaks_a, _ = find_peaks(y_a)\n",
    "    \n",
    "    #print(peaks_l)\n",
    "    #print(peaks_b)\n",
    "    #print(peaks_a)\n",
    "    #plt.figure()\n",
    "    #plt.plot(y_a)\n",
    "    #plt.plot(peaks_a, y_a[peaks_a], \"x\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #yes=here\n",
    "    return peaks_l,peaks_a,peaks_b,y_l,y_a,y_b\n",
    "\n",
    "def getaveragevaluesLAB(image,points,analpath,yespeaks):\n",
    "    w=16\n",
    "    labim = rgb2lab(image)\n",
    "    l_vec,a_vec,b_vec = cv.split(labim)\n",
    "    average_colour_aDivg=[]\n",
    "    max_val_lDivg=[]\n",
    "    average_lum=[]\n",
    "    average_comp_a_to_b=[]\n",
    "    info_l=[]\n",
    "    info_a=[]\n",
    "    info_b=[]\n",
    "    #converts the image to hsv\n",
    "    #image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    #image_hue=np.true_divide(image[:,:,0], image[:,:,1], where=(image[:,:,0]!=0) | (image[:,:,1]!=0))\n",
    "    #image_hue=image[:,:,0]\n",
    "    \n",
    "    \n",
    "    for i,pt in enumerate(points):           \n",
    "\n",
    "        crop_im_b=b_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        dividedval_b=crop_im_b.reshape((1,-1))\n",
    "        \n",
    "        crop_im=a_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        dividedval=crop_im.reshape((1,-1))\n",
    "        \n",
    "        crop_im_lval=l_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        dividedval_lval=crop_im_lval.reshape((1,-1))\n",
    "        #print(dividedval)\n",
    "        if yespeaks==1:\n",
    "            #peaks_l,peaks_a,peaks_b,y_l,y_a,y_b=gethistogrampeaksLAB(dividedval_lval,dividedval,dividedval_b)\n",
    "            peaks_l,peaks_a,peaks_b,y_l,y_a,y_b=getkdepeaksLAB(dividedval_lval,dividedval,dividedval_b)\n",
    "        else:\n",
    "            peaks_l=[0]\n",
    "            peaks_a=[0]\n",
    "            peaks_b=[0]\n",
    "        info_l.append(peaks_l)\n",
    "        info_a.append(peaks_a)\n",
    "        info_b.append(peaks_b)\n",
    "        \n",
    "        try:\n",
    "            average_comp_a_to_b.append(np.mean(dividedval)/np.mean(dividedval_b))\n",
    "        except:\n",
    "             average_comp_a_to_b.append(0.1)\n",
    "        try:\n",
    "            max_val_lDivg.append(np.max(dividedval_lval))\n",
    "        except:\n",
    "            max_val_lDivg.append(0.1)\n",
    "        try:\n",
    "            average_lum.append(np.mean(dividedval_lval))\n",
    "            #print(np.mean(dividedval_lval))\n",
    "        except:\n",
    "            average_lum.append(0.1)\n",
    "            #print('skipped')\n",
    "            \n",
    "        try:\n",
    "            average_colour_aDivg.append(np.mean(dividedval))\n",
    "        except:\n",
    "            average_colour_aDivg.append(0.1)\n",
    "            \n",
    "    #if not average_colour_aDivg:\n",
    "    #    average_colour_aDivg=[0]\n",
    "    return np.array(average_colour_aDivg),np.array(average_lum),np.array(max_val_lDivg),np.array(average_comp_a_to_b),info_l,info_a,info_b\n",
    "        #yield zippered\n",
    "    print(\"max is \",np.max(np.array(average_colour_aDivg)), \" min is \",np.min(np.array(average_colour_aDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_aDivg)), \"median is \", np.median(np.array(average_colour_aDivg)) )\n",
    "    print(\"standard deviation is \", np.std(np.array(average_colour_aDivg)))\n",
    "    #print(len(average_colour_aDivg))\n",
    "    #print(len(average_lum))\n",
    "    #print(len((max_val_lDivg)))\n",
    "    \n",
    "\n",
    "def averagehistogramshift(correctedimgdimer,pointsdimer,correctedimgtarget,threshold,analpath):\n",
    "# a function which uses the average shift of the particle colour (either hue or rgb depending ) to \n",
    "#select the particles which have shifted in the after image \n",
    "#inputs: correctedimgdimer: the image with only dimers selected\n",
    "#########pointsdimer: the locations of the dimers in the image\n",
    "#########correctedimgtarget: the registered image after target added wherein the coordinates of the selected\n",
    "# dimers have been used to clip it\n",
    "#########threshold: the values which the shifted average value must be above or below. was 0.2 \n",
    "#output: loc- the shifted selected particles. \n",
    "    avdim,ldim,maxldim,bdim,info_l,info_a,info_b=getaveragevaluesLAB(correctedimgdimer,pointsdimer,analpath,0)\n",
    "    \n",
    "    avcore,lcore,maxlcore,bdim,info_l,info_a,info_b=getaveragevaluesLAB(correctedimgtarget,pointsdimer,analpath,0)\n",
    "    minus= np.array(avdim)-np.array(avcore)\n",
    "    minus_l=np.array(ldim)-np.array(lcore)\n",
    "    \n",
    "    print(\"minus values here ------------\")\n",
    "    print(\"max value is \", np.max(minus), \"min value is \", np.min(minus), \" mean value is \", np.mean(minus))\n",
    "    print(\" median value is \", np.median(minus), \" standard deviation is \", np.std(minus))\n",
    "    loc=np.array(pointsdimer)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    ldim2=ldim[np.logical_and(minus>5,maxlcore>1)]\n",
    "    loc=loc[ldim2<30]\n",
    "    r=8\n",
    "    #loc=np.array(pointsdimer)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    targetpicked= blockimagecombo(correctedimgtarget,loc,r,0)\n",
    "    #average_values=np.array(minus)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    average_values=np.array(minus)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    #print(minus)\n",
    "    #average_values=average_values[ldim2<30]\n",
    "    #print(ldim2)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"tarmaskedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(targetpicked,savepath)\n",
    "    return loc,average_values.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def performtemplatetrainingonimages(transtarimg,analpath,sat_img):\n",
    "    \n",
    "\n",
    "    #blocks unwated particles\n",
    "    correctedimgcore,r=unwantedparticleblocking(analpath,sat_img)\n",
    "    \n",
    "    \n",
    "    #selects dimers\n",
    "    correctedimgdimer,pointsdimer,r=performkeepmatchedparticles(analpath, correctedimgcore)\n",
    "    image_circle=blockimagecombo(sat_img, pointsdimer,16,2)\n",
    "    savepath=os.path.join(analpath, \"dimerCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #print(np.unique(np.array(pointsdimer),axis=0))\n",
    "    #pointsdimer_corrected=np.unique(np.array(pointsdimer),axis=0)\n",
    "    pointsdimer_corrected=pointsdimer\n",
    "    #uses those points to select the same points in the target image \n",
    "    \n",
    "    transtarimg=makeclippingmask(transtarimg)\n",
    "    correctedimgtarget=blockimagecombo(transtarimg,pointsdimer_corrected,r,0)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgtarget,savepath)\n",
    "    \n",
    "    #scans the before and after dimers to determine if the particles shift in hue\n",
    "    threshold=-0.001\n",
    "    selected_target_locations,average_values=averagehistogramshift(correctedimgdimer,pointsdimer_corrected,correctedimgtarget,threshold,analpath)\n",
    "    image_circle=blockimagecombo(transtarimg, selected_target_locations,16,2)\n",
    "    savepath=os.path.join(analpath, \"targetCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #comment out if don't want\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\before\",sat_img,pointsdimer_corrected)\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\after\",transtarimg,selected_target_locations)\n",
    "    \n",
    "    return selected_target_locations,pointsdimer_corrected,average_values\n",
    "\n",
    "\n",
    "######### Extra functions\n",
    "\n",
    "def getindividualfoldersandsuch(bigfol):\n",
    "# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\n",
    "    topfolders=listdirs(bigfol)\n",
    "    subfolders=[0]\n",
    "    for nextfolders in topfolders:\n",
    "        subfolders= subfolders+ listdirs(nextfolders)\n",
    "    subfolders.pop(0)\n",
    "    #print(subfolders)\n",
    "    subfolders=np.array(subfolders).reshape(-1,1)\n",
    "    #print(subfolders)\n",
    "    return subfolders\n",
    "def searchforsatandtargetfolders(folder):\n",
    "#finds the satellite and targetfolders using regexp\n",
    "    subfolders2 = folder.tolist()\n",
    "    subfolders3=str(subfolders2).replace('[','').replace(']','').replace('\\\\\\\\','\\\\')\n",
    "\n",
    "    listexpfolders=listdirs(subfolders3[1:len(subfolders3)-1])\n",
    "    beforefol = [x for x in listexpfolders if re.search(\"satellite\",x)]\n",
    "    beforefol=beforefol[0]\n",
    "    afterfol= [x for x in listexpfolders if re.search(\"target\",x)]\n",
    "    afterfol=afterfol[0]\n",
    "    \n",
    "    return beforefol,afterfol\n",
    "\n",
    "def createanalysisfolder(beforefol,string):\n",
    "#creates an analysis folder in the address above where the satellite and target folders are located.\n",
    "    oneuppath=os.path.dirname(beforefol)\n",
    "    analysisfolderpath=oneuppath+\"\\\\\"+string\n",
    "    try:\n",
    "        os.mkdir(analysisfolderpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    print(analysisfolderpath)\n",
    "    print(\"processing images\")\n",
    "    return analysisfolderpath,oneuppath\n",
    "\n",
    "def createimagesubfolderforsaving(pathtomatch,analysisfolderpath):\n",
    "# creates a folder with the name of the image in the analysis folder \n",
    "    pathtomatch=beforeimfile[j]\n",
    "    matchingsearch=re.search(\"IMG_.*.CR2\",pathtomatch)\n",
    "    savefilespath=analysisfolderpath+\"\\\\\"+matchingsearch.group()+\"\\\\\"\n",
    "    try: \n",
    "        os.mkdir(savefilespath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    return savefilespath\n",
    "def addstringwithtime(savefilespath):\n",
    "# adds the current date and time so there's no saving over the top of different analysis\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    savepath=savefilespath+dt_string\n",
    "    return savepath\n",
    "def makeanalysisfolder(savefilespath,string):\n",
    "# makes a directory in the folder which matches the image name which says 'analysis'\n",
    "    analpath=os.path.join(savefilespath,string)\n",
    "                        #saves the registered image\n",
    "    try: \n",
    "        os.mkdir(analpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    return analpath\n",
    "\n",
    "################ THRESHOLDING\n",
    "def gethuevaluesthreshHSV(image,points):\n",
    "    image_hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    image_hue=image_hsv[:,:,0]\n",
    "    w=8\n",
    "    average_colour_rDivg=[]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getcentroidsandcenters(image):\n",
    "    h=8\n",
    "    src=image.copy()\n",
    "    bw = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    #_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    contours, hierarchy = cv.findContours(bw, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    list_of_centres=[]\n",
    "    boundRect = [None]*len(contours)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    \n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        center_circle, _ = cv.minEnclosingCircle(contours_poly[i])\n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(boundRect),0.5) \n",
    "   \n",
    "    #picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        list_of_centres.append((startX+h//2,startY+h//2))\n",
    "        #rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "    #list_of_centres.append((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "    for centers in list_of_centres:\n",
    "        cv.circle(src, ((np.int(np.round(centers[0])),np.int(np.round(centers[1])))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "    #%matplotlib qt\n",
    "    #plt.imshow(src)\n",
    "    #stophere=yep\n",
    "        \n",
    "    return list_of_centres\n",
    "\n",
    "\n",
    "def performthresholding(beforeim,afterim,analpath):\n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    #bef_obj=getaveragevaluesLAB(beforeim,list_of_centres,analpath,0)\n",
    "    #obj=list(bef_obj)\n",
    "    #print(obj)\n",
    "        \n",
    "    average_colour_a,average_l,max_l,comp_c,info_l1,info_a1,info_b1=getaveragevaluesLAB(beforeim,list_of_centres,analpath,0)\n",
    "    dimer_points=np.array(list_of_centres)[np.logical_and(average_colour_a<0,comp_c<0)]\n",
    "    #dimer_points=np.array(list_of_centres)[average_colour_a<20]\n",
    "    #dimer_points= np.array(list_of_centres)[average_colour >= 100]\n",
    "    average_colour_d,average_l,max_l,comp_a,info_l2,info_a2,info_b2=getaveragevaluesLAB(beforeim,dimer_points,analpath,1)\n",
    "   \n",
    "    \n",
    "    dimers_blocked=blockimagecombo(beforeim, dimer_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"corespicked\" + \".\" + \"png\")\n",
    "    performsaveimage(dimers_blocked,savepath)\n",
    "    \n",
    "    target_image=blockimagecombo(afterim, dimer_points,8,0)\n",
    "    savepath=os.path.join(analpath, \"samecoresinafter\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image,savepath)\n",
    "    \n",
    "    average_colour_after_a,average_l_a,max_l_a,comp_b,info_l3,info_a3,info_b3=getaveragevaluesLAB(target_image,dimer_points,analpath,1)\n",
    "    minus=average_colour_d-average_colour_after_a\n",
    "    minus_comp=comp_a-comp_b\n",
    "    #minus_l=max_l-max_l_a\n",
    "    target_points1=np.array(dimer_points)[np.logical_and(average_colour_after_a<0,comp_b<-1)]\n",
    "    minus_comp1=np.array(minus_comp)[np.logical_and(average_colour_after_a<0,comp_b<-1)]\n",
    "    target_points=np.array(target_points1)[minus_comp1<-5]\n",
    "    \n",
    "    #target_points=np.array(dimer_points)[minus<-7,max_l_a>0.0001)]\n",
    "    \n",
    "    #particle_difference=average_colour_dimer-average_colour_after\n",
    "    #target_points= np.array(dimer_points)[particle_difference > +10]\n",
    "    table={'colour of core': average_colour_d, 'colour of dimer': average_colour_after_a,'minus after from before': minus,'comp bef':comp_a,'comp after':comp_b,'minus comp':minus_comp}\n",
    "    print(tabulate(table, headers='keys'))\n",
    "    #tablesave=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\XueqianPlasmonicRulerData\\1104_s2w3_PR\\dry_oldsetup\\analysis\"+'\\\\'+'table.txt'\n",
    "    \n",
    "    #with open(tablesave, 'w') as f:\n",
    "    #    f.write(tabulate(table))\n",
    "    \n",
    "    target_image_picked=blockimagecombo(afterim, target_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"dimerspicked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image_picked,savepath)\n",
    "    return dimer_points,target_points,info_l2,info_a2,info_b2,info_l3,info_a3,info_b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a41bff-2202-411d-bc97-86308327eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlittleimages(bigfol):\n",
    "    %matplotlib inline\n",
    "   \n",
    "    dimerpath= r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\XueqianPlasmonicRulerData\\1104_s2w3_PR\\dry_oldsetup\\satellite\\satelliteadded\"\n",
    "    corepath=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\XueqianPlasmonicRulerData\\1104_s2w3_PR\\dry_oldsetup\\core\\core\"\n",
    "    analpath=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\XueqianPlasmonicRulerData\\1104_s2w3_PR\\dry_oldsetup\\analysis\"\n",
    "    #subfolders=getindividualfoldersandsuch(bigfol)\n",
    "    #firstfolder=subfolders[0]\n",
    "    #beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    imdimer,imcore,beforeimfile,afterimfile=imageprocessingfunction(corepath,dimerpath)\n",
    "    print(\"processed and converted images\")\n",
    "    transimaf=imgregfun(imcore[0], imdimer[0])\n",
    "    #plt.imshow(imbef[0])\n",
    "    centreimagebefore=labcolourfilt(imcore[0])\n",
    "    plt.imshow(centreimagebefore)\n",
    "    centreimageafter=labcolourfilt(transimaf)\n",
    "    #targetpicked,pointsdimer,averageval=performtemplatetrainingonimages(centreimageafter,analpath,centreimagebefore)\n",
    "    pointscore,pointssatellite,info_l2,info_a2,info_b2,info_l3,info_a3,info_b3=performthresholding(centreimagebefore,centreimageafter,analpath)\n",
    "    for pt in pointssatellite:\n",
    "        w=16\n",
    "        image_crop_bef=centreimagebefore[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        image_crop_after=centreimageafter[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        plt.figure()\n",
    "        plt.imshow(image_crop_bef)\n",
    "        plt.xlabel('before image', fontsize=18)\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        plt.imshow(image_crop_after)\n",
    "        plt.xlabel('after image', fontsize=18)\n",
    "        plt.show()\n",
    "        cv.waitKey(0)\n",
    "        #target_points= np.array(dimer_points)[particle_difference > +10]\n",
    "        \n",
    "        print(info_l2[1,-1])\n",
    "        username = input(\"Is the particle a correct change, yes(y) or no (n):\")\n",
    "        if username==\"y\":\n",
    "            savepath= analpath+'\\\\'+'core'+'\\\\'+str(pt[1])+\"beforeimg\" + \".\" + \"png\"\n",
    "            performsaveimage(image_crop_bef,savepath)\n",
    "            savepath= analpath+'\\\\'+'satellite'+'\\\\'+str(pt[1])+\"afterimg\" + \".\" + \"png\"\n",
    "            performsaveimage(image_crop_after,savepath)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(\"not anything of interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1b8de0-b693-43d0-8a2d-bdf53c9dad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed and converted images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:455: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.25236433 -3.23090556 -3.21034859 -3.19068591 -3.17190982 -3.15401245\n",
      " -3.13698572 -3.12082139 -3.105511   -3.09104593 -3.07741734 -3.06461622\n",
      " -3.05263333 -3.04145927 -3.03108443 -3.021499   -3.01269297 -3.00465613\n",
      " -2.9973781  -2.99084828 -2.98505589 -2.97998995 -2.9756393  -2.97199259\n",
      " -2.96903828 -2.96676466 -2.96515984 -2.96421177 -2.96390821 -2.96423678\n",
      " -2.96518493 -2.96673995 -2.968889   -2.9716191  -2.97491711 -2.9787698\n",
      " -2.98316379 -2.98808559 -2.9935216  -2.99945812 -3.00588136 -3.01277742\n",
      " -3.02013233 -3.02793205 -3.03616244 -3.04480932 -3.05385842 -3.06329544\n",
      " -3.073106   -3.08327568 -3.09379002 -3.10463451 -3.1157946  -3.12725568\n",
      " -3.13900314 -3.1510223  -3.16329846 -3.17581688 -3.18856279 -3.20152139\n",
      " -3.21467783 -3.22801726 -3.24152477 -3.25518545 -3.26898433 -3.28290645\n",
      " -3.29693682 -3.31106043 -3.3252623  -3.3395274  -3.35384076 -3.36818741\n",
      " -3.38255243 -3.39692096 -3.41127818 -3.42560941 -3.43990005 -3.45413565\n",
      " -3.46830194 -3.48238482 -3.49637043 -3.51024517 -3.52399573 -3.53760914\n",
      " -3.55107278 -3.56437445 -3.57750238 -3.5904453  -3.60319245 -3.61573363\n",
      " -3.62805924 -3.6401603  -3.65202851 -3.66365624 -3.6750366  -3.68616344\n",
      " -3.69703134 -3.70763571 -3.7179727  -3.72803926 -3.73783316 -3.74735292\n",
      " -3.75659785 -3.765568   -3.77426419 -3.78268792 -3.79084137 -3.79872737\n",
      " -3.80634934 -3.81371126 -3.82081763 -3.82767337 -3.83428383 -3.8406547\n",
      " -3.84679197 -3.85270183 -3.85839068 -3.86386502 -3.86913141 -3.87419643\n",
      " -3.8790666  -3.88374836 -3.888248   -3.89257163 -3.89672513 -3.90071413\n",
      " -3.90454396 -3.90821966 -3.9117459  -3.91512701 -3.91836698 -3.92146939\n",
      " -3.92443748 -3.92727412 -3.92998181 -3.93256273 -3.93501871 -3.93735132\n",
      " -3.93956183 -3.94165127 -3.94362049 -3.94547016 -3.94720081 -3.94881294\n",
      " -3.95030696 -3.95168333 -3.95294257 -3.95408529 -3.95511227 -3.9560245\n",
      " -3.95682323 -3.95750998 -3.95808662 -3.95855541 -3.95891901 -3.95918053\n",
      " -3.95934355 -3.95941215 -3.95939093 -3.95928501 -3.95910006 -3.95884228\n",
      " -3.95851843 -3.95813579 -3.95770216 -3.95722586 -3.95671568 -3.95618088\n",
      " -3.95563116 -3.95507658 -3.95452759 -3.95399494 -3.95348968 -3.95302305\n",
      " -3.95260651 -3.95225164 -3.95197011 -3.95177363 -3.9516739  -3.95168255\n",
      " -3.95181113 -3.95207101 -3.95247338 -3.95302917 -3.95374905 -3.95464335\n",
      " -3.95572204 -3.95699472 -3.95847054 -3.96015819 -3.9620659  -3.96420138\n",
      " -3.96657182 -3.96918384 -3.97204352 -3.97515637 -3.9785273  -3.98216062\n",
      " -3.98606005 -3.9902287  -3.99466909 -3.99938313 -4.00437211 -4.00963675\n",
      " -4.01517719 -4.02099296 -4.02708304 -4.03344588 -4.04007935 -4.04698083\n",
      " -4.05414717 -4.06157475 -4.06925947 -4.0771968  -4.08538177 -4.09380901\n",
      " -4.10247279 -4.11136702 -4.12048527 -4.12982082 -4.13936668 -4.1491156\n",
      " -4.15906013 -4.16919261 -4.17950522 -4.18999001 -4.2006389  -4.21144374\n",
      " -4.22239632 -4.2334884  -4.24471172 -4.25605804 -4.26751918 -4.27908698\n",
      " -4.2907534  -4.30251049 -4.3143504  -4.32626543 -4.33824803 -4.35029081\n",
      " -4.36238653 -4.37452816 -4.38670884 -4.3989219  -4.41116086 -4.42341944\n",
      " -4.43569154 -4.44797124 -4.4602528  -4.47253066 -4.4847994  -4.49705375\n",
      " -4.50928855 -4.52149877 -4.53367944 -4.5458257  -4.55793268 -4.56999559\n",
      " -4.58200958 -4.59396981 -4.60587137 -4.61770925 -4.62947836 -4.64117343\n",
      " -4.65278907 -4.66431967 -4.67575941 -4.68710223 -4.69834181 -4.70947153\n",
      " -4.7204845  -4.73137349 -4.74213095 -4.75274898 -4.76321935 -4.77353346\n",
      " -4.78368239 -4.79365686 -4.80344727 -4.81304368 -4.82243587 -4.83161335\n",
      " -4.84056535 -4.84928092 -4.85774891 -4.86595804 -4.87389692 -4.88155415\n",
      " -4.88891831 -4.89597805 -4.90272217 -4.90913961 -4.91521962 -4.9209517\n",
      " -4.92632578 -4.9313322  -4.93596183 -4.94020608 -4.94405702 -4.9475074\n",
      " -4.95055069 -4.95318117 -4.95539396 -4.95718503 -4.95855129 -4.95949057\n",
      " -4.96000166 -4.96008432 -4.95973932 -4.95896838 -4.95777422 -4.95616054\n",
      " -4.95413197 -4.95169408 -4.94885335 -4.94561712 -4.94199356 -4.93799163\n",
      " -4.93362104 -4.92889219 -4.92381613 -4.91840451 -4.91266951 -4.90662382\n",
      " -4.90028054 -4.89365319 -4.88675559 -4.87960186 -4.87220637 -4.86458366\n",
      " -4.85674843 -4.84871548 -4.84049969 -4.83211597 -4.82357922 -4.81490432\n",
      " -4.80610611 -4.79719934 -4.78819866 -4.77911863 -4.76997364 -4.76077797\n",
      " -4.75154576 -4.74229095 -4.73302735 -4.72376861 -4.71452819 -4.70531939\n",
      " -4.69615537 -4.6870491  -4.67801342 -4.669061   -4.6602044  -4.65145601\n",
      " -4.64282814 -4.63433294 -4.62598248 -4.61778874 -4.60976361 -4.6019189\n",
      " -4.59426635 -4.58681766 -4.57958447 -4.57257841 -4.56581106 -4.55929398\n",
      " -4.55303873 -4.54705687 -4.54135995 -4.53595953 -4.53086721 -4.52609456\n",
      " -4.52165322 -4.51755482 -4.51381103 -4.51043356 -4.50743413 -4.50482449\n",
      " -4.50261642 -4.50082173 -4.49945223 -4.49851978 -4.49803623 -4.49801345\n",
      " -4.49846332 -4.49939771 -4.50082849 -4.50276753 -4.50522666 -4.50821769\n",
      " -4.51175242 -4.51584259 -4.52049989 -4.52573598 -4.53156244 -4.53799079\n",
      " -4.54503248 -4.55269887 -4.56100124 -4.56995077 -4.57955854 -4.58983553\n",
      " -4.6007926  -4.61244048 -4.62478981 -4.63785108 -4.65163463 -4.66615069\n",
      " -4.68140935 -4.69742053 -4.71419402 -4.73173946 -4.75006634 -4.76918398\n",
      " -4.78910156 -4.80982807 -4.83137239 -4.8537432  -4.87694903 -4.90099826]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'here' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-80a08883c829>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetlittleimages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigfol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-0aa3d8d1866c>\u001b[0m in \u001b[0;36mgetlittleimages\u001b[1;34m(bigfol)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mcentreimageafter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabcolourfilt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransimaf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#targetpicked,pointsdimer,averageval=performtemplatetrainingonimages(centreimageafter,analpath,centreimagebefore)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mpointscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpointssatellite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_l2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_a2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_b2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_l3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_a3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_b3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperformthresholding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentreimagebefore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcentreimageafter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpointssatellite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4fcff73122f9>\u001b[0m in \u001b[0;36mperformthresholding\u001b[1;34m(beforeim, afterim, analpath)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[1;31m#dimer_points=np.array(list_of_centres)[average_colour_a<20]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m#dimer_points= np.array(list_of_centres)[average_colour >= 100]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m     \u001b[0maverage_colour_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcomp_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_l2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_a2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo_b2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetaveragevaluesLAB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeforeim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimer_points\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4fcff73122f9>\u001b[0m in \u001b[0;36mgetaveragevaluesLAB\u001b[1;34m(image, points, analpath, yespeaks)\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0myespeaks\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[1;31m#peaks_l,peaks_a,peaks_b,y_l,y_a,y_b=gethistogrampeaksLAB(dividedval_lval,dividedval,dividedval_b)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpeaks_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpeaks_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpeaks_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetkdepeaksLAB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdividedval_lval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdividedval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdividedval_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[0mpeaks_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4fcff73122f9>\u001b[0m in \u001b[0;36mgetkdepeaksLAB\u001b[1;34m(l_vec, a_vec, b_vec)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m     \u001b[0myes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhere\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m     \u001b[1;31m# score_samples returns the log of the probability density\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;31m#logprob = kde.score_samples(x_d[:, None])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'here' is not defined"
     ]
    }
   ],
   "source": [
    "getlittleimages(bigfol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1e4e3-a592-453c-babd-4348966c9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimerpath= r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\XueqianPlasmonicRulerData\\1104_s2w3_PR\\dry_oldsetup\\satellite\\satelliteadded\"\n",
    "corepath=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\XueqianPlasmonicRulerData\\1104_s2w3_PR\\dry_oldsetup\\core\\core\"\n",
    "analpath=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\Xueqian's Data\\XueqianPlasmonicRulerData\\1104_s2w3_PR\\dry_oldsetup\\analysis\"\n",
    "#subfolders=getindividualfoldersandsuch(bigfol)\n",
    "#firstfolder=subfolders[0]\n",
    "#beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction2(dimerpath,corepath)\n",
    "%matplotlib qt\n",
    "plt.imshow(imbef[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a980958-afcd-4c8f-9551-5cae8209655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageprocessingfunction2(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun2(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun2(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun2(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_auto_wb=True,\n",
    "                                #user_wb=[1.5,1.0,1.0,1.0],\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              \n",
    "                              chromatic_aberration=(1, 1),\n",
    "                              bright=1.0,\n",
    "                              \n",
    "                              dcb_enhance=True)\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        #enhancer = ImageEnhance.Contrast(metdat)\n",
    "        #metdat3 = enhancer.enhance(0.5)\n",
    "    \n",
    "        #metdat3.show()\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        \n",
    "            \n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a5c88c4-2e65-4be1-be7d-971658a57eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "clear metdat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f736c5-42c3-4bf1-a21b-b2db40f94bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
