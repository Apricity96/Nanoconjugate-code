{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-destination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\NewMicroscope\\Time_series\\slide1\\Time series in order\\Analysisfolder_Template\n",
      "processing images\n",
      "C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\NewMicroscope\\Time_series\\slide1\\Time series in order\\Analysisfolder_thresholding\n",
      "processing images\n",
      "processed and converted images\n",
      "calculating image 1 of 7\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a476409dab5e4b7797defd20bb745d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e900bbc78f4ae8b9e6cfc2167459f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a04417513f4294a38b161f9dd69173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.922435229848293  min is  -4.588185583844274\n",
      "average is  5.49518528694137 median is  4.7230651259785486\n",
      "standard deviation is  4.0692600087068245\n",
      "max is  25.317243318041818  min is  -11.233810445293837\n",
      "average is  5.090075381654554 median is  4.759204989302328\n",
      "standard deviation is  4.36734133635109\n",
      "minus values here ------------\n",
      "max value is  16.002170500335314 min value is  -12.397141812742495  mean value is  0.4051099052868165\n",
      " median value is  0.1497613066988861  standard deviation is  2.76857494543043\n",
      "calculating image 2 of 7\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559b5d00105040f39ab56e39f186684e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77a92429c5d4534b061ff681bb16aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48af8d9675d146cd9e5453dbdc66a68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.922435229848293  min is  -4.588185583844274\n",
      "average is  5.49518528694137 median is  4.7230651259785486\n",
      "standard deviation is  4.0692600087068245\n",
      "max is  25.015122458596892  min is  -11.310226587841974\n",
      "average is  4.967040853592216 median is  4.637564869199479\n",
      "standard deviation is  4.353677334603223\n",
      "minus values here ------------\n",
      "max value is  14.984457553261311 min value is  -12.864141827525074  mean value is  0.528144433349154\n",
      " median value is  0.2920623760982717  standard deviation is  2.7049321224940983\n",
      "calculating image 3 of 7\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b19348645543dd9c13fe6fa7d2579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954856fcc6d24c4392cc2e8ffe1c6239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3ed9ee8cb14c548cfda1354bc4a6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.922435229848293  min is  -4.588185583844274\n",
      "average is  5.49518528694137 median is  4.7230651259785486\n",
      "standard deviation is  4.0692600087068245\n",
      "max is  23.282530670885016  min is  -10.958929560392725\n",
      "average is  5.147956145715684 median is  4.752146253769718\n",
      "standard deviation is  4.156821936339021\n",
      "minus values here ------------\n",
      "max value is  15.33079197716199 min value is  -11.966117231489765  mean value is  0.3472291412256872\n",
      " median value is  0.03491060943384844  standard deviation is  2.76840631195565\n",
      "calculating image 4 of 7\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ab692851a946b6ba82b75927ba3c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a74455c46894f9287df10717ebe8692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c96bc6ea767436fb454b87425b6b998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.922435229848293  min is  -4.588185583844274\n",
      "average is  5.49518528694137 median is  4.7230651259785486\n",
      "standard deviation is  4.0692600087068245\n",
      "max is  22.352317090240277  min is  -10.411385774175459\n",
      "average is  5.371214421547662 median is  5.002813564214875\n",
      "standard deviation is  3.8372739507354883\n",
      "minus values here ------------\n",
      "max value is  12.138822633460093 min value is  -14.184414522054844  mean value is  0.12397086539370865\n",
      " median value is  -0.24728574994739017  standard deviation is  2.9457786433977873\n",
      "calculating image 5 of 7\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9454a615fde14ebc9dd7bbd6325b2bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e930efdc70473384b4fc4ba9425e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc57fede3e4442d8588b108addd39fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.922435229848293  min is  -4.588185583844274\n",
      "average is  5.49518528694137 median is  4.7230651259785486\n",
      "standard deviation is  4.0692600087068245\n",
      "max is  18.670454052206175  min is  -9.95599075499123\n",
      "average is  5.416704839407479 median is  5.155075978450917\n",
      "standard deviation is  3.6483175994480774\n",
      "minus values here ------------\n",
      "max value is  12.166401133910211 min value is  -13.551118225843872  mean value is  0.07848044753389176\n",
      " median value is  -0.3245441279120611  standard deviation is  3.1468297990540153\n",
      "calculating image 6 of 7\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a976cede55924d768b7c97c159642625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c54466b7d9a428cbb77aea2f1460757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ead34ee38154d91a51dbcdb7930a7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.922435229848293  min is  -4.588185583844274\n",
      "average is  5.49518528694137 median is  4.7230651259785486\n",
      "standard deviation is  4.0692600087068245\n",
      "max is  23.102424014334673  min is  -13.592569929469477\n",
      "average is  3.6891047829219152 median is  3.3515122271625115\n",
      "standard deviation is  4.149480841357585\n",
      "minus values here ------------\n",
      "max value is  21.22882681427975 min value is  -10.89530842604268  mean value is  1.8060805040194552\n",
      " median value is  1.4569536216661123  standard deviation is  2.590474443817208\n",
      "calculating image 7 of 7\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a4c276368a4a569a4e747a924e54c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73e14d3c6ca4ec2b116faeb9c570cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63cb077474a47fd948c78e87840a113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.922435229848293  min is  -4.588185583844274\n",
      "average is  5.49518528694137 median is  4.7230651259785486\n",
      "standard deviation is  4.0692600087068245\n",
      "max is  26.189542031142977  min is  -13.872780240257633\n",
      "average is  3.8794510735696335 median is  3.500092190109373\n",
      "standard deviation is  4.216061604118147\n",
      "minus values here ------------\n",
      "max value is  18.42635941608959 min value is  -11.201773648414  mean value is  1.615734213371737\n",
      " median value is  1.2978058602253182  standard deviation is  2.5934486564119292\n",
      "Finished analysis woohoo\n"
     ]
    }
   ],
   "source": [
    "##### CHANGE THIS TO YOUR FOLDER##################\n",
    "##################################################\n",
    "bigfol=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\NewMicroscope\\Time_series\"\n",
    "##################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialise dependencies\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "import imageio\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "#import hcluster\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from math import pow\n",
    "import scipy.signal \n",
    "%matplotlib qt\n",
    "#template matching\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#General Functions\n",
    "def listdirs(folder):\n",
    "## a function which lists the files in a folder and adds to a list. returns a list of folders, \n",
    "##input folder: the file path to folder\n",
    "    return [\n",
    "        d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))\n",
    "        if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "def makeclippingmask(image):\n",
    "    \n",
    "\n",
    "    #makes a clipping mask around each bright spot so the analysis isn't thrown off\n",
    "    grayA = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    blurred = cv.GaussianBlur(grayA, (11,11), 0)\n",
    "\n",
    "    #watershed thresholding. Based on: https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html\n",
    "    src = image.copy()\n",
    "    \n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    imgLaplacian = np.clip(imgLaplacian, 0, 255)\n",
    "    imgLaplacian = np.uint8(imgLaplacian)\n",
    "    #cv.imshow('Laplace Filtered Image', imgLaplacian)\n",
    "    #cv.imshow('New Sharped Image', imgResult)\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n",
    "   # _, bw2 = cv.threshold(grayA, 30, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #plt.imshow(bw)\n",
    "    bw = cv.adaptiveThreshold(bw, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 37, 1)\n",
    "    #cv.imshow('Binary Image', bw)\n",
    "    \n",
    "    \n",
    "    opening = cv.morphologyEx(bw,cv.MORPH_OPEN,kernel, iterations = 3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    # Threshold to obtain the peaks\n",
    "    # This will be the markers for the foreground objects\n",
    "    _, sure_fg = cv.threshold(dist_transform, 0.2, 1.0, cv.THRESH_BINARY)\n",
    "    # Dilate a bit the dist image\n",
    "    kernel1 = np.ones((3,3), dtype=np.uint8)\n",
    "    sure_fg = cv.dilate(sure_fg, kernel1)\n",
    "    ret, markers = cv.connectedComponents(np.uint8(sure_fg))\n",
    "    \n",
    "    \n",
    "    #cv.imshow('Final Result', sure_fg)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.float32(sure_fg)\n",
    "    sure_bg = np.float32(sure_bg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    #cv.imshow('Distance Transform Image', dist_transform)\n",
    "    \n",
    "    # Marker labelling\n",
    "    \n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    #print(markers.shape)\n",
    "    \n",
    "    markers = cv.watershed(imgResult,markers)\n",
    "    #print(markers)\n",
    "    \n",
    "    mask2 = np.zeros(image.shape[:2], dtype= np.uint8)\n",
    "    mask2[markers >1] = [255]\n",
    "    \n",
    "    #colours=((255,255,255))\n",
    "    # Fill labeled objects with random colors\n",
    "    #for i in range(markers.shape[0]):\n",
    "    #    for j in range(markers.shape[1]):\n",
    "    #        index = markers[i,j]\n",
    "    #        if index>0:\n",
    "    #            mask2[i,j] = 255\n",
    "    \n",
    "\n",
    "    image_rgb=image.copy()\n",
    "    image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    #plt.imshow(image_blocked)\n",
    "    return image_blocked\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_camera_wb=True,\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1))\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        \n",
    "def saveexcelfun(dimercoord,corecoord,savepath):\n",
    "#Save the coordinates of everything to an excel spreadsheet. Yeah I know it's ugly. \n",
    "#input: dimercoord- the dimer coordinates\n",
    "########corecoord- the core coordinates \n",
    "########savepath- the folder location where the files will be saved \n",
    "    columns=['Before Dimers xval']\n",
    "    saveexcel=savepath+\".\"+\"xlsx\"\n",
    "    beforedimercentres = pd.DataFrame({'Before Dimers xval':dimercoord})\n",
    "    try:\n",
    "        aftercorecentres = pd.DataFrame({'After core xval': corecoord})\n",
    "    except:\n",
    "        aftercorecentres=pd.DataFrame({'After core xval': np.array([0]), \n",
    "                                'After core yval': np.array([0])})\n",
    "\n",
    "   \n",
    "    writer = pd.ExcelWriter(saveexcel,engine='xlsxwriter')\n",
    "    workbook=writer.book\n",
    "    worksheet=workbook.add_worksheet('DimersPicked')\n",
    "    writer.sheets['DimersPicked'] = worksheet\n",
    "    worksheet2=workbook.add_worksheet('CoresPicked')\n",
    "    writer.sheets['CoresPicked'] = worksheet2\n",
    "\n",
    "\n",
    "    beforedimercentres.to_excel(writer,sheet_name='DimersPicked',startrow=1 , startcol=0)\n",
    "    #worksheet.write_string(beforedimercentres.shape[0] + 4, 0, beforedimercentres.name)\n",
    "\n",
    "    aftercorecentres.to_excel(writer,sheet_name='CoresPicked',startrow=1, startcol=3)\n",
    "    \n",
    "\n",
    "    writer.save()\n",
    "def savetextfilefun(data,savepath,datastring):\n",
    "##### A function which saves an array to a text file. Is a little buggy in that sometimes there's weird spaces. \n",
    "##### reccomend the excel save functions instead. Python struggles to re-read these text tiles\n",
    "\n",
    "    savetextstring=savepath+datastring+\".txt\"\n",
    "    file = open(savetextstring,\"w\")\n",
    "    for dataentry in data:\n",
    "        arr_of_strings = np.array2string(dataentry)\n",
    "        file.write(arr_of_strings) \n",
    "    file.close() \n",
    "    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "## A function which reads in images and adds them to a list of images.\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "## note !! The images wil be read in with open cv, and will be in BGR format and will look strange unless converted\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "def load_images_from_foldercv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to RGB\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "       \n",
    "        if img is not None:\n",
    "            img= cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "def load_images_from_folderhsv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to HSV\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        img= cv.cvtColor(img,  cv.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#####################################################\n",
    "###################################################\n",
    "#Template matching functions\n",
    "\n",
    "\n",
    "def findidealimagescale(image,template):\n",
    "    # loop over the images to find the template in\n",
    "   \n",
    "        # load the image, convert it to grayscale, and initialize the\n",
    "        # bookkeeping variable to keep track of the matched region\n",
    "        \n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    template=cv.cvtColor(template, cv.COLOR_HSV2RGB)\n",
    "    template=cv.cvtColor(template, cv.COLOR_RGB2GRAY)\n",
    "    #template.astype(np.uint8)\n",
    "    #gray.astype(np.uint8)\n",
    "    found = None\n",
    "    scalefin= None\n",
    "    (h, w) = template.shape[:2]\n",
    "    i=0\n",
    "    # loop over the scales of the image\n",
    "    for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "        # resize the image according to the scale, and keep track\n",
    "        # of the ratio of the resizing\n",
    "        resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "        r = gray.shape[1] / float(resized.shape[1])\n",
    "        # if the resized image is smaller than the template, then break\n",
    "        # from the loop\n",
    "        if resized.shape[0] < h or resized.shape[1] < w:\n",
    "            break\n",
    "        result = cv.matchTemplate(gray, template, cv.TM_SQDIFF_NORMED)\n",
    "        (minval, _, minloc, _) = cv.minMaxLoc(result)\n",
    "        if found is None or minval < found:\n",
    "            found = minval\n",
    "            scalefin=scale\n",
    "    return scalefin \n",
    "        \n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "        \n",
    "def nonmaxsuppression(xCoords,yCoords,template):\n",
    "    center_coordinates=[]\n",
    "    rects=[]\n",
    "    rectangle_coordinates=[]\n",
    "    (w, h) = template.shape[:2]\n",
    "    #print(w)\n",
    "    #print(h)\n",
    "## stops the overcounting of variables with nonmax suppression and returns an updated list\n",
    "    for (x, y) in zip(xCoords, yCoords):\n",
    "    # update our list of rectangles\n",
    "        rects.append((x, y, x +w, y + h))\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        center_coordinates.append((startX+h//2,startY+h//2))\n",
    "        rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "     \n",
    "    #print(\"center coordinates are \",center_coordinates)\n",
    "    #print(\"rectangle_coordinates are \", rectangle_coordinates)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithm(img_hsv,template, method,threshold):\n",
    "# defines the template matching algorithm and finds the minimum locations\n",
    "#inputs: img_rgb- the image to be matched in HSV format\n",
    "#########template- the template to be matched in HSV format\n",
    "#########method- the method of determining the minim. cv.TM_SQDIFF_NORMED is good for colour\n",
    "##### extras found here: https://docs.opencv.org/master/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d\n",
    "#########threshold: the threshold where the minimum is defined. Variable. May want to do something with min_val and max\n",
    "#outputs: locations_of_minimum- a really big array that needs to be zipped. \n",
    "#Note: this works on colour (3 d) images but may want to change to just hue\n",
    "    img_hsv = cv.cvtColor(img_hsv, cv.COLOR_HSV2BGR)\n",
    "    img_hsv = cv.cvtColor(img_hsv, cv.COLOR_BGR2Lab)\n",
    "    _,img_hsv_a,img_hsv_b=cv.split(img_hsv)\n",
    "    template = cv.cvtColor(template, cv.COLOR_HSV2BGR)\n",
    "    template = cv.cvtColor(template, cv.COLOR_BGR2Lab)\n",
    "    _,template_a,template_b=cv.split(template)\n",
    "    \n",
    "    mat_of_matching_results_a=cv.matchTemplate(img_hsv_a,template_a,method)\n",
    "    mat_of_matching_results_b=cv.matchTemplate(img_hsv_b,template_b,method)\n",
    "    \n",
    "    #This is to get some details about the minimum but isn't actually used\n",
    "    #print(\"template matching done\")\n",
    "    (min_val_a, max_val_a, _, max_loc_a) = cv.minMaxLoc(mat_of_matching_results_a)\n",
    "    (min_val_b, max_val_b, _, max_loc_b) = cv.minMaxLoc(mat_of_matching_results_b)\n",
    "    \n",
    "    #print(\"The min is done\")\n",
    "    #print(min_val)\n",
    "    #print(max_val_a)\n",
    "    if max_val_a>threshold:\n",
    "        #threshold=0.6\n",
    "        (yCoords, xCoords) = np.where(np.logical_and(mat_of_matching_results_a >= threshold, mat_of_matching_results_b>=threshold))\n",
    "        while (len(xCoords))>2500000:\n",
    "            threshold=threshold+0.1\n",
    "            #print(threshold)\n",
    "            (yCoords, xCoords) = np.where(np.logical_and(mat_of_matching_results_a >= threshold, mat_of_matching_results_b>=threshold))\n",
    "            \n",
    "    \n",
    "        center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template_a)\n",
    "    else:\n",
    "        center_coordinates=[[0,0]]\n",
    "        rectangle_coordinates=[[0,0,0,0]]\n",
    "        w=0.00001\n",
    "        h=0.00001\n",
    "    \n",
    "    #print(locations_of_minimum)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def imagetempmatch(imgpath,img_rgb,threshold,clumpflag):\n",
    "## performs the template matching function on each template image found in imgpath\n",
    "## input: imgpath: a string pointing to the folder the template images are contained in\n",
    "##########img_rgb: the image to be matched, in rgb format \n",
    "##########threshold: the threshold at which the minimum is accepted. The minimum value is the value where the \n",
    "#####################template matching function thinks that the image is matched. Note, this may be a maximum \n",
    "####################for other methods\n",
    "    #loads the template images in as HSV\n",
    "    images=load_images_from_folderhsv(imgpath)\n",
    "    center_list=[]\n",
    "    rectangle_list=[]\n",
    "    r_list=[]\n",
    "    #Creates a mask which has the shape of the image to be matched. The dtype is important or error will occur. \n",
    "    # This mask is to test whether the template matching has counted the same point multiple times\n",
    "    mask = np.zeros(img_rgb.shape, dtype=np.uint8)\n",
    "    res=[];\n",
    "    if clumpflag==1:\n",
    "        scale=findidealimagescale(img_rgb,images[0])\n",
    "    else:\n",
    "        scale=1\n",
    "    #print(scale)\n",
    "    resized = imutils.resize(img_rgb, width = int(img_rgb.shape[1]*scale))\n",
    "    for template in tqdm(images):\n",
    "        #for each template, the width and height is taken\n",
    "        if clumpflag==1:\n",
    "            scale=findidealimagescale(img_rgb,template)\n",
    "        else:\n",
    "            scale=1\n",
    "        #print(scale)\n",
    "        resized = imutils.resize(img_rgb, width = int(img_rgb.shape[1]*scale))\n",
    "\n",
    "        w=16\n",
    "        h=16\n",
    "        \n",
    "        \n",
    "        #big image converted to hsv format\n",
    "        img_hsv= cv.cvtColor(resized,  cv.COLOR_RGB2HSV)\n",
    "        #the location minima identified with the template matching algorithm\n",
    "        center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithm(img_hsv,template,cv.TM_CCOEFF_NORMED,threshold)\n",
    "        center_list.extend(center_coordinates)\n",
    "        rectangle_list.extend(rectangle_coordinates)\n",
    "        r_list.append(w)\n",
    "        \n",
    "        #print(center_coordinates)\n",
    "        \n",
    "        #print(\"locations of min are\", locations_of_min)\n",
    "        # the locations are checked for multiple counting of the same point. \n",
    "        #particle_count=checkfordoublecounting(img_hsv,locations_of_min)\n",
    "        #print(particle_count)\n",
    "    #print(np.array(center_list))\n",
    "    return np.array(center_list),np.array(rectangle_list),np.max(np.array(r_list)),h\n",
    "\n",
    "\n",
    "def blockimagecombo(image_rgb, points,r,bok):\n",
    "    #print(points)\n",
    "    if bok==1:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,255), -1)\n",
    "    else:\n",
    "        mask2 = np.zeros(image_rgb.shape[:2], dtype= np.uint8)\n",
    "        for pt in points: \n",
    "            #print(pt)\n",
    "            mask2 = cv.circle(mask2,pt,r, (255,255,255), -1)\n",
    "            \n",
    "            # a rectangle is drawn on the mask, which marks where the points are \n",
    "        #invmask=255-mask2\n",
    "        #This is an inbuilt cv function which clips the image around the mask. \n",
    "        #plt.imshow(cv.bitwise_and(image_rgb, image_rgb, mask=invmask))\n",
    "        image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "def performtemplatematching(image_rgb,imgpath,bok,threshold,clumpflag):\n",
    "## a function which performs template matching on the images and blocks them depending on whether\n",
    "## we want to keep the particles or block them out for more accuracy \n",
    "#input: image_rgb: the big image in rgb format where we are looking for matches\n",
    "########imgpath: the path to the template images, as a string\n",
    "#########bok: block or keep. 0 is for keeping, 1 is for blocking with a rectange\n",
    "#########threshold: the threshold for the minimum values. Variable. \n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=imagetempmatch(imgpath,image_rgb,threshold,clumpflag)\n",
    "    r=round(w/1.5)\n",
    "\n",
    "    correctedimg=blockimagecombo(image_rgb,center_coordinates ,r,bok)\n",
    "    return correctedimg,center_coordinates,r\n",
    "\n",
    "def performsaveimage(image,path):\n",
    "## saves image using pillow, which is a lot faster than matplot lib. \n",
    "    img_rgb_corr=image\n",
    "    try:\n",
    "        im_pil = Image.fromarray(img_rgb_corr)\n",
    "        im_pil.save(path, compress_level=1)\n",
    "    except:\n",
    "        exception=1\n",
    "\n",
    "def savetotrainingfol(foldername,image,points):\n",
    "## saves the cropped images to a folder, for use in machine learning. uses a 16 pixel box.\n",
    "#input: foldername: name of the folder where you want the images stored\n",
    "#######image: an image in rgb format which you want to cut up\n",
    "########points: the coordinates of the particles which you have selected. \n",
    "    boxwid=round(16/2)\n",
    "    w=16\n",
    "    for j,pt in enumerate(points):\n",
    "        savepathfol= addstringwithtime(foldername +'\\\\')\n",
    "        savepath= savepathfol+str(j)+\"registeredimg\" + \".\" + \"png\"\n",
    "        #savepath=os.path.join(savepathfol, str(j)+\"registeredimg\" + \".\" + \"png\")\n",
    "        lilimage=image[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        performsaveimage(lilimage,savepath)\n",
    "        \n",
    "def blockoutunwantedparticles(analpath,sat_img,path,threshold,clumpflag):\n",
    "## a function which blocks out that particles which are interfering with analysis i.e. clumps and clusters\n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#output: correctedimgcore, the corrected image after accounting for cores and clumps\n",
    "# These images are hardcoded into a folder, so the code has some dependencies. But any exmaples of the correct size will do\n",
    "    #The threshold of 0.25 seems to be highly variable\n",
    "    correctedimg,_,r= performtemplatematching(sat_img, path,1,threshold,clumpflag)\n",
    "    #plt.imshow(correctedimg)\n",
    "    #print(r)\n",
    "    return correctedimg,r\n",
    "\n",
    "\n",
    "def unwantedparticleblocking(analpath,sat_img):\n",
    "    #clusterpath=  r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\Cluster\"\n",
    "    #threshold= 0.25\n",
    "    #correctedimgcluster=blockoutunwantedparticles(analpath,sat_img,clusterpath,threshold)\n",
    "    \n",
    "    clumppath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\clump\"\n",
    "    threshold=0.55\n",
    "    savepath=os.path.join(analpath, \"clumpcorrectedimg\" + \".\" + \"png\")\n",
    "    correctedimgclump,r=blockoutunwantedparticles(analpath,sat_img,clumppath,threshold,0)\n",
    "    performsaveimage(correctedimgclump,savepath)\n",
    "    \n",
    "    corepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\core2\"\n",
    "    threshold=0.55\n",
    "    correctedimgcore,r=blockoutunwantedparticles(analpath,correctedimgclump,corepath,threshold,1)\n",
    "    savepath=os.path.join(analpath, \"corecorrectedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgcore,savepath)\n",
    "    \n",
    "    return correctedimgcore,r\n",
    "    \n",
    "def keepmatchedparticles(path,image,threshold):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "    correctedimgdimer,pointsdimer,r= performtemplatematching(image, path, 0, threshold,1)\n",
    "    \n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "                                                              \n",
    "\n",
    "def performkeepmatchedparticles(analpath,image):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "#outputs: the selected image and the dimer points selected\n",
    "    dimerpath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\dimer2\"\n",
    "    threshold=0.55\n",
    "    \n",
    "    correctedimgdimer,pointsdimer,r=keepmatchedparticles(dimerpath,image,threshold)\n",
    "    savepath=os.path.join(analpath, \"pickeddimersimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgdimer,savepath)\n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "\n",
    "\n",
    "\n",
    "def getaveragevalueshsv(image,points,w,h,analpath):\n",
    "# a function to get the average values of the image in rgb format\n",
    "#inputs: image: the hsv image\n",
    "#########points: the selected dimer values\n",
    "#########w,h- the width and height in pixels\n",
    "#########analpath: the path to the analysis folder\n",
    "#outputs: an array of the average colour of the red divided by the green vector\n",
    "\n",
    "    average_colour_rDivg=[]\n",
    "    #converts the image to hsv\n",
    "    image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_rDivg)), \" min is \",np.min(np.array(average_colour_rDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_rDivg)), \"median is \", np.mean(np.array(average_colour_rDivg)) )\n",
    "    print(\"standard deviation is \", np.mean(np.array(average_colour_rDivg)))\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getaveragevaluesLAB(image,points,analpath):\n",
    "    w=8\n",
    "    labim = rgb2lab(image)\n",
    "    l_vec,a_vec,b = cv.split(labim)\n",
    "    average_colour_aDivg=[]\n",
    "    max_val_lDivg=[]\n",
    "    average_lum=[]\n",
    "    #converts the image to hsv\n",
    "    #image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    #image_hue=np.true_divide(image[:,:,0], image[:,:,1], where=(image[:,:,0]!=0) | (image[:,:,1]!=0))\n",
    "    #image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=a_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            \n",
    "            crop_im_lval=l_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval_lval=crop_im_lval.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_aDivg.append(np.mean(dividedval))\n",
    "            \n",
    "            max_val_lDivg.append(np.max(dividedval_lval))\n",
    "            average_lum.append(np.mean(dividedval_lval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    if not average_colour_aDivg:\n",
    "        average_colour_aDivg=[0]\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_aDivg)), \" min is \",np.min(np.array(average_colour_aDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_aDivg)), \"median is \", np.median(np.array(average_colour_aDivg)) )\n",
    "    print(\"standard deviation is \", np.std(np.array(average_colour_aDivg)))\n",
    "    return np.array(average_colour_aDivg),np.array(average_lum),np.array(max_val_lDivg)\n",
    "\n",
    "def averagehistogramshift(correctedimgdimer,pointsdimer,correctedimgtarget,threshold,analpath):\n",
    "# a function which uses the average shift of the particle colour (either hue or rgb depending ) to \n",
    "#select the particles which have shifted in the after image \n",
    "#inputs: correctedimgdimer: the image with only dimers selected\n",
    "#########pointsdimer: the locations of the dimers in the image\n",
    "#########correctedimgtarget: the registered image after target added wherein the coordinates of the selected\n",
    "# dimers have been used to clip it\n",
    "#########threshold: the values which the shifted average value must be above or below. was 0.2 \n",
    "#output: loc- the shifted selected particles. \n",
    "    avdim,ldim,maxldim=getaveragevaluesLAB(correctedimgdimer,pointsdimer,analpath)\n",
    "    \n",
    "    avcore,lcore,maxlcore=getaveragevaluesLAB(correctedimgtarget,pointsdimer,analpath)\n",
    "    minus= np.array(avdim)-np.array(avcore)\n",
    "    minus_l=np.array(ldim)-np.array(lcore)\n",
    "    \n",
    "    print(\"minus values here ------------\")\n",
    "    print(\"max value is \", np.max(minus), \"min value is \", np.min(minus), \" mean value is \", np.mean(minus))\n",
    "    print(\" median value is \", np.median(minus), \" standard deviation is \", np.std(minus))\n",
    "    loc=np.array(pointsdimer)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    ldim2=ldim[np.logical_and(minus>5,maxlcore>1)]\n",
    "    loc=loc[ldim2<30]\n",
    "    r=8\n",
    "    #loc=np.array(pointsdimer)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    targetpicked= blockimagecombo(correctedimgtarget,loc,r,0)\n",
    "    #average_values=np.array(minus)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    average_values=np.array(minus)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    #print(minus)\n",
    "    #average_values=average_values[ldim2<30]\n",
    "    #print(ldim2)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"tarmaskedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(targetpicked,savepath)\n",
    "    return loc,average_values.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def performtemplatetrainingonimages(transtarimg,analpath,sat_img):\n",
    "    \n",
    "\n",
    "    #blocks unwated particles\n",
    "    correctedimgcore,r=unwantedparticleblocking(analpath,sat_img)\n",
    "    \n",
    "    \n",
    "    #selects dimers\n",
    "    correctedimgdimer,pointsdimer,r=performkeepmatchedparticles(analpath, correctedimgcore)\n",
    "    image_circle=blockimagecombo(sat_img, pointsdimer,16,2)\n",
    "    savepath=os.path.join(analpath, \"dimerCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #print(np.unique(np.array(pointsdimer),axis=0))\n",
    "    #pointsdimer_corrected=np.unique(np.array(pointsdimer),axis=0)\n",
    "    pointsdimer_corrected=pointsdimer\n",
    "    #uses those points to select the same points in the target image \n",
    "    \n",
    "    transtarimg=makeclippingmask(transtarimg)\n",
    "    correctedimgtarget=blockimagecombo(transtarimg,pointsdimer_corrected,r,0)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgtarget,savepath)\n",
    "    \n",
    "    #scans the before and after dimers to determine if the particles shift in hue\n",
    "    threshold=-0.001\n",
    "    selected_target_locations,average_values=averagehistogramshift(correctedimgdimer,pointsdimer_corrected,correctedimgtarget,threshold,analpath)\n",
    "    image_circle=blockimagecombo(transtarimg, selected_target_locations,16,2)\n",
    "    savepath=os.path.join(analpath, \"targetCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #comment out if don't want\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\before\",sat_img,pointsdimer_corrected)\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\after\",transtarimg,selected_target_locations)\n",
    "    \n",
    "    return selected_target_locations,pointsdimer_corrected,average_values\n",
    "\n",
    "\n",
    "######### Extra functions\n",
    "\n",
    "def getindividualfoldersandsuch(bigfol):\n",
    "# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\n",
    "    topfolders=listdirs(bigfol)\n",
    "    subfolders=[0]\n",
    "    for nextfolders in topfolders:\n",
    "        subfolders= subfolders+ listdirs(nextfolders)\n",
    "    subfolders.pop(0)\n",
    "    #print(subfolders)\n",
    "    subfolders=np.array(subfolders).reshape(-1,1)\n",
    "    #print(subfolders)\n",
    "    return subfolders\n",
    "def searchforsatandtargetfolders(folder):\n",
    "#finds the satellite and targetfolders using regexp\n",
    "    subfolders2 = folder.tolist()\n",
    "    subfolders3=str(subfolders2).replace('[','').replace(']','').replace('\\\\\\\\','\\\\')\n",
    "\n",
    "    listexpfolders=listdirs(subfolders3[1:len(subfolders3)-1])\n",
    "    beforefol = [x for x in listexpfolders if re.search(\"satellite\",x)]\n",
    "    beforefol=beforefol[0]\n",
    "    afterfol= [x for x in listexpfolders if re.search(\"target\",x)]\n",
    "    afterfol=afterfol[0]\n",
    "    \n",
    "    return beforefol,afterfol\n",
    "\n",
    "def createanalysisfolder(beforefol,string):\n",
    "#creates an analysis folder in the address above where the satellite and target folders are located.\n",
    "    oneuppath=os.path.dirname(beforefol)\n",
    "    analysisfolderpath=oneuppath+\"\\\\\"+string\n",
    "    try:\n",
    "        os.mkdir(analysisfolderpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    print(analysisfolderpath)\n",
    "    print(\"processing images\")\n",
    "    return analysisfolderpath,oneuppath\n",
    "\n",
    "def createimagesubfolderforsaving(pathtomatch,analysisfolderpath):\n",
    "# creates a folder with the name of the image in the analysis folder \n",
    "    pathtomatch=beforeimfile[j]\n",
    "    matchingsearch=re.search(\"IMG_.*.CR2\",pathtomatch)\n",
    "    savefilespath=analysisfolderpath+\"\\\\\"+matchingsearch.group()+\"\\\\\"\n",
    "    try: \n",
    "        os.mkdir(savefilespath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    return savefilespath\n",
    "def addstringwithtime(savefilespath):\n",
    "# adds the current date and time so there's no saving over the top of different analysis\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    savepath=savefilespath+dt_string\n",
    "    return savepath\n",
    "def makeanalysisfolder(savefilespath,string):\n",
    "# makes a directory in the folder which matches the image name which says 'analysis'\n",
    "    analpath=os.path.join(savefilespath,string)\n",
    "                        #saves the registered image\n",
    "    try: \n",
    "        os.mkdir(analpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    return analpath\n",
    "\n",
    "################ THRESHOLDING\n",
    "def gethuevaluesthreshHSV(image,points):\n",
    "    image_hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    image_hue=image_hsv[:,:,0]\n",
    "    w=8\n",
    "    average_colour_rDivg=[]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getcentroidsandcenters(image):\n",
    "    \n",
    "    #wmakes an excellent binary image\n",
    "    src = image.copy()\n",
    "\n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_RGB2GRAY)\n",
    "    #_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    contours, hierarchy = cv.findContours(bw, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    list_of_centres=[]\n",
    "    boundRect = [None]*len(contours)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        center_circle, _ = cv.minEnclosingCircle(contours_poly[i])\n",
    "        list_of_centres.append((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "        \n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "        cv.circle(src, ((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1])))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        #print((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "    #picked_rectangles=non_max_suppression_fast(np.array(boundRect),0.01)\n",
    "    #h=16;\n",
    "    #for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "    #    list_of_centres.append((np.round((startX+endX/2)),np.round((startY+endY/2))))\n",
    "        #cv.circle(src, (np.int(np.round((startX+endX/2))),np.int(np.round((startY+endY/2)))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "    #cv.imshow(\"Image\", src)\n",
    "    #plt.show()\n",
    "    #list_of_centres=np.array(list_of_centres)\n",
    "    #print(list_of_centres)\n",
    "    return list_of_centres\n",
    "\n",
    "\n",
    "def performthresholding(beforeim,afterim,analpath):\n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    average_colour=gethuevaluesthreshHSV(image,list_of_centres)\n",
    "    dimer_points= np.array(list_of_centres)[average_colour <= 20]\n",
    "    \n",
    "    average_colour_dimer=gethuevaluesthreshHSV(image,dimer_points)\n",
    "    dimers_blocked=blockimagecombo(beforeim, dimer_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"dimersblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(dimers_blocked,savepath)\n",
    "    target_image=blockimagecombo(afterim, dimer_points,8,0)\n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image,savepath)\n",
    "    average_colour_after=gethuevaluesthreshHSV(target_image,dimer_points)\n",
    "    particle_difference=average_colour_dimer-average_colour_after\n",
    "    target_points= np.array(dimer_points)[particle_difference < -10]\n",
    "    target_image_picked=blockimagecombo(afterim, target_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"targetpicked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image_picked,savepath)\n",
    "    return dimer_points,target_points\n",
    "    \n",
    "#########################\n",
    "\n",
    "\n",
    "subfolders=getindividualfoldersandsuch(bigfol)\n",
    "\n",
    "for folder in subfolders:\n",
    "    #automatically find the before and after folder \n",
    "    beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    \n",
    "    #Create the relevant folder for saving,as well as the path one folder up \n",
    "    analysisfolderpath_temp,oneuppath_temp=createanalysisfolder(beforefol,\"Analysisfolder_Template\")\n",
    "    analysisfolderpath_thresh,oneuppath_thresh=createanalysisfolder(beforefol,\"Analysisfolder_thresholding\")\n",
    "    \n",
    "    \n",
    "    #loadsall the images in \n",
    "\n",
    "    imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction(beforefol,afterfol)\n",
    "    print(\"processed and converted images\")\n",
    "    \n",
    "    \n",
    "    response=[0]*len(beforeimfile)\n",
    "    dimercount=[0]*len(beforeimfile)\n",
    "    targetcount=[0]*len(beforeimfile)\n",
    "    response_thresh=[0]*len(beforeimfile)\n",
    "    dimercount_thresh=[0]*len(beforeimfile)\n",
    "    targetcount_thresh=[0]*len(beforeimfile)\n",
    "    #t = tqdm(total=len(imbef))\n",
    "    for j,image in enumerate(imbef):\n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.25)\n",
    "            #sleep(0.1)\n",
    "\n",
    "        pathtomatch=beforeimfile[j]\n",
    "        savefilespath_temp= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_temp)\n",
    "        savefilespath_thresh= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_thresh)\n",
    "        \n",
    "        \n",
    "        #add on the currentdate and time \n",
    "        savepath_temp=addstringwithtime(savefilespath_temp)\n",
    "        savepath_thresh=addstringwithtime(savefilespath_thresh)\n",
    "        \n",
    "        \n",
    "        print(\"calculating image \"+str(j+1)+\" of \"+ str(len(imbef)))\n",
    "        \n",
    "        #make an analysis folder which says analysis in the image folder just created \n",
    "        analpath_temp=makeanalysisfolder(savefilespath_temp,\"Analysisimages_Template\")\n",
    "        analpath_thresh=makeanalysisfolder(savefilespath_thresh,\"Analysisimages_thresholding\")\n",
    "        \n",
    "        #spot matches the before and after images \n",
    "        transimaf=imgregfun(image, imaf[j])\n",
    "        #saves the redistered image\n",
    "        saveregisteredimage=os.path.join(analpath_temp, \"registeredimg\" + \".\" + \"png\")\n",
    "        performsaveimage(transimaf,saveregisteredimage)\n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "        #    pbar.update(0.5)\n",
    "        #    sleep(0.1)\n",
    "        \n",
    "        #uncomment if you want a crop box    \n",
    "        #height, width = image.shape[:2]\n",
    "        #boxwid=round(1500/2)\n",
    "        #centreimagebefore=image[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        #centreimageafter=transimaf[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        centreimagebefore=makeclippingmask(image)\n",
    "        print(\"Made the clipping Mask\")\n",
    "        #plt.imshow(centreimagebefore)\n",
    "        centreimageafter=makeclippingmask(transimaf)\n",
    "        \n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.75)\n",
    "            #sleep(0.1)\n",
    "        dimer_points,target_points=performthresholding(centreimagebefore,centreimageafter,analpath_thresh)\n",
    "        \n",
    "        #perform the template matching and see which particles shift\n",
    "        targetpicked,pointsdimer,average=performtemplatetrainingonimages(centreimageafter,analpath_temp,centreimagebefore)\n",
    "       \n",
    "        \n",
    "        #saves the to an excel spreadsheet and saves the results to a list to get the overall results at the end \n",
    "        #if I feel bothered I can add something in that uses the already analysed images but meh \n",
    "        dimercount[j]=len(pointsdimer)\n",
    "        targetcount[j]=len(targetpicked)\n",
    "        try: \n",
    "            response[j]=(len(targetpicked)/len(pointsdimer))*100\n",
    "        except:\n",
    "            response[j]=0\n",
    "        \n",
    "       # saveexcelfun(pointsdimer,targetpicked,savepath_temp)\n",
    "        \n",
    "        dimercount_thresh[j]=len(dimer_points)\n",
    "        targetcount_thresh[j]=len(target_points)\n",
    "        try: \n",
    "            response_thresh[j]=(len(target_points)/len(dimer_points))*100\n",
    "        except:\n",
    "            response_thresh[j]=0\n",
    "        #print(pointsdimer.type)\n",
    "        #print(dimer_points.type)\n",
    "        #saveexcelfun(dimer_points,target_points,savepath_thresh)\n",
    "  \n",
    "        \n",
    "        \n",
    "        #save important coordinates to a text file for later analysis\n",
    "        #Probably can delete this don't know what it's used for anymore \n",
    "        #savetextfilefun(np.array(pointsdimer),savepath,\"dimerbefore\")\n",
    "        #savetextfilefun(np.array(targetpicked),savepath,\"selectedResponse\")\n",
    "\n",
    "    print(\"Finished analysis woohoo\")\n",
    "    #t.close()\n",
    "    #Find the folders which contain the analysis and read the text files\n",
    "    #Find the image folders\n",
    "    searchfolder=oneuppath_temp\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_temp= searchfolder+'\\\\'+\"Analysisfolder_Template\"\n",
    "    imagefilefolders=os.listdir(savedir_temp)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount),'target_picked':np.array(targetcount),'response': np.array(response)})\n",
    "    responsepath_temp=savedir_temp+'\\\\'+\"responseforallimages.xlsx\"\n",
    "    responseforexcel.to_excel(responsepath_temp) \n",
    "    \n",
    "    searchfolder_thresh=oneuppath_thresh\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_thresh= searchfolder+'\\\\'+\"Analysisfolder_thresholding\"\n",
    "    imagefilefolders=os.listdir(savedir_thresh)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount_thresh),'target_picked':np.array(targetcount_thresh),'response': np.array(response_thresh)})\n",
    "    responsepath_thresh=savedir_thresh+'\\\\'+\"responseforallimages.xlsx\"\n",
    "    responseforexcel.to_excel(responsepath_thresh) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-silence",
   "metadata": {},
   "source": [
    "#################### TEMPLATE MATCHING MAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-blend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-exposure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-employee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-brush",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-dispatch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-beatles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-transparency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-beverage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-struggle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
