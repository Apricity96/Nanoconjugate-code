{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-destination",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n",
      "C:\\Users\\Image Processing PC\\Downloads\\OneDrive_2_10-8-2021\\slide1\\w3\\Analysisfolder_Template\n",
      "processing images\n",
      "folder already exists\n",
      "C:\\Users\\Image Processing PC\\Downloads\\OneDrive_2_10-8-2021\\slide1\\w3\\Analysisfolder_thresholding\n",
      "processing images\n",
      "processed and converted images\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 1 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24304ded0e2449e687a98af26507a822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81201463b07a47faadd4f59ab1543c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e134dd39d0467b948528ad35ea1464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  19.73336826751569  min is  -10.54601098332779\n",
      "average is  1.5787439324500023 median is  0.40684924283991963\n",
      "standard deviation is  5.7192887450055405\n",
      "max is  26.465294270818887  min is  -11.677048472869151\n",
      "average is  3.494499257819767 median is  1.8449676823913188\n",
      "standard deviation is  6.536765705357071\n",
      "minus values here ------------\n",
      "max value is  14.280581034246648 min value is  -13.168320122258217  mean value is  -1.9157553253697648\n",
      " median value is  -1.7214215197994895  standard deviation is  3.3751887715276916\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 2 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778d949620754da39359d0884182678e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071850e19a094662b62c401186688292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feff6c2924fc4f4d96e36ab1ea476717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  21.088189672857848  min is  -10.748742211666244\n",
      "average is  -1.420654064016946 median is  -3.181466439473619\n",
      "standard deviation is  5.630790972890525\n",
      "max is  23.66036401684119  min is  -10.321051378817035\n",
      "average is  2.349246876605082 median is  0.7322094832118946\n",
      "standard deviation is  6.418397023862722\n",
      "minus values here ------------\n",
      "max value is  12.627394675749626 min value is  -18.63571130319181  mean value is  -3.7699009406220285\n",
      " median value is  -3.2536601482711927  standard deviation is  4.144456703979219\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 3 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aad81f670db44c9b514f7b9ef955ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe132e1e71c4f6b91afb9e4265337ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4feb5e4d12284ae09840212e9fc31e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  24.88610413763344  min is  -14.082694745364236\n",
      "average is  -2.3584357378840233 median is  -4.065881301355363\n",
      "standard deviation is  5.770653078533942\n",
      "max is  24.1148210927677  min is  -10.769803128839937\n",
      "average is  2.3164238760796234 median is  0.26946034246758366\n",
      "standard deviation is  6.15702142409807\n",
      "minus values here ------------\n",
      "max value is  19.922595862861023 min value is  -23.42671526277968  mean value is  -4.674859613963647\n",
      " median value is  -4.2623622508886845  standard deviation is  4.8290904234374565\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 4 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa70306a651b4a02bd219175309c8afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5311345ef04a4619ab44d44b7e326eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9e671637a0494cb96cf55de9f205ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  21.269051489289417  min is  -12.79219651803443\n",
      "average is  -2.963146661269065 median is  -4.234287915708183\n",
      "standard deviation is  5.420772873589565\n",
      "max is  23.509587298146897  min is  -10.718350743747976\n",
      "average is  1.0793024791950974 median is  0.0\n",
      "standard deviation is  5.846755393059458\n",
      "minus values here ------------\n",
      "max value is  12.633909338154956 min value is  -18.963461759143186  mean value is  -4.0424491404641625\n",
      " median value is  -3.4279851256996077  standard deviation is  3.5236106050561955\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 5 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f0cb51c29e4688a95733014fb8a73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a2e229782c47fea83f65cb960e76aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73809186b60d4f3b9d72b4207d015f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  20.85111648735156  min is  -12.992313546968404\n",
      "average is  -2.367138875045314 median is  -3.64814147053879\n",
      "standard deviation is  5.477903588946748\n",
      "max is  19.553759504237888  min is  -14.067619742298476\n",
      "average is  2.3264315757336917 median is  1.1415120119956481\n",
      "standard deviation is  5.5984096931927\n",
      "minus values here ------------\n",
      "max value is  14.336869031560902 min value is  -15.621590187449895  mean value is  -4.693570450779006\n",
      " median value is  -4.267734910800441  standard deviation is  3.5054655629501488\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 6 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f63b4c142545ad9980dfe79965773c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dca8b269dba47d19425ab1e51e21a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e8057c04a7491789fe3a2287113bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  20.350077537088854  min is  -15.024096351558414\n",
      "average is  0.7517305135749776 median is  -0.15873117104925083\n",
      "standard deviation is  6.670556300135165\n",
      "max is  20.60364880382349  min is  -12.878866981339447\n",
      "average is  5.424461859965455 median is  5.6245078653911635\n",
      "standard deviation is  6.433431189207843\n",
      "minus values here ------------\n",
      "max value is  6.907252276578721 min value is  -17.31244432224232  mean value is  -4.672731346390478\n",
      " median value is  -4.830765080334763  standard deviation is  3.9678684855011714\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 7 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e05708683b741e08f979663b0a30749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02ced2d698546ef8a3325de6f2d2515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a338701fb943ca9b76609c4652f9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.78811638981144  min is  -14.799347501485506\n",
      "average is  0.9926738801124992 median is  0.021610084568717575\n",
      "standard deviation is  6.776000702129756\n",
      "max is  19.443105010402956  min is  -12.831061228410245\n",
      "average is  5.185317863575018 median is  5.365536643877185\n",
      "standard deviation is  5.813906300174853\n",
      "minus values here ------------\n",
      "max value is  12.885276621441472 min value is  -17.673718776391965  mean value is  -4.192643983462518\n",
      " median value is  -4.212422430441595  standard deviation is  4.134020326007603\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 8 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2406105d407f4d9f92cb6564e6347c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ec41ecbd184b39b64c99b5490a0c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2710152dd3bc42898a73f6e641bf9b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  21.981271828200832  min is  -11.889487398575005\n",
      "average is  -1.9460185348932324 median is  -3.522130477045102\n",
      "standard deviation is  5.721410032396129\n",
      "max is  18.59695273230874  min is  -6.540912748933094\n",
      "average is  2.4335833765602763 median is  1.4543010951480024\n",
      "standard deviation is  5.262853788238441\n",
      "minus values here ------------\n",
      "max value is  12.117266627744753 min value is  -18.70864882832612  mean value is  -4.379601911453508\n",
      " median value is  -4.164966799536909  standard deviation is  3.5370596128270644\n",
      "folder already exists\n",
      "folder already exists\n",
      "calculating image 9 of 17\n",
      "folder already exists\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02072f91bf44499fbf41b1b5d7f12bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d10889b01554c87aba4ec3b5d6ac14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4c9883568a4409b7c2dcd690690e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  19.02290698020847  min is  -12.677393588877703\n",
      "average is  -1.0256181440362389 median is  -2.4128010994766687\n",
      "standard deviation is  5.980692366945164\n",
      "max is  15.053956246699533  min is  -9.434377137744784\n",
      "average is  2.570893724764029 median is  1.4255704718401003\n",
      "standard deviation is  4.738378751445209\n",
      "minus values here ------------\n",
      "max value is  8.511203205719623 min value is  -13.591386018213317  mean value is  -3.5965118688002686\n",
      " median value is  -3.549555487682099  standard deviation is  3.168326094143664\n",
      "calculating image 10 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9994ac706b46d8bfc5b4ec1b1a6c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a7224b1144461e8b9622c1838b2240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41f2a7f98804b9f85584cc14be2c9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  18.727661772442726  min is  -12.726595839685405\n",
      "average is  0.6802974410456807 median is  -0.8113988849813412\n",
      "standard deviation is  6.319343033037115\n",
      "max is  14.582844606778714  min is  -12.154151970259642\n",
      "average is  1.1224124053365852 median is  0.0\n",
      "standard deviation is  3.5977529493402445\n",
      "minus values here ------------\n",
      "max value is  15.593050786908144 min value is  -10.907705293516027  mean value is  -0.4421149642909046\n",
      " median value is  -1.040808413838041  standard deviation is  4.321286420890222\n",
      "calculating image 11 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ffe092592e4269ad8ac7149ad02051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb91cb90462549e7b02815113427b85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ef20bee2204966965eeeca95e399d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  21.587246312273297  min is  -15.312777217060834\n",
      "average is  3.3222842261328296 median is  3.367936642138816\n",
      "standard deviation is  6.436650603973529\n",
      "max is  22.789355859166086  min is  -11.714611480300325\n",
      "average is  4.206214522592516 median is  3.6134082731944615\n",
      "standard deviation is  5.47824532809959\n",
      "minus values here ------------\n",
      "max value is  17.475642661764162 min value is  -12.455496833068079  mean value is  -0.8839302964596859\n",
      " median value is  -0.9288696618551482  standard deviation is  3.2476329530925647\n",
      "calculating image 12 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ae66e6d4c94d61b031f0f23acfcf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bce9e4446804e6b8fbaeef68b8e620b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6baf79cf6c38464cbdb540a474887b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.426527336264513  min is  -14.94917449524423\n",
      "average is  1.0547877285292198 median is  -0.19173031554447784\n",
      "standard deviation is  6.860481441188173\n",
      "max is  20.384334883072395  min is  -13.340413520937439\n",
      "average is  2.741177555286159 median is  1.0814244237456248\n",
      "standard deviation is  5.14533305204266\n",
      "minus values here ------------\n",
      "max value is  12.97035377573935 min value is  -12.442715422028861  mean value is  -1.686389826756939\n",
      " median value is  -1.7619387920099123  standard deviation is  3.499742925914197\n",
      "calculating image 13 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0103a7d824364f1ebc06c7d1db243bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef39dc8804914685931188c91fc58a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35005e7d205a4aaead0b604b87998ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.476315336084937  min is  -13.939024224100624\n",
      "average is  -1.5580009421161216 median is  -3.2286705270493634\n",
      "standard deviation is  5.850457326424062\n",
      "max is  17.58834577330255  min is  -10.419549283516016\n",
      "average is  3.618364151714023 median is  2.8012489808758225\n",
      "standard deviation is  5.3533594929178925\n",
      "minus values here ------------\n",
      "max value is  15.059525820618507 min value is  -18.61601540020528  mean value is  -5.176365093830144\n",
      " median value is  -5.027241441148427  standard deviation is  3.9845497901839884\n",
      "calculating image 14 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47daadca1e54416971ace4e1e6d81ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32b84c43f4c48d9af46341f0c45c648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f532dcee15742009ee251f019ebd8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  19.719407578737894  min is  -12.2010749229632\n",
      "average is  0.27416798377671187 median is  -0.5673187917315001\n",
      "standard deviation is  6.185497446624441\n",
      "max is  22.5644064568142  min is  -17.298653511239408\n",
      "average is  5.965520912365349 median is  5.519753738558119\n",
      "standard deviation is  6.427543089067999\n",
      "minus values here ------------\n",
      "max value is  13.384124018356468 min value is  -20.329155118075242  mean value is  -5.691352928588637\n",
      " median value is  -6.086351632688962  standard deviation is  4.569024306690033\n",
      "calculating image 15 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ab5dd505124465b1689f3ac3feb513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889e771395a540bd913a0a33173b7699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab6bc51d18c43c38c7d652b9965f51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  18.295595403251433  min is  -16.448888364828168\n",
      "average is  3.6073183712917687 median is  3.706358294134852\n",
      "standard deviation is  6.435853854890441\n",
      "max is  24.63433161909896  min is  -14.978960900494538\n",
      "average is  8.417281737531303 median is  9.171309907963433\n",
      "standard deviation is  6.461310754229997\n",
      "minus values here ------------\n",
      "max value is  12.61021605734269 min value is  -21.75026368512607  mean value is  -4.809963366239534\n",
      " median value is  -4.72299079698853  standard deviation is  5.658559000608901\n",
      "calculating image 16 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060c49d02d8a400a8d27b913c7c14d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b508ba43b34b38862b8fda19c462ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ed0123f44a44739f6325d528d8c4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  15.691712184380066  min is  -12.428340650099006\n",
      "average is  0.6329721335108459 median is  0.1241614765240606\n",
      "standard deviation is  5.553940076468092\n",
      "max is  22.681739657664224  min is  -10.559303645462865\n",
      "average is  8.339741768069752 median is  8.367131285474125\n",
      "standard deviation is  6.870108203962648\n",
      "minus values here ------------\n",
      "max value is  15.691712184380066 min value is  -22.416680538538245  mean value is  -7.706769634558906\n",
      " median value is  -8.689550800983737  standard deviation is  6.911250306348808\n",
      "calculating image 17 of 17\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67169b05845f4a6b932308cc8fbeef43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684bf91d238844f0b6fba174970ec529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9505c563094e4b26a46b8e5bbe8f22a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  16.701262031877544  min is  -12.873237521838691\n",
      "average is  -0.7507650726732695 median is  -1.8739041767071254\n",
      "standard deviation is  5.4752798895827715\n",
      "max is  26.409905756510227  min is  -8.89646824342788\n",
      "average is  5.617625730739478 median is  4.670615965441748\n",
      "standard deviation is  7.016318786884125\n",
      "minus values here ------------\n",
      "max value is  10.279180664838929 min value is  -21.341679025343446  mean value is  -6.368390803412748\n",
      " median value is  -6.406174196631321  standard deviation is  5.543318779933102\n",
      "Finished analysis woohoo\n",
      "C:\\Users\\Image Processing PC\\Downloads\\OneDrive_2_10-8-2021\\slide1\\w4\\Analysisfolder_Template\n",
      "processing images\n",
      "C:\\Users\\Image Processing PC\\Downloads\\OneDrive_2_10-8-2021\\slide1\\w4\\Analysisfolder_thresholding\n",
      "processing images\n",
      "processed and converted images\n",
      "calculating image 1 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a994d58a3f46e18df413e90f2ec14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702cc4ebc645404baba6eb37a89ffba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61a54cf11ac4d53b2cf74f4fc8b85cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  24.54434328844504  min is  -14.003337963500325\n",
      "average is  -1.1230204334360843 median is  -3.0551425483711494\n",
      "standard deviation is  6.024580672134406\n",
      "max is  8.868773789870273  min is  -9.33968461617128\n",
      "average is  -0.1214027009202335 median is  0.0\n",
      "standard deviation is  0.9741018073608236\n",
      "minus values here ------------\n",
      "max value is  24.54434328844504 min value is  -14.003337963500325  mean value is  -1.0016177325158508\n",
      " median value is  -3.015102670190209  standard deviation is  6.147812094601672\n",
      "calculating image 2 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664929cbbfe04faca75cd1fa0e907035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edd8b2d2b304f44b9cbed18976136d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff9db6f4672444dbf0c47b612a761af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  26.18452566883984  min is  -13.409486904543927\n",
      "average is  -0.7195543511392868 median is  -3.125906366582451\n",
      "standard deviation is  6.857989195541698\n",
      "max is  5.727940825029128  min is  -8.632281421611365\n",
      "average is  -0.04938967987734482 median is  0.0\n",
      "standard deviation is  0.6727589875367668\n",
      "minus values here ------------\n",
      "max value is  26.18452566883984 min value is  -13.409486904543927  mean value is  -0.6701646712619422\n",
      " median value is  -3.010826540310103  standard deviation is  6.908477447819854\n",
      "calculating image 3 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de4951ecbda499387286b62cea9d6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06d7ed8b14e468583bafb6a0990d46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b330c6d425b24de184fd94775fc1585a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  25.574297199163595  min is  -12.414070712259742\n",
      "average is  -0.5808409879403911 median is  -2.353132606233322\n",
      "standard deviation is  6.498258503343043\n",
      "max is  7.835003083747155  min is  -6.073572960596067\n",
      "average is  0.0158436633867179 median is  0.0\n",
      "standard deviation is  0.3709582084116989\n",
      "minus values here ------------\n",
      "max value is  25.574297199163595 min value is  -12.414070712259742  mean value is  -0.596684651327109\n",
      " median value is  -2.3622988799128564  standard deviation is  6.512779454051397\n",
      "calculating image 4 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb2be1ba80945afbf6ad7e79b1eb8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5866874f36442fc92b8691375b1b750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14643b837cd64e91926fae2cbb2978a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.890951966558312  min is  -13.167526780066334\n",
      "average is  -1.3910599845209137 median is  -3.29663418139985\n",
      "standard deviation is  6.32583855249269\n",
      "max is  28.550394843638642  min is  -9.656487497901573\n",
      "average is  0.11767762740112027 median is  0.0\n",
      "standard deviation is  1.3807194571543089\n",
      "minus values here ------------\n",
      "max value is  22.890951966558312 min value is  -33.75577957715723  mean value is  -1.5087376119220341\n",
      " median value is  -3.2993775575479103  standard deviation is  6.4591623498122495\n",
      "calculating image 5 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cc24e9a1f54ba2817f759fb3e8e587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e2b496396e47b39d77599c346e38f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce4af97f0d44dc4ae11228ac3c3d4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.509380456399242  min is  -13.525261706652552\n",
      "average is  0.27303031188303345 median is  -1.9427756270605774\n",
      "standard deviation is  6.816677811988551\n",
      "max is  4.864386750375775  min is  -12.945740057093703\n",
      "average is  -0.18236971092743506 median is  0.0\n",
      "standard deviation is  1.0311998666609103\n",
      "minus values here ------------\n",
      "max value is  26.00823987335137 min value is  -13.525261706652552  mean value is  0.4554000228104684\n",
      " median value is  -1.8181825355812358  standard deviation is  6.967796861651744\n",
      "calculating image 6 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb48698fa674b24a0d4af4c1ffe6706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec940602bc1845258f550071bd1930b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d913ca82c054a87a3085daee55865e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.559572958096943  min is  -13.640880092763801\n",
      "average is  0.407243013990008 median is  -1.3561585084089618\n",
      "standard deviation is  6.313941431793247\n",
      "max is  14.963769215713473  min is  -13.099718459617145\n",
      "average is  -0.050611037347741895 median is  0.0\n",
      "standard deviation is  1.1657169575222455\n",
      "minus values here ------------\n",
      "max value is  22.559572958096943 min value is  -19.954665610926824  mean value is  0.4578540513377499\n",
      " median value is  -1.2059208688753493  standard deviation is  6.404949165531814\n",
      "calculating image 7 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013bb0ab1d714f55a03499b1b7ca4736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fe7220d9b54a66aef76adc6ed1bf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a37204b274f416683832bfa7e3f3581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  26.123989889380464  min is  -12.502979410557014\n",
      "average is  0.12100118153816387 median is  -1.7383380777874562\n",
      "standard deviation is  6.390644438457206\n",
      "max is  7.555912673506814  min is  -9.816332706890954\n",
      "average is  -0.03900270770718121 median is  0.0\n",
      "standard deviation is  0.766013652040214\n",
      "minus values here ------------\n",
      "max value is  26.123989889380464 min value is  -12.502979410557014  mean value is  0.1600038892453451\n",
      " median value is  -1.702996865588112  standard deviation is  6.408661526680641\n",
      "calculating image 8 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77692f295a346b7ba318dc6d16d9b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deacbfad7fb34e3997836e029f2a7e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f1944c3bce43d19d2244afefd9f776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  23.580877217496713  min is  -11.019609166875268\n",
      "average is  -0.3230107614690365 median is  -1.832829919849631\n",
      "standard deviation is  5.548218199378778\n",
      "max is  0.0  min is  0.0\n",
      "average is  0.0 median is  0.0\n",
      "standard deviation is  0.0\n",
      "minus values here ------------\n",
      "max value is  23.580877217496713 min value is  -11.019609166875268  mean value is  -0.3230107614690365\n",
      " median value is  -1.832829919849631  standard deviation is  5.548218199378778\n",
      "calculating image 9 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fc4a7f4e794055bef73279f792db37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b340378b94744fcb84dd2519a5f9ba7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9218a6053464963a899f2fed86b3535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  20.881560990522065  min is  -11.591256975438357\n",
      "average is  0.4341210841297933 median is  -1.161349560681229\n",
      "standard deviation is  5.984460214973684\n",
      "max is  6.3771252246943115  min is  -8.528968930768464\n",
      "average is  -0.04541955388785133 median is  0.0\n",
      "standard deviation is  0.8996207664434329\n",
      "minus values here ------------\n",
      "max value is  20.881560990522065 min value is  -11.591256975438357  mean value is  0.4795406380176445\n",
      " median value is  -1.0393630601859212  standard deviation is  6.053249764227305\n",
      "calculating image 10 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706935cdde384eebabb2e92aee5e9f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46326f603454e2e8ea4e0b553e45918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f57720b6cd40e4b92d4cb697e7cf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  19.10185944807413  min is  -10.615500515548323\n",
      "average is  -0.15558456517460054 median is  -1.5424441383906036\n",
      "standard deviation is  5.574033583581192\n",
      "max is  8.486830297041855  min is  -9.50102460961509\n",
      "average is  0.08490555624760464 median is  0.0\n",
      "standard deviation is  1.2744679961059788\n",
      "minus values here ------------\n",
      "max value is  24.245063775730976 min value is  -15.320495337954272  mean value is  -0.2404901214222052\n",
      " median value is  -1.5693653995904324  standard deviation is  5.71267842718814\n",
      "calculating image 11 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0517471f79f048c8925ea9fde188f8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a4f628f08947b69419843ecbb18ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0af20fbff1f48ecab9719b4e4c77846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  21.993463532726068  min is  -11.72007239568071\n",
      "average is  -0.46553406042564094 median is  -1.7632992312159266\n",
      "standard deviation is  5.11905995280935\n",
      "max is  25.640747119508372  min is  -14.594865357290612\n",
      "average is  0.013842630782263592 median is  0.0\n",
      "standard deviation is  1.364550448530717\n",
      "minus values here ------------\n",
      "max value is  21.993463532726068 min value is  -27.995041271313347  mean value is  -0.47937669120790455\n",
      " median value is  -1.7233408645357582  standard deviation is  5.293576139257289\n",
      "calculating image 12 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabd1f31d3ca4dffbefc4409b2d34616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e46d86cbbea461cb60f4fd779bebe9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808983a1547e450d8e7f5d486da486aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.080733423969555  min is  -16.18661166032517\n",
      "average is  0.48723126383492793 median is  -1.5251709246089433\n",
      "standard deviation is  6.425205265103427\n",
      "max is  25.753377628251183  min is  -13.642570603159967\n",
      "average is  0.43038293417875934 median is  0.0\n",
      "standard deviation is  2.574236023110473\n",
      "minus values here ------------\n",
      "max value is  21.895948530482826 min value is  -31.308240420383868  mean value is  0.05684832965616861\n",
      " median value is  -1.7580636037713777  standard deviation is  6.939680573852172\n",
      "calculating image 13 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eca483dcf064d59823adb8280e2a706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dcd73552b740ea88618aa32043c6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc17497f0164067a92fedae4762551d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  23.004568589548192  min is  -9.969636866988298\n",
      "average is  -0.27139383228591535 median is  -1.9614237796208638\n",
      "standard deviation is  6.0389839152374325\n",
      "max is  33.45202770561692  min is  -20.908874134413367\n",
      "average is  1.4396453559207556 median is  0.0\n",
      "standard deviation is  4.461714471707294\n",
      "minus values here ------------\n",
      "max value is  38.09950382768429 min value is  -32.7692668896011  mean value is  -1.7110391882066711\n",
      " median value is  -2.7199117575236187  standard deviation is  7.689703737508189\n",
      "calculating image 14 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73040dfdbed44a388075c35664c245dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab6a950166d46ee8679179f6fc88033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f058a0ecd0c941368eae0dd7982d8741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  20.287561137162353  min is  -13.356446936777287\n",
      "average is  -1.1483536123905538 median is  -2.6789455871165457\n",
      "standard deviation is  5.6745196641664615\n",
      "max is  10.742600965093587  min is  -6.537841920207001\n",
      "average is  0.7137341546117754 median is  0.0\n",
      "standard deviation is  2.342647228966057\n",
      "minus values here ------------\n",
      "max value is  20.287561137162353 min value is  -16.71992891413821  mean value is  -1.8620877670023288\n",
      " median value is  -3.014895616452283  standard deviation is  6.0805300663060935\n",
      "calculating image 15 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50d5cb11ab34a7480cab917eaf39b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfffa1245464daab7b620c5debf1b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50975478b1ff4258858d64eae48b1b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  24.03631634276654  min is  -14.649978523478346\n",
      "average is  2.222158707115044 median is  0.5924712405376785\n",
      "standard deviation is  7.357133394327018\n",
      "max is  22.53478872356004  min is  -5.127436436774323\n",
      "average is  0.1434810054038048 median is  0.0\n",
      "standard deviation is  1.4522023736382006\n",
      "minus values here ------------\n",
      "max value is  24.03631634276654 min value is  -23.15452979741307  mean value is  2.0786777017112392\n",
      " median value is  0.4259217430591353  standard deviation is  7.486542760397414\n",
      "calculating image 16 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b15e64f606947d389211d811f88ca7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed461bfdf6e444a9a8c8210778fe62b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dc5a9969fd4e02bac7c7f28b4bfa87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  22.60978589657176  min is  -13.009866945469666\n",
      "average is  -0.7613976697281823 median is  -2.781826860922828\n",
      "standard deviation is  6.546458574421462\n",
      "max is  30.48990023118251  min is  0.0\n",
      "average is  1.784186012248232 median is  0.0\n",
      "standard deviation is  4.135421707296228\n",
      "minus values here ------------\n",
      "max value is  22.60978589657176 min value is  -31.450037769313433  mean value is  -2.5455836819764146\n",
      " median value is  -3.8850842265571828  standard deviation is  7.763557692461002\n",
      "calculating image 17 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb31671e474c428c8da6a78a6fee3bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccd178764b847958e0223136113a242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5657b68fc9495595b71667504ca164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  20.903690584372633  min is  -13.17747851392621\n",
      "average is  1.4943852597993303 median is  1.048506210001947\n",
      "standard deviation is  6.356190762105321\n",
      "max is  21.337451190451755  min is  -15.535892870358959\n",
      "average is  -0.035334841819639785 median is  0.0\n",
      "standard deviation is  1.3283370760422963\n",
      "minus values here ------------\n",
      "max value is  24.386011485858813 min value is  -23.025335683722112  mean value is  1.5297201016189699\n",
      " median value is  1.032672646740934  standard deviation is  6.547040475081385\n",
      "calculating image 18 of 18\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a23eb44385648cc8d6a006cbbf84cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3370102b7e748b19b036bd78362a937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d427847ca16c4e8b97c3fd3b825dcc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is  23.40619882987705  min is  -14.008613077725727\n",
      "average is  -1.6334277758653013 median is  -3.1111504997777004\n",
      "standard deviation is  6.046456037407272\n",
      "max is  7.927474742932542  min is  -12.971638230802292\n",
      "average is  -0.054050013257584774 median is  0.0\n",
      "standard deviation is  0.8721335447259593\n",
      "minus values here ------------\n",
      "max value is  23.40619882987705 min value is  -14.008613077725727  mean value is  -1.5793777626077168\n",
      " median value is  -3.063972737378844  standard deviation is  6.065982071333976\n",
      "Finished analysis woohoo\n"
     ]
    }
   ],
   "source": [
    "##### CHANGE THIS TO YOUR FOLDER##################\n",
    "##################################################\n",
    "bigfol=r\"C:\\Users\\Image Processing PC\\Downloads\\OneDrive_2_10-8-2021\"\n",
    "##################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialise dependencies\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "import imageio\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "#import hcluster\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from math import pow\n",
    "import scipy.signal \n",
    "%matplotlib qt\n",
    "#template matching\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#General Functions\n",
    "def listdirs(folder):\n",
    "## a function which lists the files in a folder and adds to a list. returns a list of folders, \n",
    "##input folder: the file path to folder\n",
    "    return [\n",
    "        d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))\n",
    "        if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "def makeclippingmask(image):\n",
    "    \n",
    "\n",
    "    #makes a clipping mask around each bright spot so the analysis isn't thrown off\n",
    "    grayA = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    blurred = cv.GaussianBlur(grayA, (11,11), 0)\n",
    "\n",
    "    #watershed thresholding. Based on: https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html\n",
    "    src = image.copy()\n",
    "    \n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    imgLaplacian = np.clip(imgLaplacian, 0, 255)\n",
    "    imgLaplacian = np.uint8(imgLaplacian)\n",
    "    #cv.imshow('Laplace Filtered Image', imgLaplacian)\n",
    "    #cv.imshow('New Sharped Image', imgResult)\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n",
    "   # _, bw2 = cv.threshold(grayA, 30, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #plt.imshow(bw)\n",
    "    bw = cv.adaptiveThreshold(bw, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 37, 1)\n",
    "    #cv.imshow('Binary Image', bw)\n",
    "    \n",
    "    \n",
    "    opening = cv.morphologyEx(bw,cv.MORPH_OPEN,kernel, iterations = 3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    # Threshold to obtain the peaks\n",
    "    # This will be the markers for the foreground objects\n",
    "    _, sure_fg = cv.threshold(dist_transform, 0.2, 1.0, cv.THRESH_BINARY)\n",
    "    # Dilate a bit the dist image\n",
    "    kernel1 = np.ones((3,3), dtype=np.uint8)\n",
    "    sure_fg = cv.dilate(sure_fg, kernel1)\n",
    "    ret, markers = cv.connectedComponents(np.uint8(sure_fg))\n",
    "    \n",
    "    \n",
    "    #cv.imshow('Final Result', sure_fg)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.float32(sure_fg)\n",
    "    sure_bg = np.float32(sure_bg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    #cv.imshow('Distance Transform Image', dist_transform)\n",
    "    \n",
    "    # Marker labelling\n",
    "    \n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    #print(markers.shape)\n",
    "    \n",
    "    markers = cv.watershed(imgResult,markers)\n",
    "    #print(markers)\n",
    "    \n",
    "    mask2 = np.zeros(image.shape[:2], dtype= np.uint8)\n",
    "    mask2[markers >1] = [255]\n",
    "    \n",
    "    #colours=((255,255,255))\n",
    "    # Fill labeled objects with random colors\n",
    "    #for i in range(markers.shape[0]):\n",
    "    #    for j in range(markers.shape[1]):\n",
    "    #        index = markers[i,j]\n",
    "    #        if index>0:\n",
    "    #            mask2[i,j] = 255\n",
    "    \n",
    "\n",
    "    image_rgb=image.copy()\n",
    "    image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    #plt.imshow(image_blocked)\n",
    "    return image_blocked\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_camera_wb=True,\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1))\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        \n",
    "def saveexcelfun(dimercoord,corecoord,savepath):\n",
    "#Save the coordinates of everything to an excel spreadsheet. Yeah I know it's ugly. \n",
    "#input: dimercoord- the dimer coordinates\n",
    "########corecoord- the core coordinates \n",
    "########savepath- the folder location where the files will be saved \n",
    "    columns=['Before Dimers xval']\n",
    "    saveexcel=savepath+\".\"+\"xlsx\"\n",
    "    beforedimercentres = pd.DataFrame({'Before Dimers xval':dimercoord})\n",
    "    try:\n",
    "        aftercorecentres = pd.DataFrame({'After core xval': corecoord})\n",
    "    except:\n",
    "        aftercorecentres=pd.DataFrame({'After core xval': np.array([0]), \n",
    "                                'After core yval': np.array([0])})\n",
    "\n",
    "   \n",
    "    writer = pd.ExcelWriter(saveexcel,engine='xlsxwriter')\n",
    "    workbook=writer.book\n",
    "    worksheet=workbook.add_worksheet('DimersPicked')\n",
    "    writer.sheets['DimersPicked'] = worksheet\n",
    "    worksheet2=workbook.add_worksheet('CoresPicked')\n",
    "    writer.sheets['CoresPicked'] = worksheet2\n",
    "\n",
    "\n",
    "    beforedimercentres.to_excel(writer,sheet_name='DimersPicked',startrow=1 , startcol=0)\n",
    "    #worksheet.write_string(beforedimercentres.shape[0] + 4, 0, beforedimercentres.name)\n",
    "\n",
    "    aftercorecentres.to_excel(writer,sheet_name='CoresPicked',startrow=1, startcol=3)\n",
    "    \n",
    "\n",
    "    writer.save()\n",
    "def savetextfilefun(data,savepath,datastring):\n",
    "##### A function which saves an array to a text file. Is a little buggy in that sometimes there's weird spaces. \n",
    "##### reccomend the excel save functions instead. Python struggles to re-read these text tiles\n",
    "\n",
    "    savetextstring=savepath+datastring+\".txt\"\n",
    "    file = open(savetextstring,\"w\")\n",
    "    for dataentry in data:\n",
    "        arr_of_strings = np.array2string(dataentry)\n",
    "        file.write(arr_of_strings) \n",
    "    file.close() \n",
    "    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "## A function which reads in images and adds them to a list of images.\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "## note !! The images wil be read in with open cv, and will be in BGR format and will look strange unless converted\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "def load_images_from_foldercv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to RGB\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "       \n",
    "        if img is not None:\n",
    "            img= cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "def load_images_from_folderhsv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to HSV\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        img= cv.cvtColor(img,  cv.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#####################################################\n",
    "###################################################\n",
    "#Template matching functions\n",
    "\n",
    "\n",
    "def findidealimagescale(image,template):\n",
    "    # loop over the images to find the template in\n",
    "   \n",
    "        # load the image, convert it to grayscale, and initialize the\n",
    "        # bookkeeping variable to keep track of the matched region\n",
    "        \n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    template=cv.cvtColor(template, cv.COLOR_HSV2RGB)\n",
    "    template=cv.cvtColor(template, cv.COLOR_RGB2GRAY)\n",
    "    #template.astype(np.uint8)\n",
    "    #gray.astype(np.uint8)\n",
    "    found = None\n",
    "    scalefin= None\n",
    "    (h, w) = template.shape[:2]\n",
    "    i=0\n",
    "    # loop over the scales of the image\n",
    "    for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "        # resize the image according to the scale, and keep track\n",
    "        # of the ratio of the resizing\n",
    "        resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "        r = gray.shape[1] / float(resized.shape[1])\n",
    "        # if the resized image is smaller than the template, then break\n",
    "        # from the loop\n",
    "        if resized.shape[0] < h or resized.shape[1] < w:\n",
    "            break\n",
    "        result = cv.matchTemplate(gray, template, cv.TM_SQDIFF_NORMED)\n",
    "        (minval, _, minloc, _) = cv.minMaxLoc(result)\n",
    "        if found is None or minval < found:\n",
    "            found = minval\n",
    "            scalefin=scale\n",
    "    return scalefin \n",
    "        \n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "        \n",
    "def nonmaxsuppression(xCoords,yCoords,template):\n",
    "    center_coordinates=[]\n",
    "    rects=[]\n",
    "    rectangle_coordinates=[]\n",
    "    (w, h) = template.shape[:2]\n",
    "    #print(w)\n",
    "    #print(h)\n",
    "## stops the overcounting of variables with nonmax suppression and returns an updated list\n",
    "    for (x, y) in zip(xCoords, yCoords):\n",
    "    # update our list of rectangles\n",
    "        rects.append((x, y, x +w, y + h))\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        center_coordinates.append((startX+h//2,startY+h//2))\n",
    "        rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "     \n",
    "    #print(\"center coordinates are \",center_coordinates)\n",
    "    #print(\"rectangle_coordinates are \", rectangle_coordinates)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithm(img_hsv,template, method,threshold):\n",
    "# defines the template matching algorithm and finds the minimum locations\n",
    "#inputs: img_rgb- the image to be matched in HSV format\n",
    "#########template- the template to be matched in HSV format\n",
    "#########method- the method of determining the minim. cv.TM_SQDIFF_NORMED is good for colour\n",
    "##### extras found here: https://docs.opencv.org/master/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d\n",
    "#########threshold: the threshold where the minimum is defined. Variable. May want to do something with min_val and max\n",
    "#outputs: locations_of_minimum- a really big array that needs to be zipped. \n",
    "#Note: this works on colour (3 d) images but may want to change to just hue\n",
    "    \n",
    "    mat_of_matching_results=cv.matchTemplate(img_hsv,template,method) \n",
    "    #This is to get some details about the minimum but isn't actually used\n",
    "    #print(\"template matching done\")\n",
    "    (min_val, max_val, _, max_loc) = cv.minMaxLoc(mat_of_matching_results)\n",
    "    #print(\"The min is done\")\n",
    "    #print(min_val)\n",
    "    #print(max_val)\n",
    "    (yCoords, xCoords) = np.where( mat_of_matching_results <= ((max_val-min_val)/threshold)+min_val)\n",
    "    while (len(xCoords))>250000:\n",
    "        threshold=threshold+0.5\n",
    "        (yCoords, xCoords) = np.where( mat_of_matching_results <= ((max_val-min_val)/threshold)+min_val)\n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template)\n",
    "    \n",
    "    #print(locations_of_minimum)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithmscikit(img_hsv,template,threshold):\n",
    "    mat_of_matching_results = match_template(img_hsv, template,pad_input=True)\n",
    "    max_val=np.max(mat_of_matching_results)\n",
    "    min_val=np.min(mat_of_matching_results)\n",
    "    #max = np.unravel_index(np.argmax(result), result.shape)\n",
    "    #(min_val, max_val, _, max_loc) = cv.minMaxLoc(mat_of_matching_results)\n",
    "    threshold2=((max_val-min_val)/threshold)+min_val\n",
    "    peaks=peak_local_max(image, min_distance=10, threshold_abs=None, threshold_rel=0.75)\n",
    "    print(peaks)\n",
    "    xCoords=peaks[:,1]\n",
    "    yCoords=peaks[:,2]\n",
    "    center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def imagetempmatch(imgpath,img_rgb,threshold):\n",
    "## performs the template matching function on each template image found in imgpath\n",
    "## input: imgpath: a string pointing to the folder the template images are contained in\n",
    "##########img_rgb: the image to be matched, in rgb format \n",
    "##########threshold: the threshold at which the minimum is accepted. The minimum value is the value where the \n",
    "#####################template matching function thinks that the image is matched. Note, this may be a maximum \n",
    "####################for other methods\n",
    "    #loads the template images in as HSV\n",
    "    images=load_images_from_folderhsv(imgpath)\n",
    "    #Creates a mask which has the shape of the image to be matched. The dtype is important or error will occur. \n",
    "    # This mask is to test whether the template matching has counted the same point multiple times\n",
    "    mask = np.zeros(img_rgb.shape, dtype=np.uint8)\n",
    "    res=[[]];\n",
    "    scale=findidealimagescale(img_rgb,images[0])\n",
    "    #print(scale)\n",
    "    resized = imutils.resize(img_rgb, width = int(img_rgb.shape[1]*scale))\n",
    "    for template in tqdm(images):\n",
    "        #for each template, the width and height is taken\n",
    "        \n",
    "        w=16\n",
    "        h=16\n",
    "        \n",
    "        #big image converted to hsv format\n",
    "        img_hsv= cv.cvtColor(resized,  cv.COLOR_RGB2HSV)\n",
    "        #the location minima identified with the template matching algorithm\n",
    "        center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithm(img_hsv,template,cv.TM_SQDIFF_NORMED,threshold)\n",
    "        #center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithmscikit(img_hsv,template,threshold)\n",
    "        \n",
    "        #print(\"locations of min are\", locations_of_min)\n",
    "        # the locations are checked for multiple counting of the same point. \n",
    "        #particle_count=checkfordoublecounting(img_hsv,locations_of_min)\n",
    "        #print(particle_count)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "\n",
    "def blockimagecombo(image_rgb, points,r,bok):\n",
    "    #print(points)\n",
    "    if bok==1:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,255), -1)\n",
    "    elif bok==2:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,0), 2)\n",
    "        \n",
    "    else:\n",
    "        mask2 = np.zeros(image_rgb.shape[:2], dtype= np.uint8)\n",
    "        for pt in points: \n",
    "            #print(pt)\n",
    "            mask2 = cv.circle(mask2,pt,r, (255,255,255), -1)\n",
    "            \n",
    "            # a rectangle is drawn on the mask, which marks where the points are \n",
    "        #invmask=255-mask2\n",
    "        #This is an inbuilt cv function which clips the image around the mask. \n",
    "        #plt.imshow(cv.bitwise_and(image_rgb, image_rgb, mask=invmask))\n",
    "        image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "\n",
    "def performtemplatematching(image_rgb,imgpath,bok,threshold):\n",
    "## a function which performs template matching on the images and blocks them depending on whether\n",
    "## we want to keep the particles or block them out for more accuracy \n",
    "#input: image_rgb: the big image in rgb format where we are looking for matches\n",
    "########imgpath: the path to the template images, as a string\n",
    "#########bok: block or keep. 0 is for keeping, 1 is for blocking with a rectange\n",
    "#########threshold: the threshold for the minimum values. Variable. \n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=imagetempmatch(imgpath,image_rgb,threshold)\n",
    "    r=round(w/1.5)\n",
    "\n",
    "    correctedimg=blockimagecombo(image_rgb,center_coordinates ,r,bok)\n",
    "    return correctedimg,center_coordinates,r\n",
    "\n",
    "def performsaveimage(image,path):\n",
    "## saves image using pillow, which is a lot faster than matplot lib. \n",
    "    img_rgb_corr=image\n",
    "    try:\n",
    "        im_pil = Image.fromarray(img_rgb_corr)\n",
    "        im_pil.save(path, compress_level=1)\n",
    "    except:\n",
    "        exception=1\n",
    "\n",
    "def savetotrainingfol(foldername,image,points):\n",
    "## saves the cropped images to a folder, for use in machine learning. uses a 16 pixel box.\n",
    "#input: foldername: name of the folder where you want the images stored\n",
    "#######image: an image in rgb format which you want to cut up\n",
    "########points: the coordinates of the particles which you have selected. \n",
    "    boxwid=round(16/2)\n",
    "    w=16\n",
    "    for j,pt in enumerate(points):\n",
    "        savepathfol= addstringwithtime(foldername +'\\\\')\n",
    "        savepath= savepathfol+str(j)+\"registeredimg\" + \".\" + \"png\"\n",
    "        #savepath=os.path.join(savepathfol, str(j)+\"registeredimg\" + \".\" + \"png\")\n",
    "        lilimage=image[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        performsaveimage(lilimage,savepath)\n",
    "def blockoutunwantedparticles(analpath,sat_img,path,threshold):\n",
    "## a function which blocks out that particles which are interfering with analysis i.e. clumps and clusters\n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#output: correctedimgcore, the corrected image after accounting for cores and clumps\n",
    "# These images are hardcoded into a folder, so the code has some dependencies. But any exmaples of the correct size will do\n",
    "    #The threshold of 0.25 seems to be highly variable\n",
    "    correctedimg,_,r= performtemplatematching(sat_img, path,1,threshold)\n",
    "    return correctedimg,r\n",
    "\n",
    "def unwantedparticleblocking(analpath,sat_img):\n",
    "    #clusterpath=  r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\Cluster\"\n",
    "    #threshold= 0.25\n",
    "    #correctedimgcluster=blockoutunwantedparticles(analpath,sat_img,clusterpath,threshold)\n",
    "    \n",
    "    clumppath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\clump\"\n",
    "    threshold=4\n",
    "    savepath=os.path.join(analpath, \"clumpcorrectedimg\" + \".\" + \"png\")\n",
    "    correctedimgclump,r=blockoutunwantedparticles(analpath,sat_img,clumppath,threshold)\n",
    "    performsaveimage(correctedimgclump,savepath)\n",
    "    \n",
    "    corepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\core2\"\n",
    "    threshold=10\n",
    "    correctedimgcore,r=blockoutunwantedparticles(analpath,correctedimgclump,corepath,threshold)\n",
    "    savepath=os.path.join(analpath, \"corecorrectedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgcore,savepath)\n",
    "    \n",
    "    return correctedimgcore,r\n",
    "    \n",
    "def keepmatchedparticles(path,image,threshold):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "    correctedimgdimer,pointsdimer,r= performtemplatematching(image, path, 0, threshold)\n",
    "    \n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "                                                              \n",
    "\n",
    "def performkeepmatchedparticles(analpath,image):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "#outputs: the selected image and the dimer points selected\n",
    "    dimerpath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\dimer2\"\n",
    "    threshold=2\n",
    "    \n",
    "    correctedimgdimer,pointsdimer,r=keepmatchedparticles(dimerpath,image,threshold)\n",
    "    savepath=os.path.join(analpath, \"pickeddimersimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgdimer,savepath)\n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "\n",
    "\n",
    "\n",
    "def getaveragevalueshsv(image,points,w,h,analpath):\n",
    "# a function to get the average values of the image in rgb format\n",
    "#inputs: image: the hsv image\n",
    "#########points: the selected dimer values\n",
    "#########w,h- the width and height in pixels\n",
    "#########analpath: the path to the analysis folder\n",
    "#outputs: an array of the average colour of the red divided by the green vector\n",
    "\n",
    "    average_colour_rDivg=[]\n",
    "    #converts the image to hsv\n",
    "    image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_rDivg)), \" min is \",np.min(np.array(average_colour_rDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_rDivg)), \"median is \", np.mean(np.array(average_colour_rDivg)) )\n",
    "    print(\"standard deviation is \", np.mean(np.array(average_colour_rDivg)))\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getaveragevaluesLAB(image,points,analpath):\n",
    "    w=8\n",
    "    labim = rgb2lab(image)\n",
    "    l_vec,a_vec,b = cv.split(labim)\n",
    "    average_colour_aDivg=[]\n",
    "    max_val_lDivg=[]\n",
    "    average_lum=[]\n",
    "    #converts the image to hsv\n",
    "    #image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    #image_hue=np.true_divide(image[:,:,0], image[:,:,1], where=(image[:,:,0]!=0) | (image[:,:,1]!=0))\n",
    "    #image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=a_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            \n",
    "            crop_im_lval=l_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval_lval=crop_im_lval.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_aDivg.append(np.mean(dividedval))\n",
    "            \n",
    "            max_val_lDivg.append(np.max(dividedval_lval))\n",
    "            average_lum.append(np.mean(dividedval_lval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    if not average_colour_aDivg:\n",
    "        average_colour_aDivg=[0]\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_aDivg)), \" min is \",np.min(np.array(average_colour_aDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_aDivg)), \"median is \", np.median(np.array(average_colour_aDivg)) )\n",
    "    print(\"standard deviation is \", np.std(np.array(average_colour_aDivg)))\n",
    "    return np.array(average_colour_aDivg),np.array(average_lum),np.array(max_val_lDivg)\n",
    "\n",
    "def averagehistogramshift(correctedimgdimer,pointsdimer,correctedimgtarget,threshold,analpath):\n",
    "# a function which uses the average shift of the particle colour (either hue or rgb depending ) to \n",
    "#select the particles which have shifted in the after image \n",
    "#inputs: correctedimgdimer: the image with only dimers selected\n",
    "#########pointsdimer: the locations of the dimers in the image\n",
    "#########correctedimgtarget: the registered image after target added wherein the coordinates of the selected\n",
    "# dimers have been used to clip it\n",
    "#########threshold: the values which the shifted average value must be above or below. was 0.2 \n",
    "#output: loc- the shifted selected particles. \n",
    "    avdim,ldim,maxldim=getaveragevaluesLAB(correctedimgdimer,pointsdimer,analpath)\n",
    "    \n",
    "    avcore,lcore,maxlcore=getaveragevaluesLAB(correctedimgtarget,pointsdimer,analpath)\n",
    "    minus= np.array(avdim)-np.array(avcore)\n",
    "    minus_l=np.array(ldim)-np.array(lcore)\n",
    "    \n",
    "    print(\"minus values here ------------\")\n",
    "    print(\"max value is \", np.max(minus), \"min value is \", np.min(minus), \" mean value is \", np.mean(minus))\n",
    "    print(\" median value is \", np.median(minus), \" standard deviation is \", np.std(minus))\n",
    "    loc=np.array(pointsdimer)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    ldim2=ldim[np.logical_and(minus>5,maxlcore>1)]\n",
    "    loc=loc[ldim2<30]\n",
    "    r=8\n",
    "    #loc=np.array(pointsdimer)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    targetpicked= blockimagecombo(correctedimgtarget,loc,r,0)\n",
    "    #average_values=np.array(minus)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    average_values=np.array(minus)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    #print(minus)\n",
    "    #average_values=average_values[ldim2<30]\n",
    "    #print(ldim2)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"tarmaskedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(targetpicked,savepath)\n",
    "    return loc,average_values.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def performtemplatetrainingonimages(transtarimg,analpath,sat_img):\n",
    "    \n",
    "\n",
    "    #blocks unwated particles\n",
    "    correctedimgcore,r=unwantedparticleblocking(analpath,sat_img)\n",
    "    \n",
    "    \n",
    "    #selects dimers\n",
    "    correctedimgdimer,pointsdimer,r=performkeepmatchedparticles(analpath, correctedimgcore)\n",
    "    image_circle=blockimagecombo(sat_img, pointsdimer,16,2)\n",
    "    savepath=os.path.join(analpath, \"dimerCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #print(np.unique(np.array(pointsdimer),axis=0))\n",
    "    #pointsdimer_corrected=np.unique(np.array(pointsdimer),axis=0)\n",
    "    pointsdimer_corrected=pointsdimer\n",
    "    #uses those points to select the same points in the target image \n",
    "    \n",
    "    transtarimg=makeclippingmask(transtarimg)\n",
    "    correctedimgtarget=blockimagecombo(transtarimg,pointsdimer_corrected,r,0)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgtarget,savepath)\n",
    "    \n",
    "    #scans the before and after dimers to determine if the particles shift in hue\n",
    "    threshold=-0.001\n",
    "    selected_target_locations,average_values=averagehistogramshift(correctedimgdimer,pointsdimer_corrected,correctedimgtarget,threshold,analpath)\n",
    "    image_circle=blockimagecombo(transtarimg, selected_target_locations,16,2)\n",
    "    savepath=os.path.join(analpath, \"targetCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #comment out if don't want\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\before\",sat_img,pointsdimer_corrected)\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\after\",transtarimg,selected_target_locations)\n",
    "    \n",
    "    return selected_target_locations,pointsdimer_corrected,average_values\n",
    "\n",
    "\n",
    "######### Extra functions\n",
    "\n",
    "def getindividualfoldersandsuch(bigfol):\n",
    "# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\n",
    "    topfolders=listdirs(bigfol)\n",
    "    subfolders=[0]\n",
    "    for nextfolders in topfolders:\n",
    "        subfolders= subfolders+ listdirs(nextfolders)\n",
    "    subfolders.pop(0)\n",
    "    #print(subfolders)\n",
    "    subfolders=np.array(subfolders).reshape(-1,1)\n",
    "    #print(subfolders)\n",
    "    return subfolders\n",
    "def searchforsatandtargetfolders(folder):\n",
    "#finds the satellite and targetfolders using regexp\n",
    "    subfolders2 = folder.tolist()\n",
    "    subfolders3=str(subfolders2).replace('[','').replace(']','').replace('\\\\\\\\','\\\\')\n",
    "\n",
    "    listexpfolders=listdirs(subfolders3[1:len(subfolders3)-1])\n",
    "    beforefol = [x for x in listexpfolders if re.search(\"satellite\",x)]\n",
    "    beforefol=beforefol[0]\n",
    "    afterfol= [x for x in listexpfolders if re.search(\"target\",x)]\n",
    "    afterfol=afterfol[0]\n",
    "    \n",
    "    return beforefol,afterfol\n",
    "\n",
    "def createanalysisfolder(beforefol,string):\n",
    "#creates an analysis folder in the address above where the satellite and target folders are located.\n",
    "    oneuppath=os.path.dirname(beforefol)\n",
    "    analysisfolderpath=oneuppath+\"\\\\\"+string\n",
    "    try:\n",
    "        os.mkdir(analysisfolderpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    print(analysisfolderpath)\n",
    "    print(\"processing images\")\n",
    "    return analysisfolderpath,oneuppath\n",
    "\n",
    "def createimagesubfolderforsaving(pathtomatch,analysisfolderpath):\n",
    "# creates a folder with the name of the image in the analysis folder \n",
    "    pathtomatch=beforeimfile[j]\n",
    "    matchingsearch=re.search(\"IMG_.*.CR2\",pathtomatch)\n",
    "    savefilespath=analysisfolderpath+\"\\\\\"+matchingsearch.group()+\"\\\\\"\n",
    "    try: \n",
    "        os.mkdir(savefilespath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    return savefilespath\n",
    "def addstringwithtime(savefilespath):\n",
    "# adds the current date and time so there's no saving over the top of different analysis\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    savepath=savefilespath+dt_string\n",
    "    return savepath\n",
    "def makeanalysisfolder(savefilespath,string):\n",
    "# makes a directory in the folder which matches the image name which says 'analysis'\n",
    "    analpath=os.path.join(savefilespath,string)\n",
    "                        #saves the registered image\n",
    "    try: \n",
    "        os.mkdir(analpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    return analpath\n",
    "\n",
    "################ THRESHOLDING\n",
    "def gethuevaluesthreshHSV(image,points):\n",
    "    image_hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    image_hue=image_hsv[:,:,0]\n",
    "    w=8\n",
    "    average_colour_rDivg=[]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getcentroidsandcenters(image):\n",
    "    \n",
    "    #wmakes an excellent binary image\n",
    "    src = image.copy()\n",
    "\n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_RGB2GRAY)\n",
    "    #_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    contours, hierarchy = cv.findContours(bw, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    list_of_centres=[]\n",
    "    boundRect = [None]*len(contours)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        center_circle, _ = cv.minEnclosingCircle(contours_poly[i])\n",
    "        list_of_centres.append((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "        \n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "        cv.circle(src, ((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1])))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        #print((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "    #picked_rectangles=non_max_suppression_fast(np.array(boundRect),0.01)\n",
    "    #h=16;\n",
    "    #for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "    #    list_of_centres.append((np.round((startX+endX/2)),np.round((startY+endY/2))))\n",
    "        #cv.circle(src, (np.int(np.round((startX+endX/2))),np.int(np.round((startY+endY/2)))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "    #cv.imshow(\"Image\", src)\n",
    "    #plt.show()\n",
    "    #list_of_centres=np.array(list_of_centres)\n",
    "    #print(list_of_centres)\n",
    "    return list_of_centres\n",
    "\n",
    "\n",
    "def performthresholding(beforeim,afterim,analpath):\n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    average_colour=gethuevaluesthreshHSV(image,list_of_centres)\n",
    "    dimer_points= np.array(list_of_centres)[average_colour <= 20]\n",
    "    \n",
    "    average_colour_dimer=gethuevaluesthreshHSV(image,dimer_points)\n",
    "    dimers_blocked=blockimagecombo(beforeim, dimer_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"dimersblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(dimers_blocked,savepath)\n",
    "    target_image=blockimagecombo(afterim, dimer_points,8,0)\n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image,savepath)\n",
    "    average_colour_after=gethuevaluesthreshHSV(target_image,dimer_points)\n",
    "    particle_difference=average_colour_dimer-average_colour_after\n",
    "    target_points= np.array(dimer_points)[particle_difference < -10]\n",
    "    target_image_picked=blockimagecombo(afterim, target_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"targetpicked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image_picked,savepath)\n",
    "    return dimer_points,target_points\n",
    "    \n",
    "#########################\n",
    "\n",
    "\n",
    "subfolders=getindividualfoldersandsuch(bigfol)\n",
    "\n",
    "for folder in subfolders:\n",
    "    #automatically find the before and after folder \n",
    "    beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    \n",
    "    #Create the relevant folder for saving,as well as the path one folder up \n",
    "    analysisfolderpath_temp,oneuppath_temp=createanalysisfolder(beforefol,\"Analysisfolder_Template\")\n",
    "    analysisfolderpath_thresh,oneuppath_thresh=createanalysisfolder(beforefol,\"Analysisfolder_thresholding\")\n",
    "    \n",
    "    \n",
    "    #loadsall the images in \n",
    "\n",
    "    imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction(beforefol,afterfol)\n",
    "    print(\"processed and converted images\")\n",
    "    \n",
    "    \n",
    "    response=[0]*len(beforeimfile)\n",
    "    dimercount=[0]*len(beforeimfile)\n",
    "    targetcount=[0]*len(beforeimfile)\n",
    "    response_thresh=[0]*len(beforeimfile)\n",
    "    dimercount_thresh=[0]*len(beforeimfile)\n",
    "    targetcount_thresh=[0]*len(beforeimfile)\n",
    "    #t = tqdm(total=len(imbef))\n",
    "    for j,image in enumerate(imbef):\n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.25)\n",
    "            #sleep(0.1)\n",
    "\n",
    "        pathtomatch=beforeimfile[j]\n",
    "        savefilespath_temp= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_temp)\n",
    "        savefilespath_thresh= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_thresh)\n",
    "        \n",
    "        \n",
    "        #add on the currentdate and time \n",
    "        savepath_temp=addstringwithtime(savefilespath_temp)\n",
    "        savepath_thresh=addstringwithtime(savefilespath_thresh)\n",
    "        \n",
    "        \n",
    "        print(\"calculating image \"+str(j+1)+\" of \"+ str(len(imbef)))\n",
    "        \n",
    "        #make an analysis folder which says analysis in the image folder just created \n",
    "        analpath_temp=makeanalysisfolder(savefilespath_temp,\"Analysisimages_Template\")\n",
    "        analpath_thresh=makeanalysisfolder(savefilespath_thresh,\"Analysisimages_thresholding\")\n",
    "        \n",
    "        #spot matches the before and after images \n",
    "        transimaf=imgregfun(image, imaf[j])\n",
    "        #saves the redistered image\n",
    "        saveregisteredimage=os.path.join(analpath_temp, \"registeredimg\" + \".\" + \"png\")\n",
    "        performsaveimage(transimaf,saveregisteredimage)\n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "        #    pbar.update(0.5)\n",
    "        #    sleep(0.1)\n",
    "        \n",
    "        #uncomment if you want a crop box    \n",
    "        #height, width = image.shape[:2]\n",
    "        #boxwid=round(1500/2)\n",
    "        #centreimagebefore=image[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        #centreimageafter=transimaf[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        centreimagebefore=makeclippingmask(image)\n",
    "        print(\"Made the clipping Mask\")\n",
    "        #plt.imshow(centreimagebefore)\n",
    "        centreimageafter=makeclippingmask(transimaf)\n",
    "        \n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.75)\n",
    "            #sleep(0.1)\n",
    "        dimer_points,target_points=performthresholding(centreimagebefore,centreimageafter,analpath_thresh)\n",
    "        \n",
    "        #perform the template matching and see which particles shift\n",
    "        targetpicked,pointsdimer,average=performtemplatetrainingonimages(centreimageafter,analpath_temp,centreimagebefore)\n",
    "       \n",
    "        \n",
    "        #saves the to an excel spreadsheet and saves the results to a list to get the overall results at the end \n",
    "        #if I feel bothered I can add something in that uses the already analysed images but meh \n",
    "        dimercount[j]=len(pointsdimer)\n",
    "        targetcount[j]=len(targetpicked)\n",
    "        try: \n",
    "            response[j]=(len(targetpicked)/len(pointsdimer))*100\n",
    "        except:\n",
    "            response[j]=0\n",
    "        \n",
    "        saveexcelfun(pointsdimer,targetpicked,savepath_temp)\n",
    "        \n",
    "        dimercount_thresh[j]=len(dimer_points)\n",
    "        targetcount_thresh[j]=len(target_points)\n",
    "        try: \n",
    "            response_thresh[j]=(len(target_points)/len(dimer_points))*100\n",
    "        except:\n",
    "            response_thresh[j]=0\n",
    "        #print(pointsdimer.type)\n",
    "        #print(dimer_points.type)\n",
    "        #saveexcelfun(dimer_points,target_points,savepath_thresh)\n",
    "  \n",
    "        \n",
    "        \n",
    "        #save important coordinates to a text file for later analysis\n",
    "        #Probably can delete this don't know what it's used for anymore \n",
    "        #savetextfilefun(np.array(pointsdimer),savepath,\"dimerbefore\")\n",
    "        #savetextfilefun(np.array(targetpicked),savepath,\"selectedResponse\")\n",
    "\n",
    "    print(\"Finished analysis woohoo\")\n",
    "    #t.close()\n",
    "    #Find the folders which contain the analysis and read the text files\n",
    "    #Find the image folders\n",
    "    searchfolder=oneuppath_temp\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_temp= searchfolder+'\\\\'+\"Analysisfolder_Template\"\n",
    "    imagefilefolders=os.listdir(savedir_temp)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount),'target_picked':np.array(targetcount),'response': np.array(response)})\n",
    "    responsepath_temp=savedir_temp+'\\\\'+\"responseforallimages.xlsx\"\n",
    "    responseforexcel.to_excel(responsepath_temp) \n",
    "    \n",
    "    searchfolder_thresh=oneuppath_thresh\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_thresh= searchfolder+'\\\\'+\"Analysisfolder_thresholding\"\n",
    "    imagefilefolders=os.listdir(savedir_thresh)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount_thresh),'target_picked':np.array(targetcount_thresh),'response': np.array(response_thresh)})\n",
    "    responsepath_thresh=savedir_thresh+'\\\\'+\"responseforallimages.xlsx\"\n",
    "    responseforexcel.to_excel(responsepath_thresh) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reasonable-repeat",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Image Processing PC\\\\Downloads\\\\2021-09-21\\\\2021-09-21'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5b0fbb19bf4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m \u001b[0msubfolders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetindividualfoldersandsuch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigfol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubfolders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5b0fbb19bf4c>\u001b[0m in \u001b[0;36mgetindividualfoldersandsuch\u001b[1;34m(bigfol)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetindividualfoldersandsuch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigfol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[1;31m# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m     \u001b[0mtopfolders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlistdirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigfol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m     \u001b[0msubfolders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnextfolders\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopfolders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5b0fbb19bf4c>\u001b[0m in \u001b[0;36mlistdirs\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m##input folder: the file path to folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     return [\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0md\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     ]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Image Processing PC\\\\Downloads\\\\2021-09-21\\\\2021-09-21'"
     ]
    }
   ],
   "source": [
    "##### CHANGE THIS TO YOUR FOLDER##################\n",
    "##################################################\n",
    "bigfol=r\"C:\\Users\\Image Processing PC\\Downloads\\2021-09-21\\2021-09-21\"\n",
    "##################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialise dependencies\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "import imageio\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "#import hcluster\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from math import pow\n",
    "import scipy.signal \n",
    "%matplotlib qt\n",
    "#template matching\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#General Functions\n",
    "def listdirs(folder):\n",
    "## a function which lists the files in a folder and adds to a list. returns a list of folders, \n",
    "##input folder: the file path to folder\n",
    "    return [\n",
    "        d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))\n",
    "        if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "def makeclippingmask(image):\n",
    "    \n",
    "\n",
    "    #makes a clipping mask around each bright spot so the analysis isn't thrown off\n",
    "    grayA = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    blurred = cv.GaussianBlur(grayA, (11,11), 0)\n",
    "\n",
    "    #watershed thresholding. Based on: https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html\n",
    "    src = image.copy()\n",
    "    \n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    imgLaplacian = np.clip(imgLaplacian, 0, 255)\n",
    "    imgLaplacian = np.uint8(imgLaplacian)\n",
    "    #cv.imshow('Laplace Filtered Image', imgLaplacian)\n",
    "    #cv.imshow('New Sharped Image', imgResult)\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n",
    "   # _, bw2 = cv.threshold(grayA, 30, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #plt.imshow(bw)\n",
    "    bw = cv.adaptiveThreshold(bw, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 37, 1)\n",
    "    #cv.imshow('Binary Image', bw)\n",
    "    \n",
    "    \n",
    "    opening = cv.morphologyEx(bw,cv.MORPH_OPEN,kernel, iterations = 3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    # Threshold to obtain the peaks\n",
    "    # This will be the markers for the foreground objects\n",
    "    _, sure_fg = cv.threshold(dist_transform, 0.2, 1.0, cv.THRESH_BINARY)\n",
    "    # Dilate a bit the dist image\n",
    "    kernel1 = np.ones((3,3), dtype=np.uint8)\n",
    "    sure_fg = cv.dilate(sure_fg, kernel1)\n",
    "    ret, markers = cv.connectedComponents(np.uint8(sure_fg))\n",
    "    \n",
    "    \n",
    "    #cv.imshow('Final Result', sure_fg)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.float32(sure_fg)\n",
    "    sure_bg = np.float32(sure_bg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    #cv.imshow('Distance Transform Image', dist_transform)\n",
    "    \n",
    "    # Marker labelling\n",
    "    \n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    #print(markers.shape)\n",
    "    \n",
    "    markers = cv.watershed(imgResult,markers)\n",
    "    #print(markers)\n",
    "    \n",
    "    mask2 = np.zeros(image.shape[:2], dtype= np.uint8)\n",
    "    mask2[markers >1] = [255]\n",
    "    \n",
    "    #colours=((255,255,255))\n",
    "    # Fill labeled objects with random colors\n",
    "    #for i in range(markers.shape[0]):\n",
    "    #    for j in range(markers.shape[1]):\n",
    "    #        index = markers[i,j]\n",
    "    #        if index>0:\n",
    "    #            mask2[i,j] = 255\n",
    "    \n",
    "\n",
    "    image_rgb=image.copy()\n",
    "    image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    #plt.imshow(image_blocked)\n",
    "    return image_blocked\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_camera_wb=True,\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1))\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        \n",
    "def saveexcelfun(dimercoord,corecoord,savepath):\n",
    "#Save the coordinates of everything to an excel spreadsheet. Yeah I know it's ugly. \n",
    "#input: dimercoord- the dimer coordinates\n",
    "########corecoord- the core coordinates \n",
    "########savepath- the folder location where the files will be saved \n",
    "    columns=['Before Dimers xval']\n",
    "    saveexcel=savepath+\".\"+\"xlsx\"\n",
    "    beforedimercentres = pd.DataFrame({'Before Dimers xval':dimercoord})\n",
    "    try:\n",
    "        aftercorecentres = pd.DataFrame({'After core xval': corecoord})\n",
    "    except:\n",
    "        aftercorecentres=pd.DataFrame({'After core xval': np.array([0]), \n",
    "                                'After core yval': np.array([0])})\n",
    "\n",
    "   \n",
    "    writer = pd.ExcelWriter(saveexcel,engine='xlsxwriter')\n",
    "    workbook=writer.book\n",
    "    worksheet=workbook.add_worksheet('DimersPicked')\n",
    "    writer.sheets['DimersPicked'] = worksheet\n",
    "    worksheet2=workbook.add_worksheet('CoresPicked')\n",
    "    writer.sheets['CoresPicked'] = worksheet2\n",
    "\n",
    "\n",
    "    beforedimercentres.to_excel(writer,sheet_name='DimersPicked',startrow=1 , startcol=0)\n",
    "    #worksheet.write_string(beforedimercentres.shape[0] + 4, 0, beforedimercentres.name)\n",
    "\n",
    "    aftercorecentres.to_excel(writer,sheet_name='CoresPicked',startrow=1, startcol=3)\n",
    "    \n",
    "\n",
    "    writer.save()\n",
    "def savetextfilefun(data,savepath,datastring):\n",
    "##### A function which saves an array to a text file. Is a little buggy in that sometimes there's weird spaces. \n",
    "##### reccomend the excel save functions instead. Python struggles to re-read these text tiles\n",
    "\n",
    "    savetextstring=savepath+datastring+\".txt\"\n",
    "    file = open(savetextstring,\"w\")\n",
    "    for dataentry in data:\n",
    "        arr_of_strings = np.array2string(dataentry)\n",
    "        file.write(arr_of_strings) \n",
    "    file.close() \n",
    "    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "## A function which reads in images and adds them to a list of images.\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "## note !! The images wil be read in with open cv, and will be in BGR format and will look strange unless converted\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "def load_images_from_foldercv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to RGB\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "       \n",
    "        if img is not None:\n",
    "            img= cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "def load_images_from_folderhsv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to HSV\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        img= cv.cvtColor(img,  cv.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#####################################################\n",
    "###################################################\n",
    "#Template matching functions\n",
    "\n",
    "\n",
    "def findidealimagescale(image,template):\n",
    "    # loop over the images to find the template in\n",
    "   \n",
    "        # load the image, convert it to grayscale, and initialize the\n",
    "        # bookkeeping variable to keep track of the matched region\n",
    "        \n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    template=cv.cvtColor(template, cv.COLOR_HSV2RGB)\n",
    "    template=cv.cvtColor(template, cv.COLOR_RGB2GRAY)\n",
    "    #template.astype(np.uint8)\n",
    "    #gray.astype(np.uint8)\n",
    "    found = None\n",
    "    scalefin= None\n",
    "    (h, w) = template.shape[:2]\n",
    "    i=0\n",
    "    # loop over the scales of the image\n",
    "    for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "        # resize the image according to the scale, and keep track\n",
    "        # of the ratio of the resizing\n",
    "        resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "        r = gray.shape[1] / float(resized.shape[1])\n",
    "        # if the resized image is smaller than the template, then break\n",
    "        # from the loop\n",
    "        if resized.shape[0] < h or resized.shape[1] < w:\n",
    "            break\n",
    "        result = cv.matchTemplate(gray, template, cv.TM_SQDIFF_NORMED)\n",
    "        (minval, _, minloc, _) = cv.minMaxLoc(result)\n",
    "        if found is None or minval < found:\n",
    "            found = minval\n",
    "            scalefin=scale\n",
    "    return scalefin \n",
    "        \n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "        \n",
    "def nonmaxsuppression(xCoords,yCoords,template):\n",
    "    center_coordinates=[]\n",
    "    rects=[]\n",
    "    rectangle_coordinates=[]\n",
    "    (w, h) = template.shape[:2]\n",
    "    #print(w)\n",
    "    #print(h)\n",
    "## stops the overcounting of variables with nonmax suppression and returns an updated list\n",
    "    for (x, y) in zip(xCoords, yCoords):\n",
    "    # update our list of rectangles\n",
    "        rects.append((x, y, x +w, y + h))\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        center_coordinates.append((startX+h//2,startY+h//2))\n",
    "        rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "     \n",
    "    #print(\"center coordinates are \",center_coordinates)\n",
    "    #print(\"rectangle_coordinates are \", rectangle_coordinates)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithm(img_hsv,template, method,threshold):\n",
    "# defines the template matching algorithm and finds the minimum locations\n",
    "#inputs: img_rgb- the image to be matched in HSV format\n",
    "#########template- the template to be matched in HSV format\n",
    "#########method- the method of determining the minim. cv.TM_SQDIFF_NORMED is good for colour\n",
    "##### extras found here: https://docs.opencv.org/master/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d\n",
    "#########threshold: the threshold where the minimum is defined. Variable. May want to do something with min_val and max\n",
    "#outputs: locations_of_minimum- a really big array that needs to be zipped. \n",
    "#Note: this works on colour (3 d) images but may want to change to just hue\n",
    "    \n",
    "    mat_of_matching_results=cv.matchTemplate(img_hsv,template,method) \n",
    "    #This is to get some details about the minimum but isn't actually used\n",
    "    #print(\"template matching done\")\n",
    "    (min_val, max_val, _, max_loc) = cv.minMaxLoc(mat_of_matching_results)\n",
    "    #print(\"The min is done\")\n",
    "    #print(min_val)\n",
    "    #print(max_val)\n",
    "    (yCoords, xCoords) = np.where( mat_of_matching_results <= ((max_val-min_val)/threshold)+min_val)\n",
    "    while (len(xCoords))>250000:\n",
    "        threshold=threshold+0.5\n",
    "        (yCoords, xCoords) = np.where( mat_of_matching_results <= ((max_val-min_val)/threshold)+min_val)\n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template)\n",
    "    \n",
    "    #print(locations_of_minimum)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithmscikit(img_hsv,template,threshold):\n",
    "    mat_of_matching_results = match_template(img_hsv, template,pad_input=True)\n",
    "    max_val=np.max(mat_of_matching_results)\n",
    "    min_val=np.min(mat_of_matching_results)\n",
    "    #max = np.unravel_index(np.argmax(result), result.shape)\n",
    "    #(min_val, max_val, _, max_loc) = cv.minMaxLoc(mat_of_matching_results)\n",
    "    threshold2=((max_val-min_val)/threshold)+min_val\n",
    "    peaks=peak_local_max(image, min_distance=10, threshold_abs=None, threshold_rel=0.75)\n",
    "    print(peaks)\n",
    "    xCoords=peaks[:,1]\n",
    "    yCoords=peaks[:,2]\n",
    "    center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def imagetempmatch(imgpath,img_rgb,threshold):\n",
    "## performs the template matching function on each template image found in imgpath\n",
    "## input: imgpath: a string pointing to the folder the template images are contained in\n",
    "##########img_rgb: the image to be matched, in rgb format \n",
    "##########threshold: the threshold at which the minimum is accepted. The minimum value is the value where the \n",
    "#####################template matching function thinks that the image is matched. Note, this may be a maximum \n",
    "####################for other methods\n",
    "    #loads the template images in as HSV\n",
    "    images=load_images_from_folderhsv(imgpath)\n",
    "    #Creates a mask which has the shape of the image to be matched. The dtype is important or error will occur. \n",
    "    # This mask is to test whether the template matching has counted the same point multiple times\n",
    "    mask = np.zeros(img_rgb.shape, dtype=np.uint8)\n",
    "    res=[[]];\n",
    "    scale=findidealimagescale(img_rgb,images[0])\n",
    "    #print(scale)\n",
    "    resized = imutils.resize(img_rgb, width = int(img_rgb.shape[1]*scale))\n",
    "    for template in tqdm(images):\n",
    "        #for each template, the width and height is taken\n",
    "        \n",
    "        w=16\n",
    "        h=16\n",
    "        \n",
    "        #big image converted to hsv format\n",
    "        img_hsv= cv.cvtColor(resized,  cv.COLOR_RGB2HSV)\n",
    "        #the location minima identified with the template matching algorithm\n",
    "        center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithm(img_hsv,template,cv.TM_SQDIFF_NORMED,threshold)\n",
    "        #center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithmscikit(img_hsv,template,threshold)\n",
    "        \n",
    "        #print(\"locations of min are\", locations_of_min)\n",
    "        # the locations are checked for multiple counting of the same point. \n",
    "        #particle_count=checkfordoublecounting(img_hsv,locations_of_min)\n",
    "        #print(particle_count)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "\n",
    "def blockimagecombo(image_rgb, points,r,bok):\n",
    "    #print(points)\n",
    "    if bok==1:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,255), -1)\n",
    "    elif bok==2:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,0), 2)\n",
    "        \n",
    "    else:\n",
    "        mask2 = np.zeros(image_rgb.shape[:2], dtype= np.uint8)\n",
    "        for pt in points: \n",
    "            #print(pt)\n",
    "            mask2 = cv.circle(mask2,pt,r, (255,255,255), -1)\n",
    "            \n",
    "            # a rectangle is drawn on the mask, which marks where the points are \n",
    "        #invmask=255-mask2\n",
    "        #This is an inbuilt cv function which clips the image around the mask. \n",
    "        #plt.imshow(cv.bitwise_and(image_rgb, image_rgb, mask=invmask))\n",
    "        image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "\n",
    "def performtemplatematching(image_rgb,imgpath,bok,threshold):\n",
    "## a function which performs template matching on the images and blocks them depending on whether\n",
    "## we want to keep the particles or block them out for more accuracy \n",
    "#input: image_rgb: the big image in rgb format where we are looking for matches\n",
    "########imgpath: the path to the template images, as a string\n",
    "#########bok: block or keep. 0 is for keeping, 1 is for blocking with a rectange\n",
    "#########threshold: the threshold for the minimum values. Variable. \n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=imagetempmatch(imgpath,image_rgb,threshold)\n",
    "    r=round(w/1.5)\n",
    "\n",
    "    correctedimg=blockimagecombo(image_rgb,center_coordinates ,r,bok)\n",
    "    return correctedimg,center_coordinates,r\n",
    "\n",
    "def performsaveimage(image,path):\n",
    "## saves image using pillow, which is a lot faster than matplot lib. \n",
    "    img_rgb_corr=image\n",
    "    try:\n",
    "        im_pil = Image.fromarray(img_rgb_corr)\n",
    "        im_pil.save(path, compress_level=1)\n",
    "    except:\n",
    "        exception=1\n",
    "\n",
    "def savetotrainingfol(foldername,image,points):\n",
    "## saves the cropped images to a folder, for use in machine learning. uses a 16 pixel box.\n",
    "#input: foldername: name of the folder where you want the images stored\n",
    "#######image: an image in rgb format which you want to cut up\n",
    "########points: the coordinates of the particles which you have selected. \n",
    "    boxwid=round(16/2)\n",
    "    w=16\n",
    "    for j,pt in enumerate(points):\n",
    "        savepathfol= addstringwithtime(foldername +'\\\\')\n",
    "        savepath= savepathfol+str(j)+\"registeredimg\" + \".\" + \"png\"\n",
    "        #savepath=os.path.join(savepathfol, str(j)+\"registeredimg\" + \".\" + \"png\")\n",
    "        lilimage=image[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        performsaveimage(lilimage,savepath)\n",
    "def blockoutunwantedparticles(analpath,sat_img,path,threshold):\n",
    "## a function which blocks out that particles which are interfering with analysis i.e. clumps and clusters\n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#output: correctedimgcore, the corrected image after accounting for cores and clumps\n",
    "# These images are hardcoded into a folder, so the code has some dependencies. But any exmaples of the correct size will do\n",
    "    #The threshold of 0.25 seems to be highly variable\n",
    "    correctedimg,_,r= performtemplatematching(sat_img, path,1,threshold)\n",
    "    return correctedimg,r\n",
    "\n",
    "def unwantedparticleblocking(analpath,sat_img):\n",
    "    #clusterpath=  r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\Cluster\"\n",
    "    #threshold= 0.25\n",
    "    #correctedimgcluster=blockoutunwantedparticles(analpath,sat_img,clusterpath,threshold)\n",
    "    \n",
    "    clumppath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\clump\"\n",
    "    threshold=4\n",
    "    savepath=os.path.join(analpath, \"clumpcorrectedimg\" + \".\" + \"png\")\n",
    "    correctedimgclump,r=blockoutunwantedparticles(analpath,sat_img,clumppath,threshold)\n",
    "    performsaveimage(correctedimgclump,savepath)\n",
    "    \n",
    "    corepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\core2\"\n",
    "    threshold=10\n",
    "    correctedimgcore,r=blockoutunwantedparticles(analpath,correctedimgclump,corepath,threshold)\n",
    "    savepath=os.path.join(analpath, \"corecorrectedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgcore,savepath)\n",
    "    \n",
    "    return correctedimgcore,r\n",
    "    \n",
    "def keepmatchedparticles(path,image,threshold):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "    correctedimgdimer,pointsdimer,r= performtemplatematching(image, path, 0, threshold)\n",
    "    \n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "                                                              \n",
    "\n",
    "def performkeepmatchedparticles(analpath,image):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "#outputs: the selected image and the dimer points selected\n",
    "    dimerpath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\dimer2\"\n",
    "    threshold=2\n",
    "    \n",
    "    correctedimgdimer,pointsdimer,r=keepmatchedparticles(dimerpath,image,threshold)\n",
    "    savepath=os.path.join(analpath, \"pickeddimersimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgdimer,savepath)\n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "\n",
    "\n",
    "\n",
    "def getaveragevalueshsv(image,points,w,h,analpath):\n",
    "# a function to get the average values of the image in rgb format\n",
    "#inputs: image: the hsv image\n",
    "#########points: the selected dimer values\n",
    "#########w,h- the width and height in pixels\n",
    "#########analpath: the path to the analysis folder\n",
    "#outputs: an array of the average colour of the red divided by the green vector\n",
    "\n",
    "    average_colour_rDivg=[]\n",
    "    #converts the image to hsv\n",
    "    image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_rDivg)), \" min is \",np.min(np.array(average_colour_rDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_rDivg)), \"median is \", np.mean(np.array(average_colour_rDivg)) )\n",
    "    print(\"standard deviation is \", np.mean(np.array(average_colour_rDivg)))\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getaveragevaluesLAB(image,points,analpath):\n",
    "    w=8\n",
    "    labim = rgb2lab(image)\n",
    "    l_vec,a_vec,b = cv.split(labim)\n",
    "    average_colour_aDivg=[]\n",
    "    max_val_lDivg=[]\n",
    "    average_lum=[]\n",
    "    #converts the image to hsv\n",
    "    #image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    #image_hue=np.true_divide(image[:,:,0], image[:,:,1], where=(image[:,:,0]!=0) | (image[:,:,1]!=0))\n",
    "    #image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=a_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            \n",
    "            crop_im_lval=l_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval_lval=crop_im_lval.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_aDivg.append(np.mean(dividedval))\n",
    "            \n",
    "            max_val_lDivg.append(np.max(dividedval_lval))\n",
    "            average_lum.append(np.mean(dividedval_lval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    if not average_colour_aDivg:\n",
    "        average_colour_aDivg=[0]\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_aDivg)), \" min is \",np.min(np.array(average_colour_aDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_aDivg)), \"median is \", np.median(np.array(average_colour_aDivg)) )\n",
    "    print(\"standard deviation is \", np.std(np.array(average_colour_aDivg)))\n",
    "    return np.array(average_colour_aDivg),np.array(average_lum),np.array(max_val_lDivg)\n",
    "\n",
    "def averagehistogramshift(correctedimgdimer,pointsdimer,correctedimgtarget,threshold,analpath):\n",
    "# a function which uses the average shift of the particle colour (either hue or rgb depending ) to \n",
    "#select the particles which have shifted in the after image \n",
    "#inputs: correctedimgdimer: the image with only dimers selected\n",
    "#########pointsdimer: the locations of the dimers in the image\n",
    "#########correctedimgtarget: the registered image after target added wherein the coordinates of the selected\n",
    "# dimers have been used to clip it\n",
    "#########threshold: the values which the shifted average value must be above or below. was 0.2 \n",
    "#output: loc- the shifted selected particles. \n",
    "    avdim,ldim,maxldim=getaveragevaluesLAB(correctedimgdimer,pointsdimer,analpath)\n",
    "    \n",
    "    avcore,lcore,maxlcore=getaveragevaluesLAB(correctedimgtarget,pointsdimer,analpath)\n",
    "    minus= np.array(avdim)-np.array(avcore)\n",
    "    minus_l=np.array(ldim)-np.array(lcore)\n",
    "    \n",
    "    print(\"minus values here ------------\")\n",
    "    print(\"max value is \", np.max(minus), \"min value is \", np.min(minus), \" mean value is \", np.mean(minus))\n",
    "    print(\" median value is \", np.median(minus), \" standard deviation is \", np.std(minus))\n",
    "    loc=np.array(pointsdimer)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    ldim2=ldim[np.logical_and(minus>5,maxlcore>1)]\n",
    "    loc=loc[ldim2<30]\n",
    "    r=8\n",
    "    #loc=np.array(pointsdimer)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    targetpicked= blockimagecombo(correctedimgtarget,loc,r,0)\n",
    "    #average_values=np.array(minus)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    average_values=np.array(minus)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    #print(minus)\n",
    "    #average_values=average_values[ldim2<30]\n",
    "    #print(ldim2)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"tarmaskedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(targetpicked,savepath)\n",
    "    return loc,average_values.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def performtemplatetrainingonimages(transtarimg,analpath,sat_img):\n",
    "    \n",
    "\n",
    "    #blocks unwated particles\n",
    "    correctedimgcore,r=unwantedparticleblocking(analpath,sat_img)\n",
    "    \n",
    "    \n",
    "    #selects dimers\n",
    "    correctedimgdimer,pointsdimer,r=performkeepmatchedparticles(analpath, correctedimgcore)\n",
    "    image_circle=blockimagecombo(sat_img, pointsdimer,16,2)\n",
    "    savepath=os.path.join(analpath, \"dimerCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #print(np.unique(np.array(pointsdimer),axis=0))\n",
    "    #pointsdimer_corrected=np.unique(np.array(pointsdimer),axis=0)\n",
    "    pointsdimer_corrected=pointsdimer\n",
    "    #uses those points to select the same points in the target image \n",
    "    \n",
    "    transtarimg=makeclippingmask(transtarimg)\n",
    "    correctedimgtarget=blockimagecombo(transtarimg,pointsdimer_corrected,r,0)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgtarget,savepath)\n",
    "    \n",
    "    #scans the before and after dimers to determine if the particles shift in hue\n",
    "    threshold=-0.001\n",
    "    selected_target_locations,average_values=averagehistogramshift(correctedimgdimer,pointsdimer_corrected,correctedimgtarget,threshold,analpath)\n",
    "    image_circle=blockimagecombo(transtarimg, selected_target_locations,16,2)\n",
    "    savepath=os.path.join(analpath, \"targetCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #comment out if don't want\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\before\",sat_img,pointsdimer_corrected)\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\after\",transtarimg,selected_target_locations)\n",
    "    \n",
    "    return selected_target_locations,pointsdimer_corrected,average_values\n",
    "\n",
    "\n",
    "######### Extra functions\n",
    "\n",
    "def getindividualfoldersandsuch(bigfol):\n",
    "# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\n",
    "    topfolders=listdirs(bigfol)\n",
    "    subfolders=[0]\n",
    "    for nextfolders in topfolders:\n",
    "        subfolders= subfolders+ listdirs(nextfolders)\n",
    "    subfolders.pop(0)\n",
    "    #print(subfolders)\n",
    "    subfolders=np.array(subfolders).reshape(-1,1)\n",
    "    #print(subfolders)\n",
    "    return subfolders\n",
    "def searchforsatandtargetfolders(folder):\n",
    "#finds the satellite and targetfolders using regexp\n",
    "    subfolders2 = folder.tolist()\n",
    "    subfolders3=str(subfolders2).replace('[','').replace(']','').replace('\\\\\\\\','\\\\')\n",
    "\n",
    "    listexpfolders=listdirs(subfolders3[1:len(subfolders3)-1])\n",
    "    beforefol = [x for x in listexpfolders if re.search(\"satellite\",x)]\n",
    "    beforefol=beforefol[0]\n",
    "    afterfol= [x for x in listexpfolders if re.search(\"target\",x)]\n",
    "    afterfol=afterfol[0]\n",
    "    \n",
    "    return beforefol,afterfol\n",
    "\n",
    "def createanalysisfolder(beforefol,string):\n",
    "#creates an analysis folder in the address above where the satellite and target folders are located.\n",
    "    oneuppath=os.path.dirname(beforefol)\n",
    "    analysisfolderpath=oneuppath+\"\\\\\"+string\n",
    "    try:\n",
    "        os.mkdir(analysisfolderpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    print(analysisfolderpath)\n",
    "    print(\"processing images\")\n",
    "    return analysisfolderpath,oneuppath\n",
    "\n",
    "def createimagesubfolderforsaving(pathtomatch,analysisfolderpath):\n",
    "# creates a folder with the name of the image in the analysis folder \n",
    "    pathtomatch=beforeimfile[j]\n",
    "    matchingsearch=re.search(\"IMG_.*.CR2\",pathtomatch)\n",
    "    savefilespath=analysisfolderpath+\"\\\\\"+matchingsearch.group()+\"\\\\\"\n",
    "    try: \n",
    "        os.mkdir(savefilespath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    return savefilespath\n",
    "def addstringwithtime(savefilespath):\n",
    "# adds the current date and time so there's no saving over the top of different analysis\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    savepath=savefilespath+dt_string\n",
    "    return savepath\n",
    "def makeanalysisfolder(savefilespath,string):\n",
    "# makes a directory in the folder which matches the image name which says 'analysis'\n",
    "    analpath=os.path.join(savefilespath,string)\n",
    "                        #saves the registered image\n",
    "    try: \n",
    "        os.mkdir(analpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    return analpath\n",
    "\n",
    "################ THRESHOLDING\n",
    "def gethuevaluesthreshHSV(image,points):\n",
    "    image_hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    image_hue=image_hsv[:,:,0]\n",
    "    w=8\n",
    "    average_colour_rDivg=[]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getcentroidsandcenters(image):\n",
    "    \n",
    "    #wmakes an excellent binary image\n",
    "    src = image.copy()\n",
    "\n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_RGB2GRAY)\n",
    "    #_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    contours, hierarchy = cv.findContours(bw, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    list_of_centres=[]\n",
    "    boundRect = [None]*len(contours)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        center_circle, _ = cv.minEnclosingCircle(contours_poly[i])\n",
    "        list_of_centres.append((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "        \n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "        cv.circle(src, ((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1])))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        #print((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "    #picked_rectangles=non_max_suppression_fast(np.array(boundRect),0.01)\n",
    "    #h=16;\n",
    "    #for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "    #    list_of_centres.append((np.round((startX+endX/2)),np.round((startY+endY/2))))\n",
    "        #cv.circle(src, (np.int(np.round((startX+endX/2))),np.int(np.round((startY+endY/2)))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "    #cv.imshow(\"Image\", src)\n",
    "    #plt.show()\n",
    "    #list_of_centres=np.array(list_of_centres)\n",
    "    #print(list_of_centres)\n",
    "    return list_of_centres\n",
    "\n",
    "\n",
    "def performthresholding(beforeim,afterim,analpath):\n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    average_colour=gethuevaluesthreshHSV(image,list_of_centres)\n",
    "    dimer_points= np.array(list_of_centres)[average_colour <= 20]\n",
    "    \n",
    "    average_colour_dimer=gethuevaluesthreshHSV(image,dimer_points)\n",
    "    dimers_blocked=blockimagecombo(beforeim, dimer_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"dimersblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(dimers_blocked,savepath)\n",
    "    target_image=blockimagecombo(afterim, dimer_points,8,0)\n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image,savepath)\n",
    "    average_colour_after=gethuevaluesthreshHSV(target_image,dimer_points)\n",
    "    particle_difference=average_colour_dimer-average_colour_after\n",
    "    target_points= np.array(dimer_points)[particle_difference < -10]\n",
    "    target_image_picked=blockimagecombo(afterim, target_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"targetpicked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image_picked,savepath)\n",
    "    return dimer_points,target_points\n",
    "    \n",
    "#########################\n",
    "\n",
    "\n",
    "subfolders=getindividualfoldersandsuch(bigfol)\n",
    "\n",
    "for folder in subfolders:\n",
    "    #automatically find the before and after folder \n",
    "    beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    \n",
    "    #Create the relevant folder for saving,as well as the path one folder up \n",
    "    analysisfolderpath_temp,oneuppath_temp=createanalysisfolder(beforefol,\"Analysisfolder_Template\")\n",
    "    analysisfolderpath_thresh,oneuppath_thresh=createanalysisfolder(beforefol,\"Analysisfolder_thresholding\")\n",
    "    \n",
    "    \n",
    "    #loadsall the images in \n",
    "\n",
    "    imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction(beforefol,afterfol)\n",
    "    print(\"processed and converted images\")\n",
    "    \n",
    "    \n",
    "    response=[0]*len(beforeimfile)\n",
    "    dimercount=[0]*len(beforeimfile)\n",
    "    targetcount=[0]*len(beforeimfile)\n",
    "    response_thresh=[0]*len(beforeimfile)\n",
    "    dimercount_thresh=[0]*len(beforeimfile)\n",
    "    targetcount_thresh=[0]*len(beforeimfile)\n",
    "    #t = tqdm(total=len(imbef))\n",
    "    for j,image in enumerate(imbef):\n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.25)\n",
    "            #sleep(0.1)\n",
    "\n",
    "        pathtomatch=beforeimfile[j]\n",
    "        savefilespath_temp= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_temp)\n",
    "        savefilespath_thresh= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_thresh)\n",
    "        \n",
    "        \n",
    "        #add on the currentdate and time \n",
    "        savepath_temp=addstringwithtime(savefilespath_temp)\n",
    "        savepath_thresh=addstringwithtime(savefilespath_thresh)\n",
    "        \n",
    "        \n",
    "        print(\"calculating image \"+str(j+1)+\" of \"+ str(len(imbef)))\n",
    "        \n",
    "        #make an analysis folder which says analysis in the image folder just created \n",
    "        analpath_temp=makeanalysisfolder(savefilespath_temp,\"Analysisimages_Template\")\n",
    "        analpath_thresh=makeanalysisfolder(savefilespath_thresh,\"Analysisimages_thresholding\")\n",
    "        \n",
    "        #spot matches the before and after images \n",
    "        transimaf=imgregfun(image, imaf[j])\n",
    "        #saves the redistered image\n",
    "        saveregisteredimage=os.path.join(analpath_temp, \"registeredimg\" + \".\" + \"png\")\n",
    "        performsaveimage(transimaf,saveregisteredimage)\n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "        #    pbar.update(0.5)\n",
    "        #    sleep(0.1)\n",
    "        \n",
    "        #uncomment if you want a crop box    \n",
    "        #height, width = image.shape[:2]\n",
    "        #boxwid=round(1500/2)\n",
    "        #centreimagebefore=image[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        #centreimageafter=transimaf[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        centreimagebefore=makeclippingmask(image)\n",
    "        print(\"Made the clipping Mask\")\n",
    "        #plt.imshow(centreimagebefore)\n",
    "        centreimageafter=makeclippingmask(transimaf)\n",
    "        \n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.75)\n",
    "            #sleep(0.1)\n",
    "        dimer_points,target_points=performthresholding(centreimagebefore,centreimageafter,analpath_thresh)\n",
    "        \n",
    "        #perform the template matching and see which particles shift\n",
    "        targetpicked,pointsdimer,average=performtemplatetrainingonimages(centreimageafter,analpath_temp,centreimagebefore)\n",
    "       \n",
    "        \n",
    "        #saves the to an excel spreadsheet and saves the results to a list to get the overall results at the end \n",
    "        #if I feel bothered I can add something in that uses the already analysed images but meh \n",
    "        dimercount[j]=len(pointsdimer)\n",
    "        targetcount[j]=len(targetpicked)\n",
    "        try: \n",
    "            response[j]=(len(targetpicked)/len(pointsdimer))*100\n",
    "        except:\n",
    "            response[j]=0\n",
    "        \n",
    "        saveexcelfun(pointsdimer,targetpicked,savepath_temp)\n",
    "        \n",
    "        dimercount_thresh[j]=len(dimer_points)\n",
    "        targetcount_thresh[j]=len(target_points)\n",
    "        try: \n",
    "            response_thresh[j]=(len(target_points)/len(dimer_points))*100\n",
    "        except:\n",
    "            response_thresh[j]=0\n",
    "        #print(pointsdimer.type)\n",
    "        #print(dimer_points.type)\n",
    "        #saveexcelfun(dimer_points,target_points,savepath_thresh)\n",
    "  \n",
    "        \n",
    "        \n",
    "        #save important coordinates to a text file for later analysis\n",
    "        #Probably can delete this don't know what it's used for anymore \n",
    "        #savetextfilefun(np.array(pointsdimer),savepath,\"dimerbefore\")\n",
    "        #savetextfilefun(np.array(targetpicked),savepath,\"selectedResponse\")\n",
    "\n",
    "    print(\"Finished analysis woohoo\")\n",
    "    #t.close()\n",
    "    #Find the folders which contain the analysis and read the text files\n",
    "    #Find the image folders\n",
    "    searchfolder=oneuppath_temp\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_temp= searchfolder+'\\\\'+\"Analysisfolder_Template\"\n",
    "    imagefilefolders=os.listdir(savedir_temp)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount),'target_picked':np.array(targetcount),'response': np.array(response)})\n",
    "    responsepath_temp=savedir_temp+'\\\\'+\"responseforallimages.xlsx\"\n",
    "    responseforexcel.to_excel(responsepath_temp) \n",
    "    \n",
    "    searchfolder_thresh=oneuppath_thresh\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_thresh= searchfolder+'\\\\'+\"Analysisfolder_thresholding\"\n",
    "    imagefilefolders=os.listdir(savedir_thresh)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount_thresh),'target_picked':np.array(targetcount_thresh),'response': np.array(response_thresh)})\n",
    "    responsepath_thresh=savedir_thresh+'\\\\'+\"responseforallimages.xlsx\"\n",
    "    responseforexcel.to_excel(responsepath_thresh) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-silence",
   "metadata": {},
   "source": [
    "#################### TEMPLATE MATCHING MAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlittleimages(bigfol):\n",
    "    %matplotlib inline\n",
    "    dimerpath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\dimer2\"\n",
    "    corepath=r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\core2\"\n",
    "    subfolders=getindividualfoldersandsuch(bigfol)\n",
    "    firstfolder=subfolders[0]\n",
    "    beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction(beforefol,afterfol)\n",
    "    print(\"processed and converted images\")\n",
    "    transimaf=imgregfun(imbef[0], imaf[0])\n",
    "    #plt.imshow(imbef[0])\n",
    "    centreimagebefore=makeclippingmask(imbef[0])\n",
    "    #plt.imshow(centreimagebefore)\n",
    "    centreimageafter=makeclippingmask(transimaf)\n",
    "    targetpicked,pointsdimer=performtemplatetrainingonimages(centreimageafter,analpath,centreimagebefore)\n",
    "    for pt in targetpicked:\n",
    "        image_crop=centreimageafter[pt[1]-8:pt[1]+8, pt[0]-8:pt[0]+8]\n",
    "        \n",
    "        #plt.imshow(image_crop)\n",
    "        plt.show()\n",
    "        cv.waitKey(0)\n",
    "        username = input(\"Is the particle a core (c), dimer(d) or neither(n):\")\n",
    "        if username==\"c\":\n",
    "            savepath= corepath+'\\\\'+str(pt[1])+\"coreimg\" + \".\" + \"png\"\n",
    "            performsaveimage(image_crop,savepath)\n",
    "        elif username==\"d\":\n",
    "            savepath= dimerpath+'\\\\'+str(pt[1])+\"dimerimg\" + \".\" + \"png\"\n",
    "            performsaveimage(image_crop,savepath)\n",
    "        else:\n",
    "            print(\"not anything of interest\")\n",
    "    \n",
    "def getdifferenceimages(bigfol):\n",
    "    %matplotlib inline\n",
    "    beforepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\difference_images\\before\"\n",
    "    afterpath=r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\difference_images\\after\"\n",
    "    differencepath=r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\difference_images\\difference\"\n",
    "    subfolders=getindividualfoldersandsuch(bigfol)\n",
    "    firstfolder=subfolders[0]\n",
    "    beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction(beforefol,afterfol)\n",
    "    print(\"processed and converted images\")\n",
    "    image_no=0\n",
    "    transimaf=imgregfun(imbef[image_no], imaf[image_no])\n",
    "    #plt.imshow(imbef[0])\n",
    "    centreimagebefore=makeclippingmask(imbef[image_no])\n",
    "    #plt.imshow(centreimagebefore)\n",
    "    centreimageafter=makeclippingmask(transimaf)\n",
    "    targetpicked=performtemplatematchingondifferenceimages(centreimagebefore,centreimageafter,analpath_temp)\n",
    "    #pausehere=yep\n",
    "    #pointsdimer,targetpicked=performthresholding(centreimagebefore,centreimageafter,analpath_temp)\n",
    "    #targetpicked,pointsdimer=performtemplatetrainingonimages(centreimageafter,analpath_temp,centreimagebefore)\n",
    "    for pt in targetpicked:\n",
    "        image_crop_bef=centreimagebefore[pt[1]-8:pt[1]+8, pt[0]-8:pt[0]+8]\n",
    "        image_crop_after=centreimageafter[pt[1]-8:pt[1]+8, pt[0]-8:pt[0]+8]\n",
    "        plt.figure()\n",
    "        plt.imshow(image_crop_bef)\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        plt.imshow(image_crop_after)\n",
    "        plt.show()\n",
    "        cv.waitKey(0)\n",
    "        username = input(\"Is the particle a correct change, yes(y) or no (n):\")\n",
    "        if username==\"y\":\n",
    "            savepath= beforepath+'\\\\'+str(pt[1])+\"beforeimg\" + \".\" + \"png\"\n",
    "            performsaveimage(image_crop_bef,savepath)\n",
    "            savepath= afterpath+'\\\\'+str(pt[1])+\"afterimg\" + \".\" + \"png\"\n",
    "            performsaveimage(image_crop_after,savepath)\n",
    "            HSV_image_before = cv.cvtColor(image_crop_bef, cv.COLOR_RGB2HSV)\n",
    "            HSV_image_after = cv.cvtColor(image_crop_after, cv.COLOR_RGB2HSV)\n",
    "            difference=HSV_image_before-HSV_image_after\n",
    "            difference=cv.cvtColor(difference, cv.COLOR_HSV2RGB)\n",
    "            savepath= differencepath+'\\\\'+str(pt[1])+\"differenceimg\" + \".\" + \"png\"\n",
    "            performsaveimage(difference,savepath)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"not anything of interest\")\n",
    "    \n",
    "\n",
    "def performtemplatematchingondifferenceimages(imbef,imaf,analpath_temp):\n",
    "    differencepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\difference_images\\difference\"\n",
    "    threshold=6\n",
    "    targetpicked,pointsdimer=performtemplatetrainingonimages(imaf,analpath_temp,imbef)\n",
    "    dimer=blockimagecombo(imbef, pointsdimer,16,0)\n",
    "    target=blockimagecombo(imaf, pointsdimer,16,0)\n",
    "    \n",
    "    HSV_image_before = cv.cvtColor(dimer, cv.COLOR_RGB2HSV)\n",
    "    HSV_image_after = cv.cvtColor(target, cv.COLOR_RGB2HSV)\n",
    "    difference_big=HSV_image_before-HSV_image_after\n",
    "    difference=cv.cvtColor(difference_big, cv.COLOR_HSV2RGB)\n",
    "\n",
    "    \n",
    "    correctedimgdifference,pointsdifference,r=keepmatchedparticles(differencepath,difference_big,threshold)\n",
    "    \n",
    "    dimers_responded=blockimagecombo(imbef, pointsdifference,16,0)\n",
    "    savepath=os.path.join(analpath_thresh, \"pickeddimersimg\" + \".\" + \"png\")\n",
    "    performsaveimage(dimers_responded,savepath)\n",
    "    \n",
    "    target_responded=blockimagecombo(imaf, pointsdifference,16,0)\n",
    "    savepath=os.path.join(analpath_thresh, \"pickedtargetimg\" + \".\" + \"png\")\n",
    "    performsaveimage(target_responded,savepath)\n",
    "    plt.figure()\n",
    "    plt.imshow(dimers_responded)\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.imshow(target_responded)\n",
    "    plt.show()\n",
    "    \n",
    "    return pointsdifference \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-blend",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#getdifferenceimages(bigfol)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "def mse(imageA, imageB):\n",
    "    # the 'Mean Squared Error' between the two images is the\n",
    "    # sum of the squared difference between the two images;\n",
    "    # NOTE: the two images must have the same dimension\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\n",
    "    # return the MSE, the lower the error, the more \"similar\"\n",
    "    # the two images are\n",
    "    return err\n",
    "def compare_images(imageA, imageB, title):\n",
    "    # compute the mean squared error and structural similarity\n",
    "    # index for the images\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB)\n",
    "    # setup the figure\n",
    "    fig = plt.figure(title)\n",
    "    plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "    # show first image\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    # show the second image\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    # show the images\n",
    "    plt.show()\n",
    "def flattenimage(image):\n",
    "    image_shape=image.shape\n",
    "    print(image_shape)\n",
    "    image_flat = image.flatten()\n",
    "    image_flattened=image_flat.reshape(image_shape[0],image_shape[1])\n",
    "    return image_flattened\n",
    "    \n",
    "    \n",
    "def getimagedifference(variable):\n",
    "    %matplotlib qt\n",
    "    beforepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\difference_images\\before\"\n",
    "    afterpath=r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\difference_images\\after\"\n",
    "    differencepath=r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\difference_images\\difference\"\n",
    "    imagelistB=load_images_from_foldercv(beforepath)\n",
    "    imagelistA=load_images_from_foldercv(afterpath)\n",
    "    imageA_flat=flattenimage(imagelistB[0])\n",
    "    imageB_flat=flattenimage(imagelistA[0])\n",
    "    variable=variable+2\n",
    "    compareimages(imageA_flat,imageB_flat,\"Comparison\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "getimagedifference(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-brush",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-dispatch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-beatles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-transparency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-beverage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-struggle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
