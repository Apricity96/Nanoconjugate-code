{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smooth-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from scipy import ndimage, misc\n",
    "from scipy.signal import argrelextrema\n",
    "from matplotlib import pyplot as plt\n",
    "import rawpy\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from scipy.signal import find_peaks\n",
    "import time\n",
    "import imutils\n",
    "import sys\n",
    "\n",
    "\n",
    "def makeclippingmask(image):\n",
    "    \n",
    "\n",
    "    #makes a clipping mask around each bright spot so the analysis isn't thrown off\n",
    "    grayA = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    blurred = cv.GaussianBlur(grayA, (11,11), 0)\n",
    "\n",
    "    #watershed thresholding. Based on: https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html\n",
    "    src = image.copy()\n",
    "    \n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    imgLaplacian = np.clip(imgLaplacian, 0, 255)\n",
    "    imgLaplacian = np.uint8(imgLaplacian)\n",
    "    #cv.imshow('Laplace Filtered Image', imgLaplacian)\n",
    "    #cv.imshow('New Sharped Image', imgResult)\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n",
    "   # _, bw2 = cv.threshold(grayA, 30, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #plt.imshow(bw)\n",
    "    bw = cv.adaptiveThreshold(bw, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 37, 1)\n",
    "    #cv.imshow('Binary Image', bw)\n",
    "    \n",
    "    \n",
    "    opening = cv.morphologyEx(bw,cv.MORPH_OPEN,kernel, iterations = 3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    # Threshold to obtain the peaks\n",
    "    # This will be the markers for the foreground objects\n",
    "    _, sure_fg = cv.threshold(dist_transform, 0.2, 1.0, cv.THRESH_BINARY)\n",
    "    # Dilate a bit the dist image\n",
    "    kernel1 = np.ones((3,3), dtype=np.uint8)\n",
    "    sure_fg = cv.dilate(sure_fg, kernel1)\n",
    "    ret, markers = cv.connectedComponents(np.uint8(sure_fg))\n",
    "    \n",
    "    \n",
    "    #cv.imshow('Final Result', sure_fg)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.float32(sure_fg)\n",
    "    sure_bg = np.float32(sure_bg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    #cv.imshow('Distance Transform Image', dist_transform)\n",
    "    \n",
    "    # Marker labelling\n",
    "    \n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    #print(markers.shape)\n",
    "    \n",
    "    markers = cv.watershed(imgResult,markers)\n",
    "    #print(markers)\n",
    "    \n",
    "    mask2 = np.zeros(image.shape[:2], dtype= np.uint8)\n",
    "    mask2[markers >1] = [255]\n",
    "    \n",
    "    #colours=((255,255,255))\n",
    "    # Fill labeled objects with random colors\n",
    "    #for i in range(markers.shape[0]):\n",
    "    #    for j in range(markers.shape[1]):\n",
    "    #        index = markers[i,j]\n",
    "    #        if index>0:\n",
    "    #            mask2[i,j] = 255\n",
    "    \n",
    "\n",
    "    image_rgb=image.copy()\n",
    "    image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    #plt.imshow(image_blocked)\n",
    "    return image_blocked\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_camera_wb=True,\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1))\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "\n",
    "\n",
    "def gamma_correction(image_rgb):\n",
    "    hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
    "    hue, sat, val = cv2.split(hsv)\n",
    "    \n",
    "\n",
    "    # compute gamma = log(mid*255)/log(mean)\n",
    "    mid = 0.5\n",
    "    mean = np.mean(val)\n",
    "    gamma = math.log(mid*255)/math.log(mean)\n",
    "    \n",
    "\n",
    "    # do gamma correction on value channel\n",
    "    val_gamma = np.power(val, gamma).clip(0,255).astype(np.uint8)\n",
    "    hsv_gamma = cv2.merge([hue, sat, val_gamma])\n",
    "    img_gamma2 = cv2.cvtColor(hsv_gamma, cv2.COLOR_HSV2RGB)\n",
    "    return img_gamma2\n",
    "\n",
    "def grayscale_formulation(image_gamma2):\n",
    "    k_b=0.114\n",
    "    k_f=0.299\n",
    "    r,g,b=cv2.split(image_gamma2)\n",
    "    Y=k_f*r+(1-k_f-k_b)*g+k_b*b\n",
    "    Cb=-0.168736*r-0.331264*g+0.5*b\n",
    "    Cr=0.5*r-0.418688*g+0.081312*b\n",
    "    img = cv.merge((Y, Cb, Cr))\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian(x,y,z):\n",
    "    g=((1/(2*3.1415*z**2))*exp(-(x**2+y**2)/(2*z**2)))\n",
    "    return g\n",
    "def searchforextrema(results1):\n",
    "    extrema_max=np.array([argrelextrema(results1, np.greater) for window in results1])\n",
    "    extrema_min=np.array([argrelextrema(results1, np.less) for window in results1])\n",
    "    return extrema_max,extrema_min\n",
    "def findglobalmaxima(extrema_max1,extrema_min1,extrema_max2,extrema_min2):\n",
    "    results=1\n",
    "\n",
    "\n",
    "def laplacianfiltering(image_gray):\n",
    "    Y,C_b,C_r=cv.split(image_gray)\n",
    "    \n",
    "    \n",
    "    result1 = ndimage.gaussian_laplace(Y, sigma=1)\n",
    "    result2 = ndimage.gaussian_laplace(Y, sigma=8)\n",
    "    extrama1=result2-result1\n",
    "    \n",
    "    #result3 = ndimage.gaussian_laplace(Y, sigma=8)\n",
    "    result3 = ndimage.gaussian_laplace(Y, sigma=16)\n",
    "    extrema2=result3-result2\n",
    "    \n",
    "    result5 = ndimage.gaussian_laplace(Y, sigma=32)\n",
    "    \n",
    "    extrema3=result5-result3\n",
    "    return extrama1,extrema2,extrema3\n",
    "\n",
    "def imagepyramid(image, scale):\n",
    "    rows, cols, dim = image.shape\n",
    "    pyramid = tuple(pyramid_gaussian(image, downscale=scale))\n",
    "    for p in pyramid[1:]:\n",
    "        # if the image is too small, break from the loop\n",
    "        if p.shape[0] < 30 or p.shape[1] < 30:\n",
    "            break\n",
    "        # show the resized image\n",
    "        plt.imshow(\"Layer\", p)\n",
    "        cv2.waitKey(0)\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in list(range(0, image.shape[1], stepSize)):\n",
    "        for x in list(range(0, image.shape[1], stepSize)):\n",
    "            #print(\"we're in x\")\n",
    "            cropim=image[y:y + windowSize[1], x:x + windowSize[0]]\n",
    "            yield cropim\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "def newsliding_window(image,stepSize,windowSize):\n",
    "    image_windows=[]\n",
    "    for y in list(range(0, image.shape[0], stepSize)):\n",
    "        for x in list(range(0, image.shape[1], stepSize)):\n",
    "            image_crop=image[y:y + windowSize[1], x:x + windowSize[0]]\n",
    "            image_windows.append(image_crop)\n",
    "    #print(len(image_windows))\n",
    "            \n",
    "    return image_windows\n",
    "    \n",
    "    \n",
    "def pyramid(image, scale, minSize):\n",
    "    yield image\n",
    "    \n",
    "    for  resized in pyramid_gaussian(image, downscale=scale):\n",
    "        # if the image is too small, break from the loop\n",
    "        #print(resized.shape[1])\n",
    "        if resized.shape[0] < minSize or resized.shape[1] < minSize:\n",
    "            break\n",
    "        else:\n",
    "            yield resized\n",
    "    \n",
    "\n",
    "            \n",
    "def count_dist_peaks(series, bins, prominence, width):\n",
    "    count, division = np.histogram(series, bins=bins)\n",
    "    peaks, props = find_peaks(count, prominence=prominence, width=width)\n",
    "    return peaks\n",
    "\n",
    "def some_func(window):\n",
    "    channel=cv.split(window)\n",
    "    #print(np.min(channel[0]))\n",
    "    for i,colour in enumerate(channel):\n",
    "        hist = cv2.calcHist([colour], [0], None, [8], [0, 256])\n",
    "\n",
    "\n",
    "        if imutils.is_cv2():\n",
    "            hist = cv2.normalize(hist).flatten()\n",
    "    # otherwise handle for OpenCV 3+\n",
    "        else:\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "        if i==0:\n",
    "            Y_features=hist\n",
    "            #print(Y_features)\n",
    "\n",
    "        elif i==1:\n",
    "            Cr_features=hist\n",
    "\n",
    "        else:\n",
    "            Cb_features=hist\n",
    "\n",
    "    return [Y_features,Cr_features,Cb_features]\n",
    "\n",
    "def some_func2(window):\n",
    "    \n",
    "    hist = cv2.calcHist([window], [0], None, [8], [0, 256])\n",
    "\n",
    "\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist).flatten()\n",
    "# otherwise handle for OpenCV 3+\n",
    "    else:\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "    \n",
    "\n",
    "    return [hist]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sliding_window_histogram(resized):\n",
    "    \n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "    Y_features=[]\n",
    "    Cr_features=[]\n",
    "    Cb_features=[]\n",
    "   # windows=sliding_window(resized, 4, (100, 100))\n",
    "    img_r,img_g,img_b=cv.split(resized.astype('uint8'))\n",
    "    hmax,hmin=scipyslidinghistogram(img_r)\n",
    "    return hmax,hmin\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "from skimage.filters.rank import windowed_histogram\n",
    "from skimage.morphology import disk, ball\n",
    "\n",
    "def scipyslidinghistogram(img):\n",
    "    img.astype('uint8')\n",
    "    hist_img = windowed_histogram(img, disk(18),n_bins=8)\n",
    "    hmax,hmin=searchforextrema(hist_img)\n",
    "    return hmax,hmin\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    #for window in windows:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        #print(Y_features)\n",
    "        #Y_max,Y_min=searchforextrema(np.array(Y_features))\n",
    "        \n",
    "     \n",
    "        #Cr_max,Cr_min=searchforextrema(np.array(Cr_features))\n",
    "        #Cb_max,Cb_min=searchforextrema(np.array(Cb_features))\n",
    "    return output_img#Y_max,Y_min,Cr_max,Cr_min,Cb_max,Cb_min\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brazilian-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:230: RuntimeWarning: divide by zero encountered in power\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'here' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-16b53c040331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m#print(Y_max)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mhmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msliding_window_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mpausehere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhere\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Got here\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'here' is not defined"
     ]
    }
   ],
   "source": [
    "image_before=r\"D:\\OneDrive - UNSW\\Image_Analysis\\NewMicroscope\\OneDrive_2021-06-28\\Time series experiment for analysis\\Test\\slide1\\initial\\satellite\\IMG_0380s1.CR2\"\n",
    "image_after=r\"D:\\OneDrive - UNSW\\Image_Analysis\\NewMicroscope\\OneDrive_2021-06-28\\Time series experiment for analysis\\Test\\slide1\\initial\\target\\IMG_0580t20.CR2\"\n",
    "\n",
    "image_bef,exifdata= convertfilefun(image_before)\n",
    "image_af,exifdata= convertfilefun(image_after)\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_bef= makeclippingmask(image_bef[0])\n",
    "image_af= makeclippingmask(image_af[0])\n",
    "\n",
    "transimaf=imgregfun(image_bef, image_af)\n",
    "\n",
    "gammaimg_bef=gamma_correction(image_bef)\n",
    "gammaimg_af=gamma_correction(transimaf)\n",
    "\n",
    "\n",
    "image_bef_gray=grayscale_formulation(gammaimg_bef)\n",
    "image_af_gray=grayscale_formulation(gammaimg_af)\n",
    "\n",
    "#extrema1,extrema2,extrema3=laplacianfiltering(image_bef_gray)\n",
    "y_max_tot=[]\n",
    "y_min_tot=[]\n",
    "cr_max_tot=[]\n",
    "cr_min_tot=[]\n",
    "cb_max_tot=[]\n",
    "cb_min_tot=[]\n",
    "\n",
    "images=pyramid(gammaimg_bef, 3,40)\n",
    "\n",
    "for resized in images:\n",
    "    #plt.imshow(resized)\n",
    "    #Y_max,Y_min,Cr_max,Cr_min,Cb_max,Cb_min= sliding_window_histogram(resized)\n",
    "    #print(Y_max)\n",
    "    hmax,hmin=sliding_window_histogram(resized)\n",
    "    pausehere=here\n",
    "\n",
    "    print(\"Got here\")\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    \n",
    "    rangey=[0,1,2,3]\n",
    "    for y in list(range(0, image.shape[1], stepSize)):\n",
    "        \n",
    "        print(y)\n",
    "        for x in list(range(0, image.shape[1], stepSize)):\n",
    "            print(x)\n",
    "            # yield the current window\n",
    "            #plt.imshow(image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "            return (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "y=newsliding_window(resized,8,(100,100))\n",
    "plt.imshow(windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    " sliding_window_histogram(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-english",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
