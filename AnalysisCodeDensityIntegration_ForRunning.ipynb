{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c7ffeb-d24b-4e4c-8feb-28692febebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n",
      "C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\IMAGE ANALYSIS NO BLUR\\doneandwereokay\\slide1-11120-cal2slides\\1-10fM\\Analysisfolder_thresholding\n",
      "processing images\n",
      "processed and converted images\n",
      "folder already exists\n",
      "calculating image 1 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 2 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 3 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 4 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 5 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n",
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 6 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "Finished analysis woohoo\n",
      "folder already exists\n",
      "C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\IMAGE ANALYSIS NO BLUR\\doneandwereokay\\slide1-11120-cal2slides\\2-control\\Analysisfolder_thresholding\n",
      "processing images\n",
      "processed and converted images\n",
      "folder already exists\n",
      "calculating image 1 of 2\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 2 of 2\n",
      "folder already exists\n",
      "Made the clipping Mask\n",
      "done the dimer points\n",
      "Finished analysis woohoo\n",
      "folder already exists\n",
      "C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\IMAGE ANALYSIS NO BLUR\\doneandwereokay\\slide1-11120-cal2slides\\3-10fM\\Analysisfolder_thresholding\n",
      "processing images\n",
      "processed and converted images\n",
      "folder already exists\n",
      "calculating image 1 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n",
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 2 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 3 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n",
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 4 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n",
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 5 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 6 of 6\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n",
      "Finished analysis woohoo\n",
      "folder already exists\n",
      "C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\IMAGE ANALYSIS NO BLUR\\doneandwereokay\\slide1-11120-cal2slides\\4-10fM\\Analysisfolder_thresholding\n",
      "processing images\n",
      "processed and converted images\n",
      "folder already exists\n",
      "calculating image 1 of 4\n",
      "folder already exists\n",
      "Made the clipping Mask\n",
      "done the dimer points\n",
      "folder already exists\n",
      "calculating image 2 of 4\n",
      "folder already exists\n",
      "Made the clipping Mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done the dimer points\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ebd703328fea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m#pbar.update(0.75)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;31m#sleep(0.1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[0mlist_of_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimer_points\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_points\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlistofdatabefore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperformthresholdingLABfortarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentreimagebefore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcentreimageafter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalpath_thresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m         \u001b[1;31m#print(np.array(list_of_data).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[0mneg_l_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_l_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgreenscore_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mredscore_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbluescore_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myellowscore_d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistofdatabefore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ebd703328fea>\u001b[0m in \u001b[0;36mperformthresholdingLABfortarget\u001b[1;34m(beforeim, afterim, analpath)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;31m#targeted_points=np.array(core_points).reshape((-1,2))[np.logical_and(np.asarray(greenscore).reshape((-1,1))>100,np.asarray(redscore).reshape((-1,1))>100)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m     \u001b[0mneg_l_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_l_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgreenscore_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mredscore_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbluescore_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myellowscore_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpointlist_c\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetaveragevaluesLAB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeforeim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimer_points2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[0marrayofdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneg_l_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_l_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgreenscore_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mredscore_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbluescore_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myellowscore_d\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ebd703328fea>\u001b[0m in \u001b[0;36mgetaveragevaluesLAB\u001b[1;34m(image, points, analpath, yespeaks)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[0mallcropimagesl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprocessimagecrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoints\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;31m#print(points)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m     \u001b[0mallcropimagesl2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpointlistl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckforempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallcropimagesl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ebd703328fea>\u001b[0m in \u001b[0;36mcheckforempty\u001b[1;34m(vector, points)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheckforempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m     \u001b[0mvector2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpointlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeepemptyindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvector2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpointlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "##### CHANGE THIS TO YOUR FOLDER##################\n",
    "##################################################\n",
    "bigfol=r\"C:\\Users\\Image_Processing_PC\\OneDrive\\OneDrive - UNSW\\Image_Analysis\\IMAGE ANALYSIS NO BLUR\\doneandwereokay\"\n",
    "##################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialise dependencies\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "from scipy import sparse\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "#import md5, sha\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "import imageio\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from PIL import Image,ImageEnhance,ImageFilter\n",
    "import PIL\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "#import hcluster\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from math import pow\n",
    "import scipy.signal \n",
    "%matplotlib qt\n",
    "#template matching\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.util import img_as_ubyte\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def process(token):\n",
    "    return token['text']\n",
    "\n",
    "#General Functions\n",
    "def listdirs(folder):\n",
    "## a function which lists the files in a folder and adds to a list. returns a list of folders, \n",
    "##input folder: the file path to folder\n",
    "    return [\n",
    "        d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))\n",
    "        if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "def labcolourfilt(image):\n",
    "    #%matplotlib qt\n",
    "    img_lab = cv.cvtColor(image, cv.COLOR_RGB2Lab)\n",
    "    lower_l = np.array([140,0,0])\n",
    "    upper_l = np.array([255,255,255])\n",
    "    lab_l,lab_a,lab_b=cv.split(img_lab)\n",
    "    mask = cv.inRange(img_lab, lower_l, upper_l)\n",
    "    res = cv.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    #plt.imshow(res)\n",
    "    return res\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_auto_wb=True,\n",
    "                                #user_wb=[1.5,1.0,1.0,1.0],\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1),\n",
    "                              bright=1.0,\n",
    "                              dcb_enhance=True)\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        \n",
    "def saveexcelfun(dimercoord,corecoord,savepath):\n",
    "#Save the coordinates of everything to an excel spreadsheet. Yeah I know it's ugly. \n",
    "#input: dimercoord- the dimer coordinates\n",
    "########corecoord- the core coordinates \n",
    "########savepath- the folder location where the files will be saved \n",
    "    columns=['Before Dimers xval']\n",
    "    saveexcel=savepath+\".\"+\"xlsx\"\n",
    "    beforedimercentres = pd.DataFrame({'Before Dimers xval':dimercoord})\n",
    "    try:\n",
    "        aftercorecentres = pd.DataFrame({'After core xval': corecoord})\n",
    "    except:\n",
    "        aftercorecentres=pd.DataFrame({'After core xval': np.array([0]), \n",
    "                                'After core yval': np.array([0])})\n",
    "\n",
    "   \n",
    "    writer = pd.ExcelWriter(saveexcel,engine='xlsxwriter')\n",
    "    workbook=writer.book\n",
    "    worksheet=workbook.add_worksheet('DimersPicked')\n",
    "    writer.sheets['DimersPicked'] = worksheet\n",
    "    worksheet2=workbook.add_worksheet('CoresPicked')\n",
    "    writer.sheets['CoresPicked'] = worksheet2\n",
    "\n",
    "\n",
    "    beforedimercentres.to_excel(writer,sheet_name='DimersPicked',startrow=1 , startcol=0)\n",
    "    #worksheet.write_string(beforedimercentres.shape[0] + 4, 0, beforedimercentres.name)\n",
    "\n",
    "    aftercorecentres.to_excel(writer,sheet_name='CoresPicked',startrow=1, startcol=3)\n",
    "    \n",
    "\n",
    "    writer.save()\n",
    "def savetextfilefun(data,savepath,datastring):\n",
    "##### A function which saves an array to a text file. Is a little buggy in that sometimes there's weird spaces. \n",
    "##### reccomend the excel save functions instead. Python struggles to re-read these text tiles\n",
    "\n",
    "    savetextstring=savepath+datastring+\".txt\"\n",
    "    file = open(savetextstring,\"w\")\n",
    "    for dataentry in data:\n",
    "        arr_of_strings = np.array2string(dataentry)\n",
    "        file.write(arr_of_strings) \n",
    "    file.close() \n",
    "    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "## A function which reads in images and adds them to a list of images.\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "## note !! The images wil be read in with open cv, and will be in BGR format and will look strange unless converted\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "def load_images_from_foldercv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to RGB\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "       \n",
    "        if img is not None:\n",
    "            img= cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "def load_images_from_folderhsv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to HSV\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        img= cv.cvtColor(img,  cv.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#####################################################\n",
    "###################################################\n",
    "#Template matching functions\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "        \n",
    "def nonmaxsuppression(xCoords,yCoords,template):\n",
    "    center_coordinates=[]\n",
    "    rects=[]\n",
    "    rectangle_coordinates=[]\n",
    "    (w, h) = template.shape[:2]\n",
    "    #print(w)\n",
    "    #print(h)\n",
    "## stops the overcounting of variables with nonmax suppression and returns an updated list\n",
    "    for (x, y) in zip(xCoords, yCoords):\n",
    "    # update our list of rectangles\n",
    "        rects.append((x, y, x +w, y + h))\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        center_coordinates.append((startX+h//2,startY+h//2))\n",
    "        rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "     \n",
    "    #print(\"center coordinates are \",center_coordinates)\n",
    "    #print(\"rectangle_coordinates are \", rectangle_coordinates)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "\n",
    "\n",
    "def blockimagecombo(image_rgb, points,r,bok):\n",
    "    #print(points)\n",
    "    if bok==1:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,255), -1)\n",
    "    else:\n",
    "        mask2 = np.zeros(image_rgb.shape[:2], dtype= np.uint8)\n",
    "        for pt in points: \n",
    "            #print(pt)\n",
    "            mask2 = cv.circle(mask2,pt,r, (255,255,255), -1)\n",
    "            \n",
    "            # a rectangle is drawn on the mask, which marks where the points are \n",
    "        #invmask=255-mask2\n",
    "        #This is an inbuilt cv function which clips the image around the mask. \n",
    "        #plt.imshow(cv.bitwise_and(image_rgb, image_rgb, mask=invmask))\n",
    "        image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "def performtemplatematching(image_rgb,imgpath,bok,threshold,clumpflag):\n",
    "## a function which performs template matching on the images and blocks them depending on whether\n",
    "## we want to keep the particles or block them out for more accuracy \n",
    "#input: image_rgb: the big image in rgb format where we are looking for matches\n",
    "########imgpath: the path to the template images, as a string\n",
    "#########bok: block or keep. 0 is for keeping, 1 is for blocking with a rectange\n",
    "#########threshold: the threshold for the minimum values. Variable. \n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=imagetempmatch(imgpath,image_rgb,threshold,clumpflag)\n",
    "    r=round(w/1.5)\n",
    "\n",
    "    correctedimg=blockimagecombo(image_rgb,center_coordinates ,r,bok)\n",
    "    return correctedimg,center_coordinates,r\n",
    "\n",
    "def performsaveimage(image,path):\n",
    "## saves image using pillow, which is a lot faster than matplot lib. \n",
    "    img_rgb_corr=image\n",
    "    try:\n",
    "        im_pil = Image.fromarray(img_rgb_corr)\n",
    "        im_pil.save(path, compress_level=1)\n",
    "    except:\n",
    "        exception=1\n",
    "\n",
    "def savetotrainingfol(foldername,image,points):\n",
    "## saves the cropped images to a folder, for use in machine learning. uses a 16 pixel box.\n",
    "#input: foldername: name of the folder where you want the images stored\n",
    "#######image: an image in rgb format which you want to cut up\n",
    "########points: the coordinates of the particles which you have selected. \n",
    "    boxwid=round(16/2)\n",
    "    w=16\n",
    "    for j,pt in enumerate(points):\n",
    "        savepathfol= addstringwithtime(foldername +'\\\\')\n",
    "        savepath= savepathfol+str(j)+\"registeredimg\" + \".\" + \"png\"\n",
    "        #savepath=os.path.join(savepathfol, str(j)+\"registeredimg\" + \".\" + \"png\")\n",
    "        lilimage=image[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        performsaveimage(lilimage,savepath)\n",
    "        \n",
    "def blockoutunwantedparticles(analpath,sat_img,path,threshold,clumpflag):\n",
    "## a function which blocks out that particles which are interfering with analysis i.e. clumps and clusters\n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#output: correctedimgcore, the corrected image after accounting for cores and clumps\n",
    "# These images are hardcoded into a folder, so the code has some dependencies. But any exmaples of the correct size will do\n",
    "    #The threshold of 0.25 seems to be highly variable\n",
    "    correctedimg,_,r= performtemplatematching(sat_img, path,1,threshold,clumpflag)\n",
    "    #plt.imshow(correctedimg)\n",
    "    #print(r)\n",
    "    return correctedimg,r\n",
    "\n",
    "         \n",
    "def getthecolourscores(vector):\n",
    "    #print(vector)\n",
    "    splitvec=np.array_split(vector, 2,axis=1)\n",
    "    #print(splitvec)\n",
    "    intvals=[np.trapz(vec) for vec in splitvec]\n",
    "    #print(intvals[0])\n",
    "    #print(intvals[1])\n",
    "    #yes=here\n",
    "    \n",
    "    return intvals[0],intvals[1]\n",
    "def makeLabvectorspretty(l_vec,a_vec,b_vec):\n",
    "    #l_vec = l_vec.ravel()\n",
    "    lnoz=np.nonzero(l_vec)\n",
    "    l_vecf=l_vec[lnoz]\n",
    "    #a_vec = a_vec.ravel()\n",
    "    #a_vec.sort()\n",
    "    anoz=np.nonzero(a_vec)\n",
    "    a_vecf=a_vec[anoz]\n",
    "    #b_vec = b_vec.ravel()\n",
    "    bnoz=np.nonzero(b_vec)\n",
    "    b_vecf=b_vec[bnoz]\n",
    "    return l_vecf.reshape((1,-1)),a_vecf.reshape((1,-1)),b_vecf.reshape((1,-1))\n",
    "def makeLabvectorsprettyind(l_vec):\n",
    "    lnoz=np.nonzero(l_vec)\n",
    "    l_vecf=l_vec[lnoz]\n",
    "    return l_vecf.reshape((1,-1))\n",
    "\n",
    "def makelinspacevector(vector):\n",
    "    max_vec=np.max(vector)\n",
    "    min_vec=np.min(vector)\n",
    "    #print(vector.shape)\n",
    "    xshape,yshape=vector.shape\n",
    "    \n",
    "    #print(yshape)\n",
    "    lin_vec = np.linspace(min_vec, max_vec,num=yshape)\n",
    "    return lin_vec\n",
    "\n",
    "def getkdefunction(vector):\n",
    "    #print(vector)\n",
    "    #print(vector.shape)\n",
    "    \n",
    "    \n",
    "    kde = KernelDensity(kernel=\"gaussian\", bandwidth=3)\n",
    "    \n",
    "    \n",
    "    if len(vector)==0:\n",
    "        log_dens=[0]\n",
    "      \n",
    "\n",
    "    else:\n",
    "        kde.fit(vector.reshape((1,-1)))\n",
    "        x_d=makelinspacevector(vector.reshape((1,-1)))\n",
    "        log_dens = kde.score_samples(x_d.reshape((1,-1)))\n",
    "        \n",
    "\n",
    "    return log_dens\n",
    "\n",
    "\n",
    "def getkdepeaksLABind(l_vec):\n",
    "    vector=makeLabvectorsprettyind(l_vec)\n",
    "    \n",
    "    if len(l_vec)!=0:\n",
    "        \n",
    "        log_dens_l=getkdefunction(l_vec)\n",
    "        x_d=makelinspacevector(l_vec.reshape((1,-1)))\n",
    "        #density = norm(l_vec).pdf(x_d)\n",
    "        #yes=here\n",
    "        kde = KernelDensity(bandwidth=1.0, kernel='gaussian')\n",
    "        kde.fit(l_vec[:, None])\n",
    "        logprob = kde.score_samples(x_d[:, None])\n",
    "        \n",
    "        #peaks_l, _ = find_peaks(logprob)\n",
    "        \n",
    "        intneg,intpos=getthecolourscores(vector)\n",
    "        #print(log_dens_l)\n",
    "        #%matplotlib qt\n",
    "        #plt.figure()\n",
    "        #plt.fill_between(x_d, density, alpha=0.5)\n",
    "        \n",
    "        #plt.plot(x_d, np.exp(logprob))\n",
    "        #plt.hist(l_vec,bins=5)\n",
    "        #plt.plot(density)\n",
    "        #plt.hist(l_vec, bins=8)\n",
    "        #plt.plot(x_d,density)\n",
    "        #plt.plot(peaks_l, logprob[peaks_l], \"x\")\n",
    "        #plt.show()\n",
    "        #stop=here\n",
    "        \n",
    "    #if len(peaks_l)==0:\n",
    "        #peaks_l=[0]\n",
    "    if len(intpos)==0:\n",
    "        intpos=[0.1]\n",
    "        intneg=[0.1]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #print(peaks_l)\n",
    "    #print(peaks_b)\n",
    "    #print(peaks_a)\n",
    "    #plt.figure()\n",
    "    #plt.plot(log_dens_a)\n",
    "    #plt.plot(peaks_a, log_dens_a[peaks_a], \"x\")\n",
    "    #plt.show()\n",
    "    #yes=here\n",
    "    return intneg,intpos#peaks_l    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def gethistogrampeaksLAB(l_vec,a_vec,b_vec):\n",
    "    l_vec,a_vec,b_vec=makeLabvectorspretty(l_vec,a_vec,b_vec)\n",
    "    peaks_l,peaks_a,peaks_b=getkdepeaksLAB(l_vec,a_vec,b_vec)\n",
    "    \n",
    " \n",
    "\n",
    "    return peaks_l,peaks_a,peaks_b,y_l,y_a,y_b\n",
    "\n",
    "def processimagecrop(vector,w,pt):\n",
    "    cropimage=vector[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "    #print(cropimage)\n",
    "    cropimr=cropimage.reshape((1,-1))\n",
    "    #print(cropimr)\n",
    "    return cropimr\n",
    "def keepemptyindex(vector,point):\n",
    "    item=vector[np.nonzero(vector)]\n",
    "    pointlist=point\n",
    "    return item, pointlist\n",
    "\n",
    "def checkforempty(vector,points):\n",
    "    vector2,pointlist=map(list,zip(*[keepemptyindex(item,points[index]) for index,item in enumerate(vector) if len(item[np.nonzero(item)])!=0]))\n",
    "    \n",
    "    return vector2,np.asarray(pointlist).reshape((-1,2))\n",
    "    \n",
    "\n",
    "def getaveragevaluesLAB(image,points,analpath,yespeaks):\n",
    "    #A function which gets the colour scores for each lab colour vector by finding the vector, doing a kde desnsity graph of each value, splitting that kde density in half \n",
    "    # and then integrating each half\n",
    "    ####input: image- the image you want to analyse\n",
    "    ###########points- the centre of each particle you want to analyse\n",
    "    ##########analpath- the place to save the analysis\n",
    "    ##########yespeaks- an optional boolean so you have the option to not get the scores for each round. \n",
    "    #width of the sampling box around the particle center\n",
    "    w=8\n",
    "    #convert to lab colourspace\n",
    "    labim = rgb2lab(image)\n",
    "    #split into individual vectors\n",
    "    l_vec,a_vec,b_vec = cv.split(labim)\n",
    "    average_colour_aDivg=[]\n",
    "    max_val_lDivg=[]\n",
    "    average_lum=[]\n",
    "    average_comp_a_to_b=[]\n",
    "    info_l=[]\n",
    "    info_a=[]\n",
    "    info_b=[]\n",
    "    allchannel=[l_vec,a_vec,b_vec]\n",
    "    \n",
    "    #Get the cropped particles around the center points\n",
    "    allcropimagesl=[processimagecrop(l_vec,w,pt) for pt in points if len(l_vec)!=0]\n",
    "    #print(points)\n",
    "    #check that the cropped images aren't empty, delete the empty ones\n",
    "    allcropimagesl2,pointlistl=checkforempty(allcropimagesl,points)\n",
    "    \n",
    "    \n",
    "    #repeat for the a vector\n",
    "    allcropimagesa=[processimagecrop(a_vec,w,pt) for pt in pointlistl]\n",
    "    allcropimagesa2,pointlist_a=checkforempty(allcropimagesa,pointlistl)\n",
    "   \n",
    "    \n",
    "    #repeat for the b vector\n",
    "    allcropimagesb=[processimagecrop(b_vec,w,pt) for pt in pointlist_a]\n",
    "    allcropimagesb2,pointlist_b=checkforempty(allcropimagesb,pointlist_a)\n",
    "    \n",
    "    #for each cropped image, perform the kde analysis and get the colour score by integration. repeat for the three vectors. \n",
    "    neg_l,pos_l=map(list,zip(*[getkdepeaksLABind(vector) for vector in allcropimagesl2 if yespeaks==1]))\n",
    "  \n",
    "\n",
    "    greenscore,redscore=map(list,zip(*[getkdepeaksLABind(vector) for vector in allcropimagesa2 if yespeaks==1]))\n",
    "\n",
    "  \n",
    "    bluescore,yellowscore=map(list,zip(*[getkdepeaksLABind(vector) for vector in allcropimagesb2 if yespeaks==1]))\n",
    "   \n",
    "    return neg_l,pos_l,greenscore,redscore,bluescore,yellowscore,pointlist_b\n",
    "\n",
    "\n",
    "\n",
    "######### Extra functions\n",
    "\n",
    "def getindividualfoldersandsuch(bigfol):\n",
    "# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\n",
    "    topfolders=listdirs(bigfol)\n",
    "    subfolders=[0]\n",
    "    for nextfolders in topfolders:\n",
    "        subfolders= subfolders+ listdirs(nextfolders)\n",
    "    subfolders.pop(0)\n",
    "    #print(subfolders)\n",
    "    subfolders=np.array(subfolders).reshape(-1,1)\n",
    "    #print(subfolders)\n",
    "    return subfolders\n",
    "def searchforsatandtargetfolders(folder):\n",
    "#finds the satellite and targetfolders using regexp\n",
    "    subfolders2 = folder.tolist()\n",
    "    subfolders3=str(subfolders2).replace('[','').replace(']','').replace('\\\\\\\\','\\\\')\n",
    "\n",
    "    listexpfolders=listdirs(subfolders3[1:len(subfolders3)-1])\n",
    "    beforefol = [x for x in listexpfolders if re.search(\"satellite\",x)]\n",
    "    beforefol=beforefol[0]\n",
    "    afterfol= [x for x in listexpfolders if re.search(\"target\",x)]\n",
    "    afterfol=afterfol[0]\n",
    "    \n",
    "    return beforefol,afterfol\n",
    "\n",
    "def createanalysisfolder(beforefol,string):\n",
    "#creates an analysis folder in the address above where the satellite and target folders are located.\n",
    "    oneuppath=os.path.dirname(beforefol)\n",
    "    analysisfolderpath=oneuppath+\"\\\\\"+string\n",
    "    try:\n",
    "        os.mkdir(analysisfolderpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    print(analysisfolderpath)\n",
    "    print(\"processing images\")\n",
    "    return analysisfolderpath,oneuppath\n",
    "\n",
    "def createimagesubfolderforsaving(pathtomatch,analysisfolderpath):\n",
    "# creates a folder with the name of the image in the analysis folder \n",
    "    pathtomatch=beforeimfile[j]\n",
    "    matchingsearch=re.search(\"IMG_.*.CR2\",pathtomatch)\n",
    "    savefilespath=analysisfolderpath+\"\\\\\"+matchingsearch.group()+\"\\\\\"\n",
    "    try: \n",
    "        os.mkdir(savefilespath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    return savefilespath\n",
    "def addstringwithtime(savefilespath):\n",
    "# adds the current date and time so there's no saving over the top of different analysis\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    savepath=savefilespath+dt_string\n",
    "    return savepath\n",
    "def makeanalysisfolder(savefilespath,string):\n",
    "# makes a directory in the folder which matches the image name which says 'analysis'\n",
    "    analpath=os.path.join(savefilespath,string)\n",
    "                        #saves the registered image\n",
    "    try: \n",
    "        os.mkdir(analpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    return analpath\n",
    "\n",
    "################ THRESHOLDING\n",
    "\n",
    "def getcentroidsandcenters(image):\n",
    "    ### a function which gets the centres of particles. It's not perfect but it's okay\n",
    "    \n",
    "    h=8\n",
    "    src=image.copy()\n",
    "    #turns the image black and white\n",
    "    bw = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    #_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #Finds the contours of the black and white image\n",
    "    contours, hierarchy = cv.findContours(bw, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    list_of_centres=[]\n",
    "    boundRect = [None]*len(contours)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    #filters for repeats of the same point by drawing a rectangle around it and seeing if it overlaps using non_max_suppression\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        center_circle, _ = cv.minEnclosingCircle(contours_poly[i])\n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(boundRect),0.5) \n",
    "   \n",
    "    \n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        list_of_centres.append((startX+h//2,startY+h//2))\n",
    "        #rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "    #list_of_centres.append((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "    for centers in list_of_centres:\n",
    "        cv.circle(src, ((np.int(np.round(centers[0])),np.int(np.round(centers[1])))), 20, (255, 255, 0), 1)\n",
    "\n",
    "        \n",
    "    return list_of_centres\n",
    "\n",
    "def returnlistoftargeteddimers(scorelist,greenscore,redscore):\n",
    "    ### just a function that returns the filtered values for a list of attributes\n",
    "    returnedlist=np.array(scorelist)[np.logical_and(np.array(greenscore)>100,np.array(redscore)>200)]\n",
    "    \n",
    "    return returnedlist\n",
    "def returnlistoftargetedcores(scorelist,greenscore,redscore):\n",
    "    ### just a function that returns the filtered values for a list of attributes\n",
    "    returnedlist=np.array(scorelist)[np.logical_and(np.array(greenscore)<-50,np.array(redscore)<-100)]\n",
    "    \n",
    "    return returnedlist\n",
    "\n",
    "def drawcirclesandsave(image,points,analpath,string):\n",
    "    #####A function which draws circles on an image given some points. Truly thrilling lol\n",
    "    ##inputs: image- the image you're drawing circles on\n",
    "    #########points- the centers of the circles you want to draw\n",
    "    ########analpath- the analysis path where you want to save the image\n",
    "    ########string- a description of the image\n",
    "    circleim=image.copy()\n",
    "    for pt in points:\n",
    "        cv.circle(circleim, (pt[0],pt[1]), 8, (255, 255, 0), 4)\n",
    "    savepath=analpath+'\\\\'+string\n",
    "    performsaveimage(circleim,savepath)\n",
    "    \n",
    "def performthresholdingLABfortarget(beforeim,afterim,analpath):\n",
    "    ### performs the thresholding using LAB colour vectors. Integrates these vectors for each particle to come up with colourscores for each particle, then filtered.\n",
    "    ##inputs: beforeim- dimer image\n",
    "    #########afterim-target image\n",
    "    ##### used for target data, change if you want red to green instead of green to red\n",
    "    ##outputs: list_of_data- colourscores for each target particle selected \n",
    "    ##########dimer_points2- the centres of each particle for each target particle selected\n",
    "    ##########listofdatabefore-the colourscores for each dimer particle corresponding to the selected target\n",
    "    ##########core_points2- confusing, sorry, will fix eventually. The centers of each selected dimer particle\n",
    "    #gets the list of centers of all particles using the centroid function on the before images\n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    #For each center found, get the corresponding colour and luminance values\n",
    "    neg_l,pos_l,greenscore,redscore,bluescore,yellowscore,pointlist_b=getaveragevaluesLAB(beforeim,list_of_centres,analpath,1)\n",
    "    #filter the selected points using green and red score parameters\n",
    "    filtercore=np.asarray(np.logical_and(np.array(greenscore)>100,np.array(redscore)>200))\n",
    "    #it goes funny if I try normally filtering it so I have to do this yuck version\n",
    "    core_points=np.array(pointlist_b)*filtercore\n",
    "    core_points2=(core_points[core_points!=0]).reshape((-1,2))\n",
    "    #Draw the circles of the selected particles on the image and save it in the analysis folder\n",
    "    drawcirclesandsave(beforeim,core_points2,analpath,\"dimers_selected.png\")\n",
    "    print(\"done the dimer points\")\n",
    "    \n",
    "    #Do the same process for the target, using the dimer points from before and seeing if any dimer particles have gone green\n",
    "    neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d,pointlist_d=getaveragevaluesLAB(afterim,core_points2,analpath,1)\n",
    "    #print(\"done the dimer points\")\n",
    "    filterdimer=np.asarray(np.logical_and(np.asarray(greenscore_d).reshape((-1,1))<-50,np.asarray(redscore_d).reshape((-1,1))<-100))\n",
    "    dimer_points=np.array(pointlist_d)*filterdimer\n",
    "    dimer_points2=(dimer_points[dimer_points!=0]).reshape((-1,2))\n",
    "    drawcirclesandsave(afterim,dimer_points2,analpath,\"target_selected.png\")\n",
    "    #targeted_points=np.array(core_points).reshape((-1,2))[np.logical_and(np.asarray(greenscore).reshape((-1,1))>100,np.asarray(redscore).reshape((-1,1))>100)]    \n",
    "    neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c,pointlist_c=getaveragevaluesLAB(beforeim,dimer_points2,analpath,1)\n",
    "    arrayofdata=[neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d]\n",
    "    list_of_data=[returnlistoftargetedcores(scorelist,greenscore_d,redscore_d) for scorelist in arrayofdata]\n",
    "    listofdatabefore=[neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c]\n",
    "\n",
    "    return list_of_data,core_points2,dimer_points2,listofdatabefore\n",
    "    \n",
    "    \n",
    "def performthresholdingLABforruler(beforeim,afterim,analpath):\n",
    "    ### performs the thresholding using LAB colour vectors. Integrates these vectors for each particle to come up with colourscores for each particle, then filtered.\n",
    "    ##inputs: beforeim- core image\n",
    "    #########afterim-dimer image\n",
    "    ##### used for ruler data, change if you want green to red instead of red to green\n",
    "    ##outputs: list_of_data- colourscores for each dimer particle selected \n",
    "    ##########dimer_points2- the centres of each particle for each dimer particle selected\n",
    "    ##########listofdatabefore-the colourscores for each core particle corresponding to the selected dimer\n",
    "    \n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    \n",
    "    neg_l,pos_l,greenscore,redscore,bluescore,yellowscore,pointlist_b=getaveragevaluesLAB(beforeim,list_of_centres,analpath,1)\n",
    "    filtercore=np.asarray(np.logical_and(np.array(greenscore)<-50,np.array(redscore)<-100))\n",
    "    core_points=np.array(pointlist_b)*filtercore\n",
    "    \n",
    "    core_points2=(core_points[core_points!=0]).reshape((-1,2))\n",
    "    drawcirclesandsave(beforeim,core_points2,analpath,\"cores_selected.png\")\n",
    "    \n",
    "    \n",
    "    print(\"done the core points\")\n",
    "    neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d,pointlist_d=getaveragevaluesLAB(afterim,core_points2,analpath,1)\n",
    "    #print(\"done the dimer points\")\n",
    "    filterdimer=np.asarray(np.logical_and(np.asarray(greenscore_d).reshape((-1,1))>100,np.asarray(redscore_d).reshape((-1,1))>200))\n",
    "    dimer_points=np.array(pointlist_d)*filterdimer\n",
    "    dimer_points2=(dimer_points[dimer_points!=0]).reshape((-1,2))\n",
    "    drawcirclesandsave(afterim,dimer_points2,analpath,\"dimers_selected.png\")\n",
    "    #targeted_points=np.array(core_points).reshape((-1,2))[np.logical_and(np.asarray(greenscore).reshape((-1,1))>100,np.asarray(redscore).reshape((-1,1))>100)]\n",
    "    \n",
    "    neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c,pointlist_c=getaveragevaluesLAB(beforeim,dimer_points2,analpath,1)\n",
    "    \n",
    "    arrayofdata=[neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d]\n",
    "    list_of_data=[returnlistoftargeted(scorelist,greenscore_d,redscore_d) for scorelist in arrayofdata]\n",
    "    \n",
    "    listofdatabefore=[neg_l_c,pos_l_c,greenscore_c,redscore_c,bluescore_c,yellowscore_c]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return list_of_data,dimer_points2,listofdatabefore\n",
    "subfolders=getindividualfoldersandsuch(bigfol)\n",
    "\n",
    "for folder in subfolders:\n",
    "    #automatically find the before and after folder \n",
    "    beforefol,afterfol= searchforsatandtargetfolders(folder)\n",
    "    \n",
    "    #Create the relevant folder for saving,as well as the path one folder up \n",
    "    #analysisfolderpath_temp,oneuppath_temp=createanalysisfolder(beforefol,\"Analysisfolder_Template\")\n",
    "    analysisfolderpath_thresh,oneuppath_thresh=createanalysisfolder(beforefol,\"Analysisfolder_thresholding\")\n",
    "    \n",
    "    \n",
    "    #loadsall the images in \n",
    "\n",
    "    imaf,imbef,beforeimfile,afterimfile=imageprocessingfunction(beforefol,afterfol)\n",
    "    print(\"processed and converted images\")\n",
    "    \n",
    "    \n",
    "    #response=[0]*len(beforeimfile)\n",
    "    #dimercount=[0]*len(beforeimfile)\n",
    "    #targetcount=[0]*len(beforeimfile)\n",
    "    response_thresh=[0]*len(beforeimfile)\n",
    "    dimercount_thresh=[0]*len(beforeimfile)\n",
    "    targetcount_thresh=[0]*len(beforeimfile)\n",
    "    dimer_greenscore=[0]*len(beforeimfile)\n",
    "    dimer_redscore=[0]*len(beforeimfile)\n",
    "    dimer_yellowscore=[0]*len(beforeimfile)\n",
    "    dimer_bluescore=[0]*len(beforeimfile)\n",
    "    dimer_lscore=[0]*len(beforeimfile)\n",
    "    target_greenscore=[0]*len(beforeimfile)\n",
    "    target_redscore=[0]*len(beforeimfile)\n",
    "    target_yellowscore=[0]*len(beforeimfile)\n",
    "    target_bluescore=[0]*len(beforeimfile)\n",
    "    target_lscore=[0]*len(beforeimfile)\n",
    "    #t = tqdm(total=len(imbef))\n",
    "    for j,image in enumerate(imbef):\n",
    "        \n",
    "\n",
    "        pathtomatch=beforeimfile[j]\n",
    "        #savefilespath_temp= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_temp)\n",
    "        savefilespath_thresh= createimagesubfolderforsaving(pathtomatch,analysisfolderpath_thresh)\n",
    "        \n",
    "        \n",
    "        #add on the currentdate and time \n",
    "        #savepath_temp=addstringwithtime(savefilespath_temp)\n",
    "        savepath_thresh=addstringwithtime(savefilespath_thresh)\n",
    "        \n",
    "        \n",
    "        print(\"calculating image \"+str(j+1)+\" of \"+ str(len(imbef)))\n",
    "        \n",
    "        #make an analysis folder which says analysis in the image folder just created \n",
    "        #analpath_temp=makeanalysisfolder(savefilespath_temp,\"Analysisimages_Template\")\n",
    "        analpath_thresh=makeanalysisfolder(savefilespath_thresh,\"Analysisimages_thresholding\")\n",
    "        \n",
    "        #spot matches the before and after images \n",
    "        transimaf=imgregfun(image, imaf[j])\n",
    "        #saves the redistered image\n",
    "        saveregisteredimage=os.path.join(analpath_thresh, \"registeredimg\" + \".\" + \"png\")\n",
    "        performsaveimage(transimaf,saveregisteredimage)\n",
    "       \n",
    "        #uncomment if you want a crop box    \n",
    "        #height, width = image.shape[:2]\n",
    "        #boxwid=round(1500/2)\n",
    "        #centreimagebefore=image[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        #centreimageafter=transimaf[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "        centreimagebefore=labcolourfilt(image)\n",
    "        \n",
    "        print(\"Made the clipping Mask\")\n",
    "        #plt.imshow(centreimagebefore)\n",
    "        centreimageafter=labcolourfilt(transimaf)\n",
    "        \n",
    "        #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "            #pbar.write('processed: %d' % (j+1))\n",
    "            #pbar.update(0.75)\n",
    "            #sleep(0.1)\n",
    "        list_of_data,dimer_points,target_points,listofdatabefore=performthresholdingLABfortarget(centreimagebefore,centreimageafter,analpath_thresh)\n",
    "        #print(np.array(list_of_data).shape)\n",
    "        neg_l_d,pos_l_d,greenscore_d,redscore_d,bluescore_d,yellowscore_d=np.vsplit(np.array(listofdatabefore), 6)\n",
    "        #print(neg_l_d.shape)\n",
    "        neg_l,pos_l,greenscore,redscore,bluescore,yellowscore=np.vsplit(np.array(list_of_data), 6)\n",
    "\n",
    "        #print(neg_l.shape)\n",
    "        #print(neg_l.reshape((-1,1)))\n",
    "\n",
    "        neg_l=neg_l.reshape((-1,1))\n",
    "        pos_l=pos_l.reshape((-1,1))\n",
    "        greenscore=greenscore.reshape((-1,1))\n",
    "        redscore=redscore.reshape((-1,1))\n",
    "        bluescore=bluescore.reshape((-1,1))\n",
    "        yellowscore=yellowscore.reshape((-1,1))\n",
    "\n",
    "        neg_l_d=neg_l.reshape((-1,1))\n",
    "        pos_l_d=pos_l.reshape((-1,1))\n",
    "        greenscore_d=greenscore_d.reshape((-1,1))\n",
    "        redscore_d=redscore_d.reshape((-1,1))\n",
    "        bluescore_d=bluescore_d.reshape((-1,1))\n",
    "        yellowscore_d=yellowscore_d.reshape((-1,1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #saves the to an excel spreadsheet and saves the results to a list to get the overall results at the end \n",
    "        #if I feel bothered I can add something in that uses the already analysed images but meh \n",
    "\n",
    "        \n",
    "        dimercount_thresh[j]=len(dimer_points)\n",
    "        targetcount_thresh[j]=len(target_points)\n",
    "        saveexpath=analpath_thresh+'\\\\'+\"responseforallimages.xlsx\"\n",
    "\n",
    "        # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "        writer = pd.ExcelWriter('pandas_multiple.xlsx', engine='xlsxwriter')\n",
    "        dimerresp=pd.DataFrame({'dimer_greenscore':greenscore_d,'dimer_yellowscore':yellowscore_d,'dimer_redscore':redscore_d,'dimer_bluescore':bluescore_d,'dimer_luminosity':neg_l_d})\n",
    "        targresp=pd.DataFrame({'target_greenscore':greenscor,'target_yellowscore':yellowscore,'target_redscore':redscore,'target_bluescore':bluescore,'target_luminosity':neg_l})\n",
    "        # Write each dataframe to a different worksheet.\n",
    "        dimerresp.to_excel(writer, sheet_name='DimerData')\n",
    "        targetresp.to_excel(writer, sheet_name='Sheet2')\n",
    "        \n",
    "\n",
    "        # Close the Pandas Excel writer and output the Excel file.\n",
    "        writer.save()\n",
    "        try: \n",
    "            response_thresh[j]=(len(target_points)/len(dimer_points))*100\n",
    "            \n",
    "        except:\n",
    "            response_thresh[j]=0\n",
    "\n",
    "  \n",
    " \n",
    "    print(\"Finished analysis woohoo\")\n",
    "    #t.close()\n",
    "    \n",
    "    searchfolder_thresh=oneuppath_thresh\n",
    "    #insearchfolder=os.listdir(searchfolder)\n",
    "    savedir_thresh= searchfolder_thresh+'\\\\'+\"Analysisfolder_thresholding\"\n",
    "    imagefilefolders=os.listdir(savedir_thresh)\n",
    "    #Write excel worsheet in the analysis folder\n",
    "    #print(dimercount_thresh)\n",
    "    \n",
    "    responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount_thresh),'target_picked':np.array(targetcount_thresh),'response': np.array(response_thresh)})\n",
    "    \n",
    "    responsepath_thresh=savedir_thresh+'\\\\'+\"responseforallimages.xlsx\"\n",
    "\n",
    "    responseforexcel.to_excel(responsepath_thresh) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3faef-fac1-4d5a-9e73-e13ab65790d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bc7c79-9f0f-4730-a470-bd965725c4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1997, 571, 890, 981, 579, 1936]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f382608-fa0a-47a9-97d6-d715453004c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
