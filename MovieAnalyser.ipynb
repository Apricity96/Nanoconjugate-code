{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n",
      "D:\\OneDrive - UNSW\\Image_Analysis\\Spectra\\OneDrive_2021-10-18\\Analysisfolder\n",
      "processing images\n",
      "folder already exists\n",
      "D:\\OneDrive - UNSW\\Image_Analysis\\Spectra\\OneDrive_2021-10-18\\images\n",
      "processing images\n"
     ]
    }
   ],
   "source": [
    "##### CHANGE THIS TO YOUR MOVIE##################\n",
    "##################################################\n",
    "bigfol=r\"D:\\OneDrive - UNSW\\Image_Analysis\\Spectra\\OneDrive_2021-10-18\\C0117.mp4\"\n",
    "##################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialise dependencies\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "import imageio\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "#import hcluster\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from math import pow\n",
    "import scipy.signal \n",
    "%matplotlib qt\n",
    "#template matching\n",
    "import cv2 as cv2\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "\n",
    "def readinimageframes(video_address,savefol):\n",
    "    vidcap = cv2.VideoCapture(video_address)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        if count >3000:\n",
    "            mod= count %100\n",
    "            if mod ==0:\n",
    "                path1= str(count) +\"frame.png\"\n",
    "                savepath=os.path.join(savefol,path1)\n",
    "                cv2.imwrite(savepath, image)     # save frame as JPEG file      \n",
    "                success,image = vidcap.read()\n",
    "                yield image\n",
    "            count += 1\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#General Functions\n",
    "def listdirs(folder):\n",
    "## a function which lists the files in a folder and adds to a list. returns a list of folders, \n",
    "##input folder: the file path to folder\n",
    "    return [\n",
    "        d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder))\n",
    "        if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "def makeclippingmask(image):\n",
    "    \n",
    "\n",
    "    #makes a clipping mask around each bright spot so the analysis isn't thrown off\n",
    "    grayA = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    blurred = cv.GaussianBlur(grayA, (11,11), 0)\n",
    "\n",
    "    #watershed thresholding. Based on: https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html\n",
    "    src = image.copy()\n",
    "    \n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    imgLaplacian = np.clip(imgLaplacian, 0, 255)\n",
    "    imgLaplacian = np.uint8(imgLaplacian)\n",
    "    #cv.imshow('Laplace Filtered Image', imgLaplacian)\n",
    "    #cv.imshow('New Sharped Image', imgResult)\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n",
    "   # _, bw2 = cv.threshold(grayA, 30, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    #plt.imshow(bw)\n",
    "    bw = cv.adaptiveThreshold(bw, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 37, 1)\n",
    "    #cv.imshow('Binary Image', bw)\n",
    "    \n",
    "    \n",
    "    opening = cv.morphologyEx(bw,cv.MORPH_OPEN,kernel, iterations = 3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    # Threshold to obtain the peaks\n",
    "    # This will be the markers for the foreground objects\n",
    "    _, sure_fg = cv.threshold(dist_transform, 0.2, 1.0, cv.THRESH_BINARY)\n",
    "    # Dilate a bit the dist image\n",
    "    kernel1 = np.ones((3,3), dtype=np.uint8)\n",
    "    sure_fg = cv.dilate(sure_fg, kernel1)\n",
    "    ret, markers = cv.connectedComponents(np.uint8(sure_fg))\n",
    "    \n",
    "    \n",
    "    #cv.imshow('Final Result', sure_fg)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.float32(sure_fg)\n",
    "    sure_bg = np.float32(sure_bg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    #cv.imshow('Distance Transform Image', dist_transform)\n",
    "    \n",
    "    # Marker labelling\n",
    "    \n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    #print(markers.shape)\n",
    "    \n",
    "    markers = cv.watershed(imgResult,markers)\n",
    "    #print(markers)\n",
    "    \n",
    "    mask2 = np.zeros(image.shape[:2], dtype= np.uint8)\n",
    "    mask2[markers >1] = [255]\n",
    "    \n",
    "    #colours=((255,255,255))\n",
    "    # Fill labeled objects with random colors\n",
    "    #for i in range(markers.shape[0]):\n",
    "    #    for j in range(markers.shape[1]):\n",
    "    #        index = markers[i,j]\n",
    "    #        if index>0:\n",
    "    #            mask2[i,j] = 255\n",
    "    \n",
    "\n",
    "    image_rgb=image.copy()\n",
    "    image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    #plt.imshow(image_blocked)\n",
    "    return image_blocked\n",
    "\n",
    "def imgregfun(imagebef, imageafter):\n",
    "#### A function for image registration, stolen of the internet but I can't remember where from\n",
    "###Inputs: imagebef- the before image\n",
    "##########imageafter- the after image\n",
    "###outputs: transimaf- the translated after image\n",
    "    # Open the image files.\n",
    "    img1_color = imageafter  # Image to be aligned.\n",
    "    img2_color = imagebef  # Reference image.\n",
    "\n",
    "    # Convert to grayscale.\n",
    "    img1 = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
    "    img2 = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)\n",
    "    height, width = img2.shape\n",
    "\n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv.ORB_create(5000)\n",
    "\n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not reqiured in this case).\n",
    "    kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "    kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # Match features between the two images.\n",
    "    # We create a Brute Force matcher with\n",
    "    # Hamming distance as measurement mode.\n",
    "    matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match the two sets of descriptors.\n",
    "    matches = matcher.match(d1, d2)\n",
    "\n",
    "    # Sort matches on the basis of their Hamming distance.\n",
    "    matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "    # Take the top 90 % matches forward.\n",
    "    matches = matches[:np.int(len(matches) * 90)]\n",
    "    no_of_matches = len(matches)\n",
    "\n",
    "    # Define empty matrices of shape no_of_matches * 2.\n",
    "    p1 = np.zeros((no_of_matches, 2))\n",
    "    p2 = np.zeros((no_of_matches, 2))\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "        p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "\n",
    "    # Find the homography matrix.\n",
    "    homography, mask = cv.findHomography(p1, p2, cv.RANSAC)\n",
    "\n",
    "    # Use this matrix to transform the\n",
    "    # colored image wrt the reference image.\n",
    "    transformed_img = cv.warpPerspective(img1_color, homography,\n",
    "                                          (width, height))\n",
    "    transimaf=transformed_img\n",
    "    return transimaf\n",
    "def imageprocessingfunction(beforefol,afterfol):\n",
    "###A function for getting all the CR2 files within the before and after folders, then reading them\n",
    "### and saving them on the disk as virtual images \n",
    "##########################################################################\n",
    "###Inputs: beforefol: selected before folder\n",
    "##########afterfol: selected after folder \n",
    "###Outputs: imaf: the images in the after folder as an array\n",
    "###########imbef: the images in the before folder as an array \n",
    "###########beforeimfile: the list of before image files\n",
    "###########afterimfile: the list of after image files\n",
    "    # Get file list\n",
    "    beforeimfile=glob.glob(beforefol+\"\\\\\"+\"*.CR2\")\n",
    "    afterimfile=glob.glob(afterfol+\"\\\\\"+\"*.CR2\")\n",
    "    #print(afterimfile)\n",
    "\n",
    "    #Exifdata is just there in case you need to edit the images in a fancy way.\n",
    "    imaf,labaf,imbef,labef=[],[],[],[]\n",
    "    for impath in afterimfile:\n",
    "        image,exifdata=   convertfilefun(impath)\n",
    "        imaf.append(np.dstack((image)))\n",
    "        labaf.append(exifdata)\n",
    "    for impath in beforeimfile:\n",
    "        image,exifdata= convertfilefun(impath)\n",
    "        imbef.append(np.dstack((image)))\n",
    "        labef.append(exifdata)\n",
    "    return imaf,imbef,beforeimfile,afterimfile\n",
    "\n",
    "def convertfilefun(path):\n",
    "## a function which converts CR2 images to TIFF images the computer can actually read\n",
    "## input: path- path to raw image\n",
    "## output : an image that is readable using cv2\n",
    "    with rawpy.imread(path) as raw:\n",
    "        #Can fiddle with camera settings but I wouldn't reccoment it\n",
    "        rgb = raw.postprocess(use_camera_wb=True,\n",
    "                              no_auto_bright=True,\n",
    "                              gamma=(2.222, 4.5),\n",
    "                              chromatic_aberration=(1, 1))\n",
    "        #cv2.imwrite(path + '.tiff',rgb)\n",
    "        # extract EXIF data to save as metadata\n",
    "        metdat = Image.open(path)\n",
    "        exifdata = metdat.getexif()\n",
    "        image = rgb\n",
    "        image = rgb.reshape(\n",
    "            (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        return image, exifdata\n",
    "        #plt.imsave(path + '.png',rgb)\n",
    "        #g=print(path + '.png')\n",
    "        #return g\n",
    "        \n",
    "def saveexcelfun(dimercoord,corecoord,savepath):\n",
    "#Save the coordinates of everything to an excel spreadsheet. Yeah I know it's ugly. \n",
    "#input: dimercoord- the dimer coordinates\n",
    "########corecoord- the core coordinates \n",
    "########savepath- the folder location where the files will be saved \n",
    "    columns=['Before Dimers xval']\n",
    "    saveexcel=savepath+\".\"+\"xlsx\"\n",
    "    beforedimercentres = pd.DataFrame({'Before Dimers xval':dimercoord})\n",
    "    try:\n",
    "        aftercorecentres = pd.DataFrame({'After core xval': corecoord})\n",
    "    except:\n",
    "        aftercorecentres=pd.DataFrame({'After core xval': np.array([0]), \n",
    "                                'After core yval': np.array([0])})\n",
    "\n",
    "   \n",
    "    writer = pd.ExcelWriter(saveexcel,engine='xlsxwriter')\n",
    "    workbook=writer.book\n",
    "    worksheet=workbook.add_worksheet('DimersPicked')\n",
    "    writer.sheets['DimersPicked'] = worksheet\n",
    "    worksheet2=workbook.add_worksheet('CoresPicked')\n",
    "    writer.sheets['CoresPicked'] = worksheet2\n",
    "\n",
    "\n",
    "    beforedimercentres.to_excel(writer,sheet_name='DimersPicked',startrow=1 , startcol=0)\n",
    "    #worksheet.write_string(beforedimercentres.shape[0] + 4, 0, beforedimercentres.name)\n",
    "\n",
    "    aftercorecentres.to_excel(writer,sheet_name='CoresPicked',startrow=1, startcol=3)\n",
    "    \n",
    "\n",
    "    writer.save()\n",
    "def savetextfilefun(data,savepath,datastring):\n",
    "##### A function which saves an array to a text file. Is a little buggy in that sometimes there's weird spaces. \n",
    "##### reccomend the excel save functions instead. Python struggles to re-read these text tiles\n",
    "\n",
    "    savetextstring=savepath+datastring+\".txt\"\n",
    "    file = open(savetextstring,\"w\")\n",
    "    for dataentry in data:\n",
    "        arr_of_strings = np.array2string(dataentry)\n",
    "        file.write(arr_of_strings) \n",
    "    file.close() \n",
    "    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "## A function which reads in images and adds them to a list of images.\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "## note !! The images wil be read in with open cv, and will be in BGR format and will look strange unless converted\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "def load_images_from_foldercv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to RGB\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "       \n",
    "        if img is not None:\n",
    "            img= cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "def load_images_from_folderhsv(folder):\n",
    "## A function which reads in images and adds them to a list of images. This function also converts them to HSV\n",
    "## input: folder- a string which points to the folder location\n",
    "## output: images, a list of images within the folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        img= cv.cvtColor(img,  cv.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#####################################################\n",
    "###################################################\n",
    "#Template matching functions\n",
    "\n",
    "\n",
    "def findidealimagescale(image,template):\n",
    "    # loop over the images to find the template in\n",
    "   \n",
    "        # load the image, convert it to grayscale, and initialize the\n",
    "        # bookkeeping variable to keep track of the matched region\n",
    "        \n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    template=cv.cvtColor(template, cv.COLOR_HSV2RGB)\n",
    "    template=cv.cvtColor(template, cv.COLOR_RGB2GRAY)\n",
    "    #template.astype(np.uint8)\n",
    "    #gray.astype(np.uint8)\n",
    "    found = None\n",
    "    scalefin= None\n",
    "    (h, w) = template.shape[:2]\n",
    "    i=0\n",
    "    # loop over the scales of the image\n",
    "    for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "        # resize the image according to the scale, and keep track\n",
    "        # of the ratio of the resizing\n",
    "        resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "        r = gray.shape[1] / float(resized.shape[1])\n",
    "        # if the resized image is smaller than the template, then break\n",
    "        # from the loop\n",
    "        if resized.shape[0] < h or resized.shape[1] < w:\n",
    "            break\n",
    "        result = cv.matchTemplate(gray, template, cv.TM_SQDIFF_NORMED)\n",
    "        (minval, _, minloc, _) = cv.minMaxLoc(result)\n",
    "        if found is None or minval < found:\n",
    "            found = minval\n",
    "            scalefin=scale\n",
    "    return scalefin \n",
    "        \n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "        \n",
    "def nonmaxsuppression(xCoords,yCoords,template):\n",
    "    center_coordinates=[]\n",
    "    rects=[]\n",
    "    rectangle_coordinates=[]\n",
    "    (w, h) = template.shape[:2]\n",
    "    #print(w)\n",
    "    #print(h)\n",
    "## stops the overcounting of variables with nonmax suppression and returns an updated list\n",
    "    for (x, y) in zip(xCoords, yCoords):\n",
    "    # update our list of rectangles\n",
    "        rects.append((x, y, x +w, y + h))\n",
    "    picked_rectangles=non_max_suppression_fast(np.array(rects),0.5)\n",
    "        #I hate how opencv does rectangles, so arrange these to finds the centres\n",
    "    for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "        center_coordinates.append((startX+h//2,startY+h//2))\n",
    "        rectangle_coordinates.append((startX, startY, endX, endY))\n",
    "     \n",
    "    #print(\"center coordinates are \",center_coordinates)\n",
    "    #print(\"rectangle_coordinates are \", rectangle_coordinates)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithm(img_hsv,template, method,threshold):\n",
    "# defines the template matching algorithm and finds the minimum locations\n",
    "#inputs: img_rgb- the image to be matched in HSV format\n",
    "#########template- the template to be matched in HSV format\n",
    "#########method- the method of determining the minim. cv.TM_SQDIFF_NORMED is good for colour\n",
    "##### extras found here: https://docs.opencv.org/master/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d\n",
    "#########threshold: the threshold where the minimum is defined. Variable. May want to do something with min_val and max\n",
    "#outputs: locations_of_minimum- a really big array that needs to be zipped. \n",
    "#Note: this works on colour (3 d) images but may want to change to just hue\n",
    "    \n",
    "    mat_of_matching_results=cv.matchTemplate(img_hsv,template,method) \n",
    "    #This is to get some details about the minimum but isn't actually used\n",
    "    #print(\"template matching done\")\n",
    "    (min_val, max_val, _, max_loc) = cv.minMaxLoc(mat_of_matching_results)\n",
    "    #print(\"The min is done\")\n",
    "    #print(min_val)\n",
    "    #print(max_val)\n",
    "    (yCoords, xCoords) = np.where( mat_of_matching_results <= ((max_val-min_val)/threshold)+min_val)\n",
    "    while (len(xCoords))>250000:\n",
    "        threshold=threshold+0.5\n",
    "        (yCoords, xCoords) = np.where( mat_of_matching_results <= ((max_val-min_val)/threshold)+min_val)\n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template)\n",
    "    \n",
    "    #print(locations_of_minimum)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "def templatematchingalgorithmscikit(img_hsv,template,threshold):\n",
    "    mat_of_matching_results = match_template(img_hsv, template,pad_input=True)\n",
    "    max_val=np.max(mat_of_matching_results)\n",
    "    min_val=np.min(mat_of_matching_results)\n",
    "    #max = np.unravel_index(np.argmax(result), result.shape)\n",
    "    #(min_val, max_val, _, max_loc) = cv.minMaxLoc(mat_of_matching_results)\n",
    "    threshold2=((max_val-min_val)/threshold)+min_val\n",
    "    peaks=peak_local_max(image, min_distance=10, threshold_abs=None, threshold_rel=0.75)\n",
    "    print(peaks)\n",
    "    xCoords=peaks[:,1]\n",
    "    yCoords=peaks[:,2]\n",
    "    center_coordinates,rectangle_coordinates,w,h=nonmaxsuppression(xCoords,yCoords,template)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def imagetempmatch(imgpath,img_rgb,threshold):\n",
    "## performs the template matching function on each template image found in imgpath\n",
    "## input: imgpath: a string pointing to the folder the template images are contained in\n",
    "##########img_rgb: the image to be matched, in rgb format \n",
    "##########threshold: the threshold at which the minimum is accepted. The minimum value is the value where the \n",
    "#####################template matching function thinks that the image is matched. Note, this may be a maximum \n",
    "####################for other methods\n",
    "    #loads the template images in as HSV\n",
    "    images=load_images_from_folderhsv(imgpath)\n",
    "    #Creates a mask which has the shape of the image to be matched. The dtype is important or error will occur. \n",
    "    # This mask is to test whether the template matching has counted the same point multiple times\n",
    "    mask = np.zeros(img_rgb.shape, dtype=np.uint8)\n",
    "    res=[[]];\n",
    "    scale=findidealimagescale(img_rgb,images[0])\n",
    "    #print(scale)\n",
    "    resized = imutils.resize(img_rgb, width = int(img_rgb.shape[1]*scale))\n",
    "    for template in tqdm(images):\n",
    "        #for each template, the width and height is taken\n",
    "        \n",
    "        w=16\n",
    "        h=16\n",
    "        \n",
    "        #big image converted to hsv format\n",
    "        img_hsv= cv.cvtColor(resized,  cv.COLOR_RGB2HSV)\n",
    "        #the location minima identified with the template matching algorithm\n",
    "        center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithm(img_hsv,template,cv.TM_SQDIFF_NORMED,threshold)\n",
    "        #center_coordinates,rectangle_coordinates,w,h=templatematchingalgorithmscikit(img_hsv,template,threshold)\n",
    "        \n",
    "        #print(\"locations of min are\", locations_of_min)\n",
    "        # the locations are checked for multiple counting of the same point. \n",
    "        #particle_count=checkfordoublecounting(img_hsv,locations_of_min)\n",
    "        #print(particle_count)\n",
    "    return center_coordinates,rectangle_coordinates,w,h\n",
    "\n",
    "\n",
    "def blockimagecombo(image_rgb, points,r,bok):\n",
    "    #print(points)\n",
    "    if bok==1:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,255), -1)\n",
    "    elif bok==2:\n",
    "        image_blocked=image_rgb.copy()\n",
    "        for pt in points:\n",
    "            \n",
    "            image_blocked = cv.circle(image_blocked,pt,r, (255,255,0), 2)\n",
    "        \n",
    "    else:\n",
    "        mask2 = np.zeros(image_rgb.shape[:2], dtype= np.uint8)\n",
    "        for pt in points: \n",
    "            #print(pt)\n",
    "            mask2 = cv.circle(mask2,pt,r, (255,255,255), -1)\n",
    "            \n",
    "            # a rectangle is drawn on the mask, which marks where the points are \n",
    "        #invmask=255-mask2\n",
    "        #This is an inbuilt cv function which clips the image around the mask. \n",
    "        #plt.imshow(cv.bitwise_and(image_rgb, image_rgb, mask=invmask))\n",
    "        image_blocked = cv.bitwise_and(image_rgb, image_rgb, mask=mask2)\n",
    "    return image_blocked\n",
    "\n",
    "\n",
    "\n",
    "def performtemplatematching(image_rgb,imgpath,bok,threshold):\n",
    "## a function which performs template matching on the images and blocks them depending on whether\n",
    "## we want to keep the particles or block them out for more accuracy \n",
    "#input: image_rgb: the big image in rgb format where we are looking for matches\n",
    "########imgpath: the path to the template images, as a string\n",
    "#########bok: block or keep. 0 is for keeping, 1 is for blocking with a rectange\n",
    "#########threshold: the threshold for the minimum values. Variable. \n",
    "    \n",
    "    center_coordinates,rectangle_coordinates,w,h=imagetempmatch(imgpath,image_rgb,threshold)\n",
    "    r=round(w/1.5)\n",
    "\n",
    "    correctedimg=blockimagecombo(image_rgb,center_coordinates ,r,bok)\n",
    "    return correctedimg,center_coordinates,r\n",
    "\n",
    "def performsaveimage(image,path):\n",
    "## saves image using pillow, which is a lot faster than matplot lib. \n",
    "    img_rgb_corr=image\n",
    "    try:\n",
    "        im_pil = Image.fromarray(img_rgb_corr)\n",
    "        im_pil.save(path, compress_level=1)\n",
    "    except:\n",
    "        exception=1\n",
    "\n",
    "def savetotrainingfol(foldername,image,points):\n",
    "## saves the cropped images to a folder, for use in machine learning. uses a 16 pixel box.\n",
    "#input: foldername: name of the folder where you want the images stored\n",
    "#######image: an image in rgb format which you want to cut up\n",
    "########points: the coordinates of the particles which you have selected. \n",
    "    boxwid=round(16/2)\n",
    "    w=16\n",
    "    for j,pt in enumerate(points):\n",
    "        savepathfol= addstringwithtime(foldername +'\\\\')\n",
    "        savepath= savepathfol+str(j)+\"registeredimg\" + \".\" + \"png\"\n",
    "        #savepath=os.path.join(savepathfol, str(j)+\"registeredimg\" + \".\" + \"png\")\n",
    "        lilimage=image[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "        performsaveimage(lilimage,savepath)\n",
    "def blockoutunwantedparticles(analpath,sat_img,path,threshold):\n",
    "## a function which blocks out that particles which are interfering with analysis i.e. clumps and clusters\n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#output: correctedimgcore, the corrected image after accounting for cores and clumps\n",
    "# These images are hardcoded into a folder, so the code has some dependencies. But any exmaples of the correct size will do\n",
    "    #The threshold of 0.25 seems to be highly variable\n",
    "    correctedimg,_,r= performtemplatematching(sat_img, path,1,threshold)\n",
    "    return correctedimg,r\n",
    "\n",
    "def unwantedparticleblocking(analpath,sat_img):\n",
    "    #clusterpath=  r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\Cluster\"\n",
    "    #threshold= 0.25\n",
    "    #correctedimgcluster=blockoutunwantedparticles(analpath,sat_img,clusterpath,threshold)\n",
    "    \n",
    "    clumppath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\clump\"\n",
    "    threshold=4\n",
    "    savepath=os.path.join(analpath, \"clumpcorrectedimg\" + \".\" + \"png\")\n",
    "    correctedimgclump,r=blockoutunwantedparticles(analpath,sat_img,clumppath,threshold)\n",
    "    performsaveimage(correctedimgclump,savepath)\n",
    "    \n",
    "    corepath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\core2\"\n",
    "    threshold=10\n",
    "    correctedimgcore,r=blockoutunwantedparticles(analpath,correctedimgclump,corepath,threshold)\n",
    "    savepath=os.path.join(analpath, \"corecorrectedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgcore,savepath)\n",
    "    \n",
    "    return correctedimgcore,r\n",
    "    \n",
    "def keepmatchedparticles(path,image,threshold):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "    correctedimgdimer,pointsdimer,r= performtemplatematching(image, path, 0, threshold)\n",
    "    \n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "                                                              \n",
    "\n",
    "def performkeepmatchedparticles(analpath,image):\n",
    "## a function which keeps the wanted particles and blocks out the rest. \n",
    "#inputs: analpath: the path to the analysis folder\n",
    "######## sat_img: the before target image in rgb format\n",
    "#########path: path to the images to analyse\n",
    "#outputs: the selected image and the dimer points selected\n",
    "    dimerpath= r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\dimer2\"\n",
    "    threshold=2\n",
    "    \n",
    "    correctedimgdimer,pointsdimer,r=keepmatchedparticles(dimerpath,image,threshold)\n",
    "    savepath=os.path.join(analpath, \"pickeddimersimg\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgdimer,savepath)\n",
    "    return correctedimgdimer,pointsdimer,r\n",
    "\n",
    "\n",
    "\n",
    "def getaveragevalueshsv(image,points,w,h,analpath):\n",
    "# a function to get the average values of the image in rgb format\n",
    "#inputs: image: the hsv image\n",
    "#########points: the selected dimer values\n",
    "#########w,h- the width and height in pixels\n",
    "#########analpath: the path to the analysis folder\n",
    "#outputs: an array of the average colour of the red divided by the green vector\n",
    "\n",
    "    average_colour_rDivg=[]\n",
    "    #converts the image to hsv\n",
    "    image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_rDivg)), \" min is \",np.min(np.array(average_colour_rDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_rDivg)), \"median is \", np.mean(np.array(average_colour_rDivg)) )\n",
    "    print(\"standard deviation is \", np.mean(np.array(average_colour_rDivg)))\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getaveragevaluesLAB(image,points,analpath):\n",
    "    w=8\n",
    "    labim = rgb2lab(image)\n",
    "    l_vec,a_vec,b = cv.split(labim)\n",
    "    average_colour_aDivg=[]\n",
    "    max_val_lDivg=[]\n",
    "    average_lum=[]\n",
    "    #converts the image to hsv\n",
    "    #image = cv.cvtColor(image,  cv.COLOR_RGB2HSV)\n",
    "    #image_hue=np.true_divide(image[:,:,0], image[:,:,1], where=(image[:,:,0]!=0) | (image[:,:,1]!=0))\n",
    "    #image_hue=image[:,:,0]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=a_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            \n",
    "            crop_im_lval=l_vec[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval_lval=crop_im_lval.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_aDivg.append(np.mean(dividedval))\n",
    "            \n",
    "            max_val_lDivg.append(np.max(dividedval_lval))\n",
    "            average_lum.append(np.mean(dividedval_lval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    if not average_colour_aDivg:\n",
    "        average_colour_aDivg=[0]\n",
    "    \n",
    "    print(\"max is \",np.max(np.array(average_colour_aDivg)), \" min is \",np.min(np.array(average_colour_aDivg)))\n",
    "    print(\"average is \", np.mean(np.array(average_colour_aDivg)), \"median is \", np.median(np.array(average_colour_aDivg)) )\n",
    "    print(\"standard deviation is \", np.std(np.array(average_colour_aDivg)))\n",
    "    return np.array(average_colour_aDivg),np.array(average_lum),np.array(max_val_lDivg)\n",
    "\n",
    "def averagehistogramshift(correctedimgdimer,pointsdimer,correctedimgtarget,threshold,analpath):\n",
    "# a function which uses the average shift of the particle colour (either hue or rgb depending ) to \n",
    "#select the particles which have shifted in the after image \n",
    "#inputs: correctedimgdimer: the image with only dimers selected\n",
    "#########pointsdimer: the locations of the dimers in the image\n",
    "#########correctedimgtarget: the registered image after target added wherein the coordinates of the selected\n",
    "# dimers have been used to clip it\n",
    "#########threshold: the values which the shifted average value must be above or below. was 0.2 \n",
    "#output: loc- the shifted selected particles. \n",
    "    avdim,ldim,maxldim=getaveragevaluesLAB(correctedimgdimer,pointsdimer,analpath)\n",
    "    \n",
    "    avcore,lcore,maxlcore=getaveragevaluesLAB(correctedimgtarget,pointsdimer,analpath)\n",
    "    minus= np.array(avdim)-np.array(avcore)\n",
    "    minus_l=np.array(ldim)-np.array(lcore)\n",
    "    \n",
    "    print(\"minus values here ------------\")\n",
    "    print(\"max value is \", np.max(minus), \"min value is \", np.min(minus), \" mean value is \", np.mean(minus))\n",
    "    print(\" median value is \", np.median(minus), \" standard deviation is \", np.std(minus))\n",
    "    loc=np.array(pointsdimer)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    ldim2=ldim[np.logical_and(minus>5,maxlcore>1)]\n",
    "    loc=loc[ldim2<30]\n",
    "    r=8\n",
    "    #loc=np.array(pointsdimer)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    targetpicked= blockimagecombo(correctedimgtarget,loc,r,0)\n",
    "    #average_values=np.array(minus)[np.logical_and(minus<threshold, minus > -3)]\n",
    "    average_values=np.array(minus)[np.logical_and(minus>5,maxlcore>1)]\n",
    "    #print(minus)\n",
    "    #average_values=average_values[ldim2<30]\n",
    "    #print(ldim2)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"tarmaskedimg\" + \".\" + \"png\")\n",
    "    performsaveimage(targetpicked,savepath)\n",
    "    return loc,average_values.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def performtemplatetrainingonimages(transtarimg,analpath,sat_img):\n",
    "    \n",
    "\n",
    "    #blocks unwated particles\n",
    "    correctedimgcore,r=unwantedparticleblocking(analpath,sat_img)\n",
    "    \n",
    "    \n",
    "    #selects dimers\n",
    "    correctedimgdimer,pointsdimer,r=performkeepmatchedparticles(analpath, correctedimgcore)\n",
    "    image_circle=blockimagecombo(sat_img, pointsdimer,16,2)\n",
    "    savepath=os.path.join(analpath, \"dimerCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #print(np.unique(np.array(pointsdimer),axis=0))\n",
    "    #pointsdimer_corrected=np.unique(np.array(pointsdimer),axis=0)\n",
    "    pointsdimer_corrected=pointsdimer\n",
    "    #uses those points to select the same points in the target image \n",
    "    \n",
    "    transtarimg=makeclippingmask(transtarimg)\n",
    "    correctedimgtarget=blockimagecombo(transtarimg,pointsdimer_corrected,r,0)\n",
    "    \n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(correctedimgtarget,savepath)\n",
    "    \n",
    "    #scans the before and after dimers to determine if the particles shift in hue\n",
    "    threshold=-0.001\n",
    "    selected_target_locations,average_values=averagehistogramshift(correctedimgdimer,pointsdimer_corrected,correctedimgtarget,threshold,analpath)\n",
    "    image_circle=blockimagecombo(transtarimg, selected_target_locations,16,2)\n",
    "    savepath=os.path.join(analpath, \"targetCircled\" + \".\" + \"png\")\n",
    "    performsaveimage(image_circle,savepath)\n",
    "    \n",
    "    \n",
    "    #comment out if don't want\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\before\",sat_img,pointsdimer_corrected)\n",
    "    #savetotrainingfol(r\"D:\\OneDrive - UNSW\\Image_Analysis\\typesofParticles\\NewAItraining\\newmicroscope\\unsorted\\after\",transtarimg,selected_target_locations)\n",
    "    \n",
    "    return selected_target_locations,pointsdimer_corrected,average_values\n",
    "\n",
    "\n",
    "######### Extra functions\n",
    "\n",
    "def getindividualfoldersandsuch(bigfol):\n",
    "# a function which gets the folders underneath the big folder. Must be the format: bigfol>slide>sample>satellite | target> images\n",
    "    topfolders=listdirs(bigfol)\n",
    "    subfolders=[0]\n",
    "    for nextfolders in topfolders:\n",
    "        subfolders= subfolders+ listdirs(nextfolders)\n",
    "    subfolders.pop(0)\n",
    "    #print(subfolders)\n",
    "    subfolders=np.array(subfolders).reshape(-1,1)\n",
    "    #print(subfolders)\n",
    "    return subfolders\n",
    "def searchforsatandtargetfolders(folder):\n",
    "#finds the satellite and targetfolders using regexp\n",
    "    subfolders2 = folder.tolist()\n",
    "    subfolders3=str(subfolders2).replace('[','').replace(']','').replace('\\\\\\\\','\\\\')\n",
    "\n",
    "    listexpfolders=listdirs(subfolders3[1:len(subfolders3)-1])\n",
    "    beforefol = [x for x in listexpfolders if re.search(\"satellite\",x)]\n",
    "    beforefol=beforefol[0]\n",
    "    afterfol= [x for x in listexpfolders if re.search(\"target\",x)]\n",
    "    afterfol=afterfol[0]\n",
    "    \n",
    "    return beforefol,afterfol\n",
    "\n",
    "def createanalysisfolder(beforefol,string):\n",
    "#creates an analysis folder in the address above where the satellite and target folders are located.\n",
    "    oneuppath=os.path.dirname(beforefol)\n",
    "    analysisfolderpath=oneuppath+\"\\\\\"+string\n",
    "    try:\n",
    "        os.mkdir(analysisfolderpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    print(analysisfolderpath)\n",
    "    print(\"processing images\")\n",
    "    return analysisfolderpath,oneuppath\n",
    "\n",
    "def createimagesubfolderforsaving(pathtomatch,analysisfolderpath):\n",
    "# creates a folder with the name of the image in the analysis folder \n",
    "    pathtomatch=beforeimfile[j]\n",
    "    matchingsearch=re.search(\"IMG_.*.CR2\",pathtomatch)\n",
    "    savefilespath=analysisfolderpath+\"\\\\\"+matchingsearch.group()+\"\\\\\"\n",
    "    try: \n",
    "        os.mkdir(savefilespath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    return savefilespath\n",
    "def addstringwithtime(savefilespath):\n",
    "# adds the current date and time so there's no saving over the top of different analysis\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    savepath=savefilespath+dt_string\n",
    "    return savepath\n",
    "def makeanalysisfolder(savefilespath,string):\n",
    "# makes a directory in the folder which matches the image name which says 'analysis'\n",
    "    analpath=os.path.join(savefilespath,string)\n",
    "                        #saves the registered image\n",
    "    try: \n",
    "        os.mkdir(analpath)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    return analpath\n",
    "\n",
    "################ THRESHOLDING\n",
    "def gethuevaluesthreshHSV(image,points):\n",
    "    image_hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    image_hue=image_hsv[:,:,0]\n",
    "    w=8\n",
    "    average_colour_rDivg=[]\n",
    "    for i,pt in enumerate(points):           \n",
    "        try: \n",
    "            crop_im=image_hue[pt[1]-w:pt[1]+w, pt[0]-w:pt[0]+w]\n",
    "            dividedval=crop_im.reshape((1,-1))\n",
    "            #print(dividedval)\n",
    "            average_colour_rDivg.append(np.mean(dividedval))\n",
    "            \n",
    "        except:\n",
    "            z=1;\n",
    "    return np.array(average_colour_rDivg)\n",
    "\n",
    "def getcentroidsandcenters(image):\n",
    "    \n",
    "    #wmakes an excellent binary image\n",
    "    src = image.copy()\n",
    "\n",
    "    \n",
    "    # Create a kernel that we will use to sharpen our image\n",
    "    # an approximation of second derivative, a quite strong kernel\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    \n",
    "    # Create binary image from source image\n",
    "    # Create binary image from source image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_RGB2GRAY)\n",
    "    #_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    contours, hierarchy = cv.findContours(bw, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    list_of_centres=[]\n",
    "    boundRect = [None]*len(contours)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        center_circle, _ = cv.minEnclosingCircle(contours_poly[i])\n",
    "        list_of_centres.append((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "        \n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "        cv.circle(src, ((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1])))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        #print((np.int(np.round(center_circle[0])),np.int(np.round(center_circle[1]))))\n",
    "    #picked_rectangles=non_max_suppression_fast(np.array(boundRect),0.01)\n",
    "    #h=16;\n",
    "    #for (startX, startY, endX, endY) in picked_rectangles:\n",
    "        #the coordinates are top left hand corner, bottom right hand corner for rectangles \n",
    "    #    list_of_centres.append((np.round((startX+endX/2)),np.round((startY+endY/2))))\n",
    "        #cv.circle(src, (np.int(np.round((startX+endX/2))),np.int(np.round((startY+endY/2)))), 20, (255, 255, 0), 1)\n",
    "        \n",
    "    #cv.imshow(\"Image\", src)\n",
    "    #plt.show()\n",
    "    #list_of_centres=np.array(list_of_centres)\n",
    "    #print(list_of_centres)\n",
    "    return list_of_centres\n",
    "\n",
    "\n",
    "def performthresholding(beforeim,afterim,analpath):\n",
    "    list_of_centres=getcentroidsandcenters(beforeim)\n",
    "    average_colour=gethuevaluesthreshHSV(image,list_of_centres)\n",
    "    dimer_points= np.array(list_of_centres)[average_colour <= 20]\n",
    "    \n",
    "    average_colour_dimer=gethuevaluesthreshHSV(image,dimer_points)\n",
    "    dimers_blocked=blockimagecombo(beforeim, dimer_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"dimersblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(dimers_blocked,savepath)\n",
    "    target_image=blockimagecombo(afterim, dimer_points,8,0)\n",
    "    savepath=os.path.join(analpath, \"targetblocked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image,savepath)\n",
    "    average_colour_after=gethuevaluesthreshHSV(target_image,dimer_points)\n",
    "    particle_difference=average_colour_dimer-average_colour_after\n",
    "    target_points= np.array(dimer_points)[particle_difference < -10]\n",
    "    target_image_picked=blockimagecombo(afterim, target_points,16,0)\n",
    "    savepath=os.path.join(analpath, \"targetpicked\" + \".\" + \"png\")\n",
    "    performsaveimage(target_image_picked,savepath)\n",
    "    return dimer_points,target_points\n",
    "    \n",
    "#########################\n",
    "\n",
    "\n",
    "#subfolders=getindividualfoldersandsuch(bigfol)\n",
    "#oneuppath=os.path.dirname(bigfol)\n",
    "analysisfolderpath,oneuppath=createanalysisfolder(bigfol,\"Analysisfolder\")\n",
    "#print(analysisfolderpath)\n",
    "savefilespath,oneuppath=createanalysisfolder(analysisfolderpath,\"images\")\n",
    "images=readinimageframes(bigfol,savefilespath)\n",
    "images2=readinimageframes(bigfol,savefilespath)\n",
    "lengthim=sum(1 for x in images2)\n",
    "\n",
    "    \n",
    "print(\"processed and converted images\")\n",
    "\n",
    "\n",
    "response=[0]*len(lengthim)\n",
    "dimercount=[0]*len(lengthim)\n",
    "targetcount=[0]*len(lengthim)\n",
    "response_thresh=[0]*len(lengthim)\n",
    "dimercount_thresh=[0]*len(lengthim)\n",
    "targetcount_thresh=[0]*len(lengthim)\n",
    "#t = tqdm(total=len(imbef))\n",
    "for j,image in enumerate(images):\n",
    "    if j==0:\n",
    "        break\n",
    "    #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "        #pbar.write('processed: %d' % (j+1))\n",
    "        #pbar.update(0.25)\n",
    "        #sleep(0.1)\n",
    "\n",
    "    \n",
    "    savefilespath_temp,oneuppath=createanalysisfolder(analysisfolderpath,\"Individual_image_analysis\")\n",
    "    \n",
    "\n",
    "\n",
    "    #add on the currentdate and time \n",
    "    savepath_temp=addstringwithtime(savefilespath_temp)\n",
    "    savepath_thresh=addstringwithtime(savefilespath_temp)\n",
    "\n",
    "\n",
    "    print(\"calculating image \"+str(j+1)+\" of \"+ str(len(images)))\n",
    "\n",
    "    #make an analysis folder which says analysis in the image folder just created \n",
    "    analpath_temp=makeanalysisfolder(savefilespath_temp,\"Analysisimages_Template\")\n",
    "    analpath_thresh=makeanalysisfolder(savefilespath_thresh,\"Analysisimages_thresholding\")\n",
    "\n",
    "    #spot matches the before and after images \n",
    "    transimaf=imgregfun(image, image[j-1])\n",
    "    #saves the redistered image\n",
    "    saveregisteredimage=os.path.join(analpath_temp, \"registeredimg\" + \".\" + \"png\")\n",
    "    performsaveimage(transimaf,saveregisteredimage)\n",
    "    #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "        #pbar.write('processed: %d' % (j+1))\n",
    "    #    pbar.update(0.5)\n",
    "    #    sleep(0.1)\n",
    "\n",
    "    #uncomment if you want a crop box    \n",
    "    #height, width = image.shape[:2]\n",
    "    #boxwid=round(1500/2)\n",
    "    #centreimagebefore=image[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "    #centreimageafter=transimaf[round(height/2)-boxwid:round(height/2)+boxwid,round(width/2)-boxwid:round(width/2)+boxwid]\n",
    "    centreimagebefore=makeclippingmask(image)\n",
    "    print(\"Made the clipping Mask\")\n",
    "    #plt.imshow(centreimagebefore)\n",
    "    centreimageafter=makeclippingmask(transimaf)\n",
    "\n",
    "    #with tqdm(total=len(imbef), file=sys.stdout) as pbar:\n",
    "\n",
    "        #pbar.write('processed: %d' % (j+1))\n",
    "        #pbar.update(0.75)\n",
    "        #sleep(0.1)\n",
    "    dimer_points,target_points=performthresholding(centreimagebefore,centreimageafter,analpath_thresh)\n",
    "\n",
    "    #perform the template matching and see which particles shift\n",
    "    targetpicked,pointsdimer,average=performtemplatetrainingonimages(centreimageafter,analpath_temp,centreimagebefore)\n",
    "\n",
    "\n",
    "    #saves the to an excel spreadsheet and saves the results to a list to get the overall results at the end \n",
    "    #if I feel bothered I can add something in that uses the already analysed images but meh \n",
    "    dimercount[j]=len(pointsdimer)\n",
    "    targetcount[j]=len(targetpicked)\n",
    "    try: \n",
    "        response[j]=(len(targetpicked)/len(pointsdimer))*100\n",
    "    except:\n",
    "        response[j]=0\n",
    "\n",
    "    saveexcelfun(pointsdimer,targetpicked,savepath_temp)\n",
    "\n",
    "    dimercount_thresh[j]=len(dimer_points)\n",
    "    targetcount_thresh[j]=len(target_points)\n",
    "    try: \n",
    "        response_thresh[j]=(len(target_points)/len(dimer_points))*100\n",
    "    except:\n",
    "        response_thresh[j]=0\n",
    "    #print(pointsdimer.type)\n",
    "    #print(dimer_points.type)\n",
    "    #saveexcelfun(dimer_points,target_points,savepath_thresh)\n",
    "\n",
    "\n",
    "\n",
    "    #save important coordinates to a text file for later analysis\n",
    "    #Probably can delete this don't know what it's used for anymore \n",
    "    #savetextfilefun(np.array(pointsdimer),savepath,\"dimerbefore\")\n",
    "    #savetextfilefun(np.array(targetpicked),savepath,\"selectedResponse\")\n",
    "\n",
    "print(\"Finished analysis woohoo\")\n",
    "#t.close()\n",
    "#Find the folders which contain the analysis and read the text files\n",
    "#Find the image folders\n",
    "searchfolder=analysisfolderpath\n",
    "#insearchfolder=os.listdir(searchfolder)\n",
    "savedir_temp= searchfolder+'\\\\'+\"Analysisimages_Template\"\n",
    "imagefilefolders=os.listdir(savedir_temp)\n",
    "#Write excel worsheet in the analysis folder\n",
    "responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount),'target_picked':np.array(targetcount),'response': np.array(response)})\n",
    "responsepath_temp=savedir_temp+'\\\\'+\"responseforallimages.xlsx\"\n",
    "responseforexcel.to_excel(responsepath_temp) \n",
    "\n",
    "searchfolder_thresh=analysisfolderpath\n",
    "#insearchfolder=os.listdir(searchfolder)\n",
    "savedir_thresh= searchfolder+'\\\\'+\"Analysisimages_thresholding\"\n",
    "imagefilefolders=os.listdir(savedir_thresh)\n",
    "#Write excel worsheet in the analysis folder\n",
    "responseforexcel = pd.DataFrame({'dimers_picked':np.array(dimercount_thresh),'target_picked':np.array(targetcount_thresh),'response': np.array(response_thresh)})\n",
    "responsepath_thresh=savedir_thresh+'\\\\'+\"responseforallimages.xlsx\"\n",
    "responseforexcel.to_excel(responsepath_thresh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-inspection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
